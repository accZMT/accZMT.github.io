<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>llt</title>
  
  <subtitle>只想挽起你的手 戎马一生挥毫只为你</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://acczmt.top/"/>
  <updated>2018-08-16T03:00:00.183Z</updated>
  <id>https://acczmt.top/</id>
  
  <author>
    <name>李岚天</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis基本命令</title>
    <link href="https://acczmt.top/2018/08/14/redis%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"/>
    <id>https://acczmt.top/2018/08/14/redis基本命令/</id>
    <published>2018-08-14T09:52:00.000Z</published>
    <updated>2018-08-16T03:00:00.183Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/14.jpg?imageView2/2/h/600"><br></div><p><strong>Redis 是一个速度非常快的非关系型数据库，使用内存作为主存储，内存中的数据也可以被持久化到硬盘。Redis以键值对形式(key-value)存储数据，其中值可以分为以下5中类型：</strong></p><ul><li><a href="#字符串">字符串(string)</a></li><li><a href="#哈希">哈希(hash)</a></li><li><a href="#列表">列表(list)</a></li><li><a href="#集合">集合(set)</a></li><li><a href="#有序集合">有序集合(zset)</a></li><li><a href="#key">key</a></li></ul><h3 id="Redis-基本命令"><a href="#Redis-基本命令" class="headerlink" title="Redis 基本命令"></a>Redis 基本命令</h3><blockquote><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4></blockquote><p>Redis的字符串(string)可以存储字符串、整数、浮点数。String命令及描述如下表所示：</p><table><thead><tr><th>String命令</th><th>描 述</th></tr></thead><tbody><tr><td>set key value</td><td>设置字符串key的值</td></tr><tr><td>get key</td><td>获取字符串key的值</td></tr><tr><td>del key</td><td>删除key</td></tr><tr><td>strlen key</td><td>获取值长度</td></tr><tr><td>mset key1 value1 key2 value2…</td><td>设置多个值</td></tr><tr><td>mget key1 key2…</td><td>获取多个值</td></tr><tr><td>append key value</td><td>追加值</td></tr><tr><td>incr key</td><td>将key对应的值加一</td></tr><tr><td>decr key</td><td>将key对应的值减一</td></tr><tr><td>incrby key intnum</td><td>将key对应的值加整数</td></tr><tr><td>decrby key intnum</td><td>将key对应的值减整数</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; mset age 30 sex man</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; mget age sex</span><br><span class="line">1) <span class="string">"30"</span></span><br><span class="line">2) <span class="string">"man"</span></span><br><span class="line">127.0.0.1:6379&gt; append name lisi</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">"lisi"</span></span><br><span class="line">127.0.0.1:6379&gt; strlen name</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; incr age</span><br><span class="line">(<span class="built_in">integer</span>) 31</span><br><span class="line">127.0.0.1:6379&gt; incrby age 10</span><br><span class="line">(<span class="built_in">integer</span>) 41</span><br><span class="line">127.0.0.1:6379&gt; decr age</span><br><span class="line">(<span class="built_in">integer</span>) 40</span><br><span class="line">127.0.0.1:6379&gt; decrby age 20</span><br><span class="line">(<span class="built_in">integer</span>) 20</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><blockquote><h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4></blockquote><p>Redis的列表(list)可以有序地存储多个字符串。List命令及描述如下所示：</p><blockquote><p>索引值从0开始 ，可以为负数</p></blockquote><table><thead><tr><th>List命令</th><th>描 述</th></tr></thead><tbody><tr><td>lpush key1 value1 value2 …</td><td>在列表key左端插入一个或者多个值</td></tr><tr><td>rpush key1 value1 value2 …</td><td>在列表key又端插入一个或者多个值</td></tr><tr><td>linsert key before/after pivot value</td><td>在一个元素的前/后插入新的元素</td></tr><tr><td>lset key index value</td><td>设置指定索引的元素值</td></tr><tr><td>lpop key</td><td>在列表key左端弹出一个值</td></tr><tr><td>rpop key</td><td>在列表key右端弹出一个值</td></tr><tr><td>llen key</td><td>获取列表key的长度</td></tr><tr><td>lindex key index</td><td>获取列表key中index位置的值</td></tr><tr><td>lrange key start end</td><td>获取列表key中位置在[start,end]范围的值</td></tr><tr><td>ltrim key start end</td><td>裁剪列表，改为元集合的一个子集</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush fond study game sing</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; lrange fond 0 -1</span><br><span class="line">1) <span class="string">"sing"</span></span><br><span class="line">2) <span class="string">"game"</span></span><br><span class="line">3) <span class="string">"study"</span></span><br><span class="line">127.0.0.1:6379&gt; rpush friends Jane Jack</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; linsert friends after Jack kangkang</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; lrange friends 0 -1</span><br><span class="line">1) <span class="string">"Jane"</span></span><br><span class="line">2) <span class="string">"Jack"</span></span><br><span class="line">3) <span class="string">"kangkang"</span></span><br><span class="line">127.0.0.1:6379&gt; lset fond 2 swim</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lpop fond</span><br><span class="line"><span class="string">"sing"</span></span><br><span class="line">127.0.0.1:6379&gt; rpop friends</span><br><span class="line"><span class="string">"kangkang"</span></span><br><span class="line">127.0.0.1:6379&gt; lrange fond 0 -1</span><br><span class="line">1) <span class="string">"game"</span></span><br><span class="line">2) <span class="string">"swim"</span></span><br><span class="line">127.0.0.1:6379&gt; llen fond</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; lindex fond 0</span><br><span class="line"><span class="string">"game"</span></span><br><span class="line">127.0.0.1:6379&gt; ltrim friends 0 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lrange friends 0 -1</span><br><span class="line">1) <span class="string">"Jane"</span></span><br><span class="line">2) <span class="string">"Jack"</span></span><br></pre></td></tr></table></figure><blockquote><h4 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h4></blockquote><p>Redis的哈希(Hash)可以存储多个键值对，其中的键和值都是字符串。Hash命令及描述如下表所示：</p><table><thead><tr><th>Hash命令</th><th>描述</th></tr></thead><tbody><tr><td>hset key field value</td><td>将哈希key的field字段赋值为value</td></tr><tr><td>hmset key field1 value1 field2 value2…</td><td>设置多个值</td></tr><tr><td>hdel key field1 field2…</td><td>删除哈希key的一个或多个字段</td></tr><tr><td>hget key field</td><td>获取哈希key的field字段的值</td></tr><tr><td>hmget key field1 field2…</td><td>获取多个属性的值</td></tr><tr><td>hgetall key</td><td>获取哈希key的所有字段和值</td></tr><tr><td>hkeys key</td><td>获取所有属性</td></tr><tr><td>hvals key</td><td>获取所有值</td></tr><tr><td>hlen  key</td><td>返回包含数据的个数</td></tr><tr><td>hexists key field</td><td>判断属性是否存在，存在返回1，不存在返回0</td></tr><tr><td>hstrlen key field</td><td>返回值的字符串长度</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset point x 10</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; hmset point y 20</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; hget point y</span><br><span class="line"><span class="string">"20"</span></span><br><span class="line">127.0.0.1:6379&gt; hmget point</span><br><span class="line">(error) ERR wrong number of argu</span><br><span class="line">127.0.0.1:6379&gt; hmget point x z</span><br><span class="line">1) <span class="string">"10"</span></span><br><span class="line">2) <span class="string">"30"</span></span><br><span class="line">127.0.0.1:6379&gt; hgetall point</span><br><span class="line">1) <span class="string">"x"</span></span><br><span class="line">2) <span class="string">"10"</span></span><br><span class="line">3) <span class="string">"y"</span></span><br><span class="line">4) <span class="string">"20"</span></span><br><span class="line">5) <span class="string">"z"</span></span><br><span class="line">6) <span class="string">"30"</span></span><br><span class="line">127.0.0.1:6379&gt; hkeys point</span><br><span class="line">1) <span class="string">"x"</span></span><br><span class="line">2) <span class="string">"y"</span></span><br><span class="line">3) <span class="string">"z"</span></span><br><span class="line">127.0.0.1:6379&gt; hvals point</span><br><span class="line">1) <span class="string">"10"</span></span><br><span class="line">2) <span class="string">"20"</span></span><br><span class="line">3) <span class="string">"30"</span></span><br><span class="line">127.0.0.1:6379&gt; hlen point</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; hexists point w</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379&gt; hstrlen point x</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; hdel point x y z</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br></pre></td></tr></table></figure><blockquote><h4 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h4></blockquote><p>Redis中的集合(set)可以存储多个唯一的字符串。set命令及描述如下表所示：</p><table><thead><tr><th>set命令</th><th>描 述</th></tr></thead><tbody><tr><td>sadd key member1 member2…</td><td>向集合key中添加一个或多个成员</td></tr><tr><td>srem key member1 member2…</td><td>删除集合key中一个或者多个成员</td></tr><tr><td>smembers key</td><td>获取集合key中所有成员</td></tr><tr><td>scard key</td><td>获取集合key中成员数量</td></tr><tr><td>sismember key menber</td><td>判断member是否是集合key的成员</td></tr><tr><td>sinter key1 key2…</td><td>求多个集合的交集</td></tr><tr><td>sdiff  key1 key2…</td><td>求多个集合的差集</td></tr><tr><td>sunion key1 key2…</td><td>求多个集合的合集</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd color red black blue whi</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; smembers color</span><br><span class="line">1) <span class="string">"black"</span></span><br><span class="line">2) <span class="string">"white"</span></span><br><span class="line">3) <span class="string">"blue"</span></span><br><span class="line">4) <span class="string">"red"</span></span><br><span class="line">127.0.0.1:6379&gt; scard color</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; sismember color yellow</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379&gt; sadd colors red blue yellow p</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; sinter color colors</span><br><span class="line">1) <span class="string">"blue"</span></span><br><span class="line">2) <span class="string">"red"</span></span><br><span class="line">127.0.0.1:6379&gt; sdiff color colors</span><br><span class="line">1) <span class="string">"black"</span></span><br><span class="line">2) <span class="string">"white"</span></span><br><span class="line">127.0.0.1:6379&gt; sunion color colors</span><br><span class="line">1) <span class="string">"yellow"</span></span><br><span class="line">2) <span class="string">"black"</span></span><br><span class="line">3) <span class="string">"pink"</span></span><br><span class="line">4) <span class="string">"white"</span></span><br><span class="line">5) <span class="string">"blue"</span></span><br><span class="line">6) <span class="string">"red"</span></span><br><span class="line">127.0.0.1:6379&gt; srem color red black</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br></pre></td></tr></table></figure><blockquote><h4 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h4></blockquote><p>Redis中的有序集合(ZSet)与集合(Set)类似，可以存储多个唯一的字符串，但在有序集合中，每个成员都有一个分数，所有成员按给定分数在集合中有序排列。Zset命令及描述如下图所示：</p><table><thead><tr><th>Zset命令</th><th>描 述</th></tr></thead><tbody><tr><td>zadd key score1 member1 score2 member2…</td><td>向有序集合key中添加一个或多个成员</td></tr><tr><td>zrem key member member2 …</td><td>删除有序集合key中一个或多个成员</td></tr><tr><td>zrange key start stop</td><td>获取有序集合key中位置在[start,end]范围的所有成员</td></tr><tr><td>zrangebyscore key min max</td><td>获取有序集合key中分值在[min,max]范围的所有成员</td></tr><tr><td>zcount key key min max</td><td>获取有序集合key中分值在[min,max]范围的个数</td></tr><tr><td>zcard key</td><td>返回元素的个数</td></tr><tr><td>zscore key member</td><td>返回有序集合key中，成员member的分值</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd country 1 China 2 Russia 3 India 4 France</span><br><span class="line">(<span class="built_in">integer</span>) 5</span><br><span class="line">127.0.0.1:6379&gt; zrange country 0 -1</span><br><span class="line">1) <span class="string">"China"</span></span><br><span class="line">2) <span class="string">"Russia"</span></span><br><span class="line">3) <span class="string">"India"</span></span><br><span class="line">4) <span class="string">"France"</span></span><br><span class="line">5) <span class="string">"Italy"</span></span><br><span class="line">127.0.0.1:6379&gt; zrangebyscore country 1 3</span><br><span class="line">1) <span class="string">"China"</span></span><br><span class="line">2) <span class="string">"Russia"</span></span><br><span class="line">3) <span class="string">"India"</span></span><br><span class="line">127.0.0.1:6379&gt; zcount country 1 4</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; zcard country</span><br><span class="line">(<span class="built_in">integer</span>) 5</span><br><span class="line">127.0.0.1:6379&gt; zscore country China</span><br><span class="line"><span class="string">"1"</span></span><br></pre></td></tr></table></figure><blockquote><h4 id="key"><a href="#key" class="headerlink" title="key"></a>key</h4></blockquote><table><thead><tr><th>key命令</th><th>描 述</th></tr></thead><tbody><tr><td>keys pattern</td><td>查找键，参数支持正则</td></tr><tr><td>exists key</td><td>判断键是否存在，如果存在返回1，不存在返回0</td></tr><tr><td>type key</td><td>查看键及对应的值</td></tr><tr><td>del key1 key2 …</td><td>删除键及对应的值</td></tr><tr><td>expire key seconds</td><td>设置过期时间，以秒为单位</td></tr><tr><td>ttl key</td><td>查看有效时间，以秒为单位</td></tr></tbody></table><blockquote><ul><li>更多详细命令请参考官网 <a href="https://redis.io" target="_blank" rel="noopener">https://redis.io</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/14.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="redis" scheme="https://acczmt.top/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>scrapy爬取jobbole</title>
    <link href="https://acczmt.top/2018/08/13/scrapy%E7%88%AC%E5%8F%96jobbole/"/>
    <id>https://acczmt.top/2018/08/13/scrapy爬取jobbole/</id>
    <published>2018-08-13T13:00:00.000Z</published>
    <updated>2018-08-16T03:00:36.856Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/15.jpg?imageView2/2/h/600"><br></div></p><blockquote><p>以jobbole为例，获取<a href="http://blog.jobbole.com/all-posts/" target="_blank" rel="noopener">最新文章</a>中的数据，使用ItemLoader清洗数据，并保存为json文件，下载封面图片</p></blockquote><blockquote><p>打开命令行cd到指定的文件夹，依次执行以下命令</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject jobbole</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> jobbole</span><br><span class="line"></span><br><span class="line">scrapy genspider blog blog.jobbole.com</span><br></pre></td></tr></table></figure><blockquote><p>在items.py 中定义一个JobboleItemLoader类继承ItemLoader </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"><span class="keyword">from</span> scrapy.loader.processors <span class="keyword">import</span> MapCompose,TakeFirst</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobboleItemLoader</span><span class="params">(ItemLoader)</span>:</span></span><br><span class="line">    <span class="comment"># 设置输出内容的类型</span></span><br><span class="line">    <span class="comment"># 默认返回的数据为一个列表 </span></span><br><span class="line">    <span class="comment"># default_output_processor = ItemLoader.default_output_processor()</span></span><br><span class="line">    <span class="comment"># TakeFirst 获取所有数据当中的第一条数据</span></span><br><span class="line">    default_output_processor = TakeFirst()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取评论、收藏中的数字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_num</span><span class="params">(value)</span>:</span></span><br><span class="line">    value = value.split(<span class="string">' '</span>)[<span class="number">1</span>]</span><br><span class="line">    value = <span class="number">0</span> <span class="keyword">if</span> value==<span class="string">''</span> <span class="keyword">else</span> int(value)</span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobboleItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    img_src = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    date = scrapy.Field(</span><br><span class="line">        input_processor = MapCompose(<span class="keyword">lambda</span> x:x.strip().replace(<span class="string">' ·'</span>,<span class="string">''</span>))</span><br><span class="line">    )</span><br><span class="line">    detail_url = scrapy.Field()</span><br><span class="line">    like = scrapy.Field(input_processor=MapCompose(<span class="keyword">lambda</span> x:int(x)))</span><br><span class="line">    collect = scrapy.Field(</span><br><span class="line">        input_processor = MapCompose(get_num)</span><br><span class="line">    )</span><br><span class="line">    comment = scrapy.Field(input_processor=MapCompose(get_num))</span><br></pre></td></tr></table></figure><blockquote><p>blog.py 文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> JobboleItem</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> JobboleItemLoader</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BlogSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'blog'</span></span><br><span class="line">    allowed_domains = [<span class="string">'blog.jobbole.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://blog.jobbole.com/all-posts/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        data_list = response.xpath(<span class="string">'//div[@class="post floated-thumb"]'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            img_src = data.xpath(<span class="string">'.//div[@class="post-thumb"]/a/img/@src'</span>).get()</span><br><span class="line">            detail_url = data.xpath(<span class="string">'.//div[@class="post-thumb"]/a/@href'</span>).get()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(detail_url,meta=&#123;<span class="string">"img"</span>:img_src&#125;,callback=self.get_detail_info_with_url)</span><br><span class="line">        <span class="comment"># 获取下一页链接  </span></span><br><span class="line">        <span class="comment"># next_page = response.xpath('//a[@class="next page-numbers"]/@href')</span></span><br><span class="line">        <span class="comment"># if len(next_page) != 0:</span></span><br><span class="line">        <span class="comment">#     yield scrapy.Request(next_page.get(),callback=self.parse)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_detail_info_with_url</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建ItemLoader的实例化对象的时候 需要传入两个参数</span></span><br><span class="line">        <span class="comment"># 参数1：item的实例化对象 item里面为还要提取的数据的字段</span></span><br><span class="line">        <span class="comment"># 参数2：网页的源码</span></span><br><span class="line">        item_loader = JobboleItemLoader(item=JobboleItem(),response=response)</span><br><span class="line"></span><br><span class="line">        item_loader.add_xpath(<span class="string">'title'</span>,<span class="string">'//h1/text()'</span>)</span><br><span class="line">        item_loader.add_value(<span class="string">'img_src'</span>,response.meta[<span class="string">'img'</span>])</span><br><span class="line">        item_loader.add_xpath(<span class="string">'date'</span>,<span class="string">'//p[@class="entry-meta-hide-on-mobile"]/text()'</span>)</span><br><span class="line">        item_loader.add_value(<span class="string">'detail_url'</span>,response.url)</span><br><span class="line">        item_loader.add_xpath(<span class="string">'like'</span>,<span class="string">'//h10/text()'</span>)</span><br><span class="line">        item_loader.add_xpath(<span class="string">'collect'</span>,<span class="string">'//span[contains(@class,"bookmark-btn")]/text()'</span>)</span><br><span class="line">        item_loader.add_xpath(<span class="string">'comment'</span>,<span class="string">'//span[@class="btn-bluet-bigger href-style hide-on-480"]/text()'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将item_loader加载器中保存的每一个field数据收集起来，赋值给item </span></span><br><span class="line">        item = item_loader.load_item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><blockquote><p>pipelines.py 文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonItemExporter</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">""" 使用JsonItemExporter保存json文件"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'blog.json'</span>,<span class="string">'wb'</span>)</span><br><span class="line">        self.export = JsonItemExporter(self.file,ensure_ascii=<span class="keyword">False</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        print(<span class="string">"爬虫开始了"</span>)</span><br><span class="line">        self.export.start_exporting()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self,item,spider)</span>:</span></span><br><span class="line">        self.export.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.export.finish_exporting()</span><br><span class="line">        self.file.close()</span><br><span class="line">        print(<span class="string">'爬虫结束了'</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DownloadImagesPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="string">"""继承ImagesPipeline 下载封面图片"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        </span><br><span class="line">        src = item[<span class="string">'img_src'</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=src,meta=&#123;<span class="string">'item'</span>:item[<span class="string">'title'</span>]&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 以标题命名</span></span><br><span class="line">        title = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        <span class="keyword">return</span> title + <span class="string">'.jpg'</span></span><br></pre></td></tr></table></figure><blockquote><p>settings.py 文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将爬虫协议改为False</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="comment"># 'jobbole.pipelines.JobbolePipeline': 300,</span></span><br><span class="line">   <span class="string">'jobbole.pipelines.JsonPipeline'</span>: <span class="number">1</span>,</span><br><span class="line">   <span class="string">'jobbole.pipelines.DownloadImagesPipeline'</span>: <span class="number">2</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 图片保存路径</span></span><br><span class="line">IMAGES_STORE = <span class="string">'imgs'</span></span><br></pre></td></tr></table></figure><blockquote><p>在jobbole/jobbole下新建一个main.py文件，直接运行main.py 文件即可</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl blog'</span>.split())</span><br></pre></td></tr></table></figure><p>源码放到了GitHub上<a href="https://github.com/accZMT/python_study/tree/master/jobbole/jobbole" target="_blank" rel="noopener">jobbole项目源码</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/15.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;
      
    
    </summary>
    
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>python+smtp发送email</title>
    <link href="https://acczmt.top/2018/08/10/python+smtp%E5%8F%91%E9%80%81email/"/>
    <id>https://acczmt.top/2018/08/10/python+smtp发送email/</id>
    <published>2018-08-10T11:10:00.000Z</published>
    <updated>2018-08-16T02:59:38.599Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/16.jpg?imageView2/2/h/600"><br></div><p>今天刚学过使用smtplib和email发送邮件，感觉挺有意思的，下面为自己的学习总结</p><p><code>使用python+smtp 需要开启smtp服务，这里使用qq邮箱</code><br><code>密码为第三方登录授权码</code></p><p>1.引入所需要的包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> smtplib</span><br><span class="line"><span class="comment"># 创建包含文本数据的邮件体</span></span><br><span class="line"><span class="keyword">from</span> email.mime.text <span class="keyword">import</span> MIMEText </span><br><span class="line"><span class="comment"># 创建包含图片数据的邮件体</span></span><br><span class="line"><span class="keyword">from</span> email.mime.image <span class="keyword">import</span> MIMEImage</span><br><span class="line"><span class="comment"># 作用是生成包含多个部分的邮件体的MIME对象</span></span><br><span class="line"><span class="keyword">from</span> email.mime.multipart <span class="keyword">import</span> MIMEMultipart</span><br></pre></td></tr></table></figure><p>2.发送纯文本信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置邮箱的域名</span></span><br><span class="line">HOST = <span class="string">"smtp.qq.com"</span></span><br><span class="line"><span class="comment"># 邮件标题</span></span><br><span class="line">SUBJECT = <span class="string">"中午有时间吗"</span></span><br><span class="line"><span class="comment"># 发件人的邮箱</span></span><br><span class="line">FROM = <span class="string">"XXX@qq.com"</span></span><br><span class="line"><span class="comment"># 设置收件人的邮箱</span></span><br><span class="line">TO = <span class="string">'XX@qq.com'</span></span><br><span class="line"><span class="comment"># 发送邮件主体到对方的邮箱中</span></span><br><span class="line"><span class="comment"># 参数1 发送的内容  内容为字符串</span></span><br><span class="line"><span class="comment"># 参数2 内容的类型  文本类型默认为plain</span></span><br><span class="line"><span class="comment"># 参数3 内容的编码方式</span></span><br><span class="line">message_text = MIMEText(<span class="string">'中午一起吃鸡啊'</span>,<span class="string">'plain'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 设置邮件发件人</span></span><br><span class="line">message_text[<span class="string">'From'</span>] = FROM</span><br><span class="line">message_text[<span class="string">'To'</span>] = TO</span><br><span class="line">message_text[<span class="string">'Subject'</span>] = SUBJECT</span><br><span class="line"><span class="comment"># 获取简单邮件传输协议的证书</span></span><br><span class="line">email_client = smtplib.SMTP_SSL()</span><br><span class="line"><span class="comment"># 设置发件人邮件的域名和端口</span></span><br><span class="line">email_client.connect(HOST,<span class="string">'465'</span>)</span><br><span class="line"><span class="comment"># 密码为邮箱授权码</span></span><br><span class="line">result = email_client.login(FROM,<span class="string">'xxx'</span>)</span><br><span class="line">print(<span class="string">"登录结果："</span>,result)</span><br><span class="line"><span class="comment"># 参数依次为是发件人、收件人、邮件内容</span></span><br><span class="line">email_client.sendmail(FROM,TO,message_text.as_string())</span><br><span class="line"><span class="comment"># 关闭邮件发送客户端</span></span><br><span class="line">email_client.close()</span><br></pre></td></tr></table></figure></p><p>3.发送附件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">"smtp.qq.com"</span></span><br><span class="line">FROM = <span class="string">"XXX@qq.com"</span></span><br><span class="line">TO = <span class="string">'XX@qq.com'</span></span><br><span class="line">message_xlsx = MIMEText(open(<span class="string">'table.xlsx'</span>,<span class="string">'rb'</span>).read(),<span class="string">'base64'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 设置文件在附件当中的名字</span></span><br><span class="line">message_xlsx[<span class="string">'Content-Disposition'</span>] = <span class="string">'attachment;filename="test11111.xlsx"'</span></span><br><span class="line">message_xlsx[<span class="string">'From'</span>] = FROM</span><br><span class="line">message_xlsx[<span class="string">'To'</span>] = TO</span><br><span class="line">message_xlsx[<span class="string">'Subject'</span>] = SUBJECT</span><br><span class="line">email_client = smtplib.SMTP_SSL()</span><br><span class="line">email_client.connect(HOST,<span class="string">'465'</span>)</span><br><span class="line">result = email_client.login(FROM,<span class="string">'xxx'</span>)</span><br><span class="line">print(<span class="string">"登录结果："</span>,result)</span><br><span class="line">email_client.sendmail(FROM,TO,message_xlsx.as_string())</span><br><span class="line">email_client.close()</span><br></pre></td></tr></table></figure></p><p>4.发送图片<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">"smtp.qq.com"</span></span><br><span class="line">FROM = <span class="string">"XXX@qq.com"</span></span><br><span class="line">TO = <span class="string">'XX@qq.com'</span></span><br><span class="line"></span><br><span class="line">message = MIMEMultipart(<span class="string">'related'</span>)</span><br><span class="line"></span><br><span class="line">message_text = MIMEText(<span class="string">'&lt;h1 style="color:blue;font-size=100px"&gt;中午一起吃鸡&lt;/h1&gt;&lt;img src="cid:big"&gt;'</span>,<span class="string">'html'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line">message.attach(message_text)</span><br><span class="line"><span class="comment"># ---------添加图片</span></span><br><span class="line">img_data = open(<span class="string">'timg.gif'</span>,<span class="string">'rb'</span>)</span><br><span class="line"><span class="comment"># 设置读取获取的二进制数据</span></span><br><span class="line">message_img = MIMEImage(img_data.read())</span><br><span class="line">img_data.close()</span><br><span class="line"><span class="comment"># 将图片添加到文本中去</span></span><br><span class="line">message_img.add_header(<span class="string">'Content-ID'</span>,<span class="string">'big'</span>)</span><br><span class="line">message.attach(message_img)</span><br><span class="line"><span class="comment"># -------------发送图片第二种 与添加附件文件的方式一样</span></span><br><span class="line">message_img = MIMEText(open(<span class="string">'timg.gif'</span>,<span class="string">'rb'</span>).read(),<span class="string">'base64'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line">message_img[<span class="string">'Content-disposition'</span>] = <span class="string">'attachment;filename="happy.gif"'</span></span><br><span class="line">message.attach(message_img)</span><br><span class="line"></span><br><span class="line">message[<span class="string">'From'</span>] = FROM</span><br><span class="line">message[<span class="string">'To'</span>] = TO</span><br><span class="line">message[<span class="string">'Subject'</span>] = SUBJECT</span><br><span class="line"></span><br><span class="line">email_client = smtplib.SMTP_SSL()</span><br><span class="line">email_client.connect(HOST,<span class="string">'465'</span>)</span><br><span class="line">result = email_client.login(FROM,<span class="string">'xxx'</span>)</span><br><span class="line">print(<span class="string">"登录结果："</span>,result)</span><br><span class="line">email_client.sendmail(FROM,TO,message.as_string())</span><br><span class="line">email_client.close()</span><br></pre></td></tr></table></figure></p><p>5.群发邮件</p><p>只需要修改收件人字段和sendmail里面的TO字段，如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TO = <span class="string">'xxxxx@163.com,xxx@qq.com'</span></span><br><span class="line"></span><br><span class="line">email_client.sendmail(FROM,TO.split(<span class="string">','</span>),message.as_string())</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/16.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="smtp" scheme="https://acczmt.top/tags/smtp/"/>
    
      <category term="email" scheme="https://acczmt.top/tags/email/"/>
    
  </entry>
  
  <entry>
    <title>安装mySQL版本5.6.41.0</title>
    <link href="https://acczmt.top/2018/08/09/%E5%AE%89%E8%A3%85mySQL%E7%89%88%E6%9C%AC5.6/"/>
    <id>https://acczmt.top/2018/08/09/安装mySQL版本5.6/</id>
    <published>2018-08-09T13:30:00.000Z</published>
    <updated>2018-08-10T00:51:41.744Z</updated>
    
    <content type="html"><![CDATA[<p>下载mySQL版本5.6.41.0可以从<a href="https://dev.mysql.com/downloads/windows/installer/5.6.html" target="_blank" rel="noopener">官网</a>下载，也可以选择百度云盘<a href="https://pan.baidu.com/s/1gu3c3xdZUvW2AilnhfZ--Q" target="_blank" rel="noopener">链接</a>密码：habz</p><p>下载完成后直接点击安装，下面为安装步骤：</p><ul><li><p>1.进入第一个界面，点击I accept license terms, 然后点击next</p></li><li><p>2.此时进入下个界面，根据个人需求选择不同的选项，这里选择Developer Default，点击next</p></li></ul><p><img src="/img/mysql/1.jpg" alt="Developer Default"></p><ul><li>3.直接点击next,会弹出一个提示框，点击Yes</li></ul><p><img src="/img/mysql/3.jpg" alt="MySQL Install"></p><ul><li>4.点击Execute,等待下载插件,完成之后点击finish</li></ul><p><img src="/img/mysql/4.jpg" alt="Installation"></p><ul><li>5.一路点击next,直到配置密码，密码根据需要配置如：123456</li></ul><p><img src="/img/mysql/7.jpg" alt="Password"></p><ul><li>6.点击next,至下面界面，点击Execute,安装完成后点击finish</li></ul><p><img src="/img/mysql/8.jpg" alt="Apply Configuration"></p><ul><li>7.一路点击next,在下图Password中输入第五步设置的密码，完成后点击next</li></ul><p><img src="/img/mysql/9.jpg" alt="input password"></p><ul><li>8.点击Execute，等待安装,完成之后点击finish</li></ul><p><img src="/img/mysql/11.png" alt="Apply Configuration"></p><ul><li>9.最后出现以下界面</li></ul><p><img src="/img/mysql/12.png" alt="Apply Configuration"></p><ul><li>10.点击Local instance MySQL56 输入设置的密码进入workbench中</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;下载mySQL版本5.6.41.0可以从&lt;a href=&quot;https://dev.mysql.com/downloads/windows/installer/5.6.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官网&lt;/a&gt;下载，也可以选择百度云
      
    
    </summary>
    
    
      <category term="mySQL" scheme="https://acczmt.top/tags/mySQL/"/>
    
  </entry>
  
  <entry>
    <title>pymysql存储中文数据出错解决方法</title>
    <link href="https://acczmt.top/2018/08/08/pymysql%E5%AD%98%E5%82%A8%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE%E5%87%BA%E9%94%99%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>https://acczmt.top/2018/08/08/pymysql存储中文数据出错解决方法/</id>
    <published>2018-08-08T14:30:00.000Z</published>
    <updated>2018-08-16T02:59:21.735Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/17.jpg?imageView2/2/h/600"><br></div><h2 id="pymysql存储中文数据出错解决方法"><a href="#pymysql存储中文数据出错解决方法" class="headerlink" title="pymysql存储中文数据出错解决方法"></a>pymysql存储中文数据出错解决方法</h2><ul><li><p>错误类型：<code>pymysql.err.InternalError: (1366, &quot;Incorrect string value: &#39;\\xE5\\x82\\xB2\\xE5\\xA8\\x87...&#39; for column &#39;name&#39; at row 1&quot;)</code></p></li><li><p>原因为不能把中文存入数据库：但是代码中也添加了charset=”utf8”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">    self.conn = pymysql.connect(host=<span class="string">'localhost'</span>,port=<span class="number">3306</span>,user=<span class="string">'root'</span>,</span><br><span class="line">                                password=<span class="string">'123456'</span>,db=<span class="string">"hongxiudb"</span>,charset=<span class="string">'utf8'</span>)</span><br><span class="line">    self.cursor = self.conn.cursor()</span><br></pre></td></tr></table></figure></li><li><p>之后我将charset改为了charset=”utf-8”，结果还是不如人意，继续出错：</p></li><li><p><code>AttributeError: &#39;NoneType&#39; object has no attribute &#39;encoding&#39;</code></p></li><li><p>找到了自己的原因为创建数据表时没有指定charset。</p></li><li><p><code>解决方法为：</code></p></li><li><p>创建数据表时指定charset=utf8，如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> hongxiudb;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> hongxiu(</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">text</span>,</span><br><span class="line">author <span class="built_in">text</span>,</span><br><span class="line">intro <span class="built_in">text</span></span><br><span class="line">)<span class="keyword">engine</span>=<span class="keyword">InnoDB</span> <span class="keyword">default</span> <span class="keyword">charset</span>=utf8;</span><br></pre></td></tr></table></figure></li><li><p>连接数据代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">    self.conn = pymysql.connect(host=<span class="string">'localhost'</span>,port=<span class="number">3306</span>,user=<span class="string">'root'</span>,</span><br><span class="line">                                password=<span class="string">'123456'</span>,db=<span class="string">"hongxiudb"</span>,charset=<span class="string">'utf8'</span>)</span><br><span class="line">    self.cursor = self.conn.cursor()</span><br></pre></td></tr></table></figure></li><li><p>最后程序完美的执行结束。</p></li><li><p>出错原因还是因为自己不细心，没有好的编码规范。下次一定要将代码写全，不要因为少写几句代码而出错耽误更多的时间。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/17.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="python" scheme="https://acczmt.top/tags/python/"/>
    
      <category term="pymysql" scheme="https://acczmt.top/tags/pymysql/"/>
    
  </entry>
  
  <entry>
    <title>scrapy + json保存</title>
    <link href="https://acczmt.top/2018/08/07/scrapy+json%E4%BF%9D%E5%AD%98/"/>
    <id>https://acczmt.top/2018/08/07/scrapy+json保存/</id>
    <published>2018-08-07T14:23:00.000Z</published>
    <updated>2018-08-16T03:00:18.360Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/18.jpg?imageView2/2/h/600"><br></div><h3 id="本篇博客目的："><a href="#本篇博客目的：" class="headerlink" title="* 本篇博客目的："></a>* 本篇博客目的：</h3><p>练习使用scrapy，并将获取的信息存储为json格式，以获取<a href="http://www.hongxiu.com/all?gender=2&amp;catId=-1" target="_blank" rel="noopener">红袖小说</a>信息为例</p><ul><li><strong>在命令行新建一个项目</strong>  </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject hongxiu</span><br><span class="line">cd hongxiu</span><br><span class="line">scrapy genspider novel www.hongxiu.com</span><br></pre></td></tr></table></figure><ul><li><strong>打开编辑器修改items.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HongxiuItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    img_src = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    novel_type = scrapy.Field()</span><br><span class="line">    vip = scrapy.Field()</span><br><span class="line">    total_word = scrapy.Field()</span><br><span class="line">    total_collect = scrapy.Field()</span><br><span class="line">    total_click = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure><ul><li><strong>spiders/novel.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> HongxiuItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NovelSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'novel'</span></span><br><span class="line">    allowed_domains = [<span class="string">'www.hongxiu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.hongxiu.com/all?gender=2&amp;catId=-1'</span>]</span><br><span class="line">    base_url = <span class="string">'http://www.hongxiu.com'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        <span class="string">"""获取分类的Id，每个分类的第一页链接"""</span></span><br><span class="line">        type_list_url = response.xpath(<span class="string">'//ul[@type="category"]/li/a/@href'</span>).extract()</span><br><span class="line">        catid = response.xpath(<span class="string">'//ul[@type="category"]/li/@data-id'</span>).extract()</span><br><span class="line">        <span class="keyword">del</span> type_list_url[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">del</span> catid[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> x,t <span class="keyword">in</span> zip(type_list_url,catid):</span><br><span class="line">            url = self.base_url + x</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url,meta=&#123;<span class="string">"type"</span>:t&#125;,callback=self.get_content_with_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content_with_url</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        <span class="string">"""获取十个分类的前十页链接"""</span></span><br><span class="line">        <span class="keyword">for</span> page_num <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</span><br><span class="line">            catId = response.meta[<span class="string">'type'</span>]</span><br><span class="line">            url = <span class="string">f"https://www.hongxiu.com/all?pageNum=<span class="subst">&#123;page_num&#125;</span>&amp;pageSize=10&amp;gender=2&amp;catId=<span class="subst">&#123;catId&#125;</span>&amp;isFinish=-1&amp;isVip=-1&amp;size=-1&amp;updT=-1&amp;orderBy=0"</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url,callback=self.get_novel_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_novel_url</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""获取小说的详情链接"""</span></span><br><span class="line">        novel_url_list = response.xpath(<span class="string">'//div[@class="book-info"]/h3/a/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> novel_url <span class="keyword">in</span> novel_url_list:</span><br><span class="line">            url = self.base_url + novel_url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.get_novel_detail_info)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_novel_detail_info</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""获取小说信息"""</span></span><br><span class="line">        <span class="comment"># 注意：response.xpath('//div[@class="book-img"]/a/img/@src').extract()[0]获取到的src值后面有一个\r,所以使用replace('\r', '')</span></span><br><span class="line">        img_src = <span class="string">'https:'</span> + response.xpath(<span class="string">'//div[@class="book-img"]/a/img/@src'</span>).extract()[<span class="number">0</span>].replace(<span class="string">'\r'</span>, <span class="string">''</span>)</span><br><span class="line">        title = response.xpath(<span class="string">'//h1/em/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        author = response.xpath(<span class="string">'//h1/a/text()'</span>).extract()[<span class="number">0</span>].split()[<span class="number">0</span>]</span><br><span class="line">        tags = response.xpath(<span class="string">'//p[@class="tag-box"]/span[@class="tag"]'</span>)[<span class="number">0</span>]</span><br><span class="line">        novel_type = tags.xpath(<span class="string">'//i[@class="blue"]/text()'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">        vip = tags.xpath(<span class="string">'//i[@class="org"]/text()'</span>).extract()</span><br><span class="line">        vip = <span class="string">"免费"</span> <span class="keyword">if</span> len(vip) == <span class="number">0</span> <span class="keyword">else</span> vip[<span class="number">0</span>]</span><br><span class="line">        total_word = response.xpath(<span class="string">'//p[@class="total"]/span[1]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        total_collect = response.xpath(<span class="string">'//p[@class="total"]/span[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        total_click = response.xpath(<span class="string">'//p[@class="total"]/span[last()]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        content = <span class="string">''</span></span><br><span class="line">        content_list = response.xpath(<span class="string">'//div[@class="book-information cf"]//p[@class="intro"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> con <span class="keyword">in</span> content_list:</span><br><span class="line">            content += con</span><br><span class="line"></span><br><span class="line">        item = HongxiuItem()</span><br><span class="line">        item[<span class="string">'img_src'</span>] = [img_src]</span><br><span class="line">        item[<span class="string">"title"</span>] = title</span><br><span class="line">        item[<span class="string">"author"</span>] = author</span><br><span class="line">        item[<span class="string">"novel_type"</span>] = novel_type</span><br><span class="line">        item[<span class="string">'vip'</span>] = vip</span><br><span class="line">        item[<span class="string">"total_word"</span>] = total_word</span><br><span class="line">        item[<span class="string">"total_collect"</span>] = total_collect</span><br><span class="line">        item[<span class="string">"total_click"</span>] = total_click</span><br><span class="line">        item[<span class="string">"content"</span>] = content</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><ul><li><strong>修改pipelines.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用来打开指定文件 并且对文件进行转码 防止出现乱码问题</span></span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XiaoshuoPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># w+ ,r+ 读写文件</span></span><br><span class="line">        <span class="comment"># 前者读写文件 如果文件不存在 则创建</span></span><br><span class="line">        <span class="comment"># 后者读写文件 如果文件不存在 则抛出异常</span></span><br><span class="line">        self.file = codecs.open(filename=<span class="string">'book.json'</span>,mode=<span class="string">'w+'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment">#     如果想要将数据写入本地或者是使用数据库的时候，这个方法需要保留</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="string">"""spider打开时（处理数据前）回调该方法，</span></span><br><span class="line"><span class="string">        通常该方法用于在开始处理数据之前，完成某些初始化工作"""</span></span><br><span class="line">        self.file.write(<span class="string">'&#123;"list":['</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="string">"""spider关闭时（处理数据后）回调该方法，</span></span><br><span class="line"><span class="string">        通常该方法用于在处理完所有数据之后，完成某些清理工作"""</span></span><br><span class="line">        print(<span class="string">"爬虫结束了"</span>)</span><br><span class="line">        self.file.seek(<span class="number">-1</span>,os.SEEK_END)</span><br><span class="line">        self.file.truncate()</span><br><span class="line">        self.file.seek(<span class="number">-1</span>,os.SEEK_END)</span><br><span class="line">        self.file.truncate()</span><br><span class="line">        self.file.write(<span class="string">']&#125;'</span>)</span><br><span class="line">        self.file.close()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># dumps 将字典对象转化为字符串  ASCII编码是否可用</span></span><br><span class="line">        <span class="comment"># 如果 直接将字典形式的数据写入文件当中 会发生错误</span></span><br><span class="line">        <span class="comment"># 所以需要将字典形式的值 转化成字符串的格式写入文件当中</span></span><br><span class="line">        result = json.dumps(dict(item),ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">        self.file.write(result)</span><br><span class="line">        self.file.write(<span class="string">",\n"</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>settings.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'hongxiu.pipelines.HongxiuPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>在spiders文件下新建main.py文件，添加内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl novel'</span>.split())</span><br></pre></td></tr></table></figure><ul><li><strong>最后右键运行main.py文件即可,运行结束之后会生成一个book.json文件</strong></li><li><strong>验证是否为json文件，将book.json文件拖入火狐浏览器查看，如下所示即为成功</strong><br><img src="/img/sucai/json验证.jpg" alt="json验证"></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/18.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>scrapy实现下载图片</title>
    <link href="https://acczmt.top/2018/08/07/scrapy%E7%BB%83%E4%B9%A0/"/>
    <id>https://acczmt.top/2018/08/07/scrapy练习/</id>
    <published>2018-08-07T11:30:20.000Z</published>
    <updated>2018-08-16T03:00:27.701Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/19.jpg?imageView2/2/h/600"><br></div></p><h3 id="本篇博客目的："><a href="#本篇博客目的：" class="headerlink" title="* 本篇博客目的："></a>* 本篇博客目的：</h3><p>练习使用scrapy，获取站长素材中的所有<a href="http://sc.chinaz.com/tubiao/" target="_blank" rel="noopener">图标</a>图片,并重写ImagesPipeline，实现分类保存</p><ul><li><strong>在命令行新建一个项目</strong>  </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject zhanzhangsucai</span><br><span class="line">cd zhanzhangsucai</span><br><span class="line">scrapy genspider chinaz sc.chinaz.com</span><br></pre></td></tr></table></figure><ul><li><strong>打开编辑器修改items.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhanzhangsucaiItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    src = scrapy.Field()</span><br></pre></td></tr></table></figure><ul><li><strong>spiders/chinaz.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> ZhanzhangsucaiItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChinazSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'chinaz'</span></span><br><span class="line">    allowed_domains = [<span class="string">'sc.chinaz.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://sc.chinaz.com/tubiao/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""获取所有图片"""</span></span><br><span class="line">        href_list = response.xpath(<span class="string">'//li/span/a/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> href_list:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=href,callback=self.get_detail_img_url)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取下一页</span></span><br><span class="line">        next_page = response.xpath(<span class="string">'//a[@class="nextpage"]/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">if</span> len(next_page) != <span class="number">0</span>:</span><br><span class="line">            next_url = <span class="string">'http://sc.chinaz.com/tubiao/'</span> + next_page[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_detail_img_url</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        title = response.xpath(<span class="string">'//div[@class="text_wrap"]/h2/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        srcs = response.xpath(<span class="string">'//div[@class="png_pic"]/img/@src'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> src <span class="keyword">in</span> srcs:</span><br><span class="line">            item = ZhanzhangsucaiItem()</span><br><span class="line">            item[<span class="string">'title'</span>] = title</span><br><span class="line">            item[<span class="string">'src'</span>] = [src]</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><ul><li><strong>pipelines.py文件,删除原来的内容，添加新的内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IconPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="comment"># for src in item['src']:</span></span><br><span class="line">        src = item[<span class="string">'src'</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=src,meta=&#123;<span class="string">'item'</span>:item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 管道里面提供了一系列的内置方法，这些方法会自动从第一个执行到最后一个</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line"></span><br><span class="line">        item = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        title = item[<span class="string">'title'</span>]</span><br><span class="line">        src = item[<span class="string">'src'</span>][<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># for index,src in enumerate(srcs):</span></span><br><span class="line">        path = <span class="string">'%s/%s.ico'</span> % (title,src)</span><br><span class="line">        <span class="keyword">return</span> path</span><br></pre></td></tr></table></figure><ul><li><strong>settings.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'zhanzhangsucai.pipelines.IconPipeline'</span>: <span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE = <span class="string">'../imgs'</span></span><br></pre></td></tr></table></figure><ul><li><strong>在spiders文件下新建main.py文件，添加内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl chinaz'</span>.split())</span><br></pre></td></tr></table></figure><ul><li><strong>最后右键运行main.py文件即可，图片最少有14万张，比较费时</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/19.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>selenium获取美食杰信息</title>
    <link href="https://acczmt.top/2018/08/02/selenium%E8%8E%B7%E5%8F%96%E7%BE%8E%E9%A3%9F%E6%9D%B0%E4%BF%A1%E6%81%AF/"/>
    <id>https://acczmt.top/2018/08/02/selenium获取美食杰信息/</id>
    <published>2018-08-01T20:10:20.000Z</published>
    <updated>2018-08-16T03:01:03.704Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/21.jpg?imageView2/2/h/600"><br></div><ul><li><p>学习目的：练习selenium的用法，获取<a href="http://www.meishij.net/" target="_blank" rel="noopener">美食杰</a>—&gt;菜谱大全—&gt;<a href="https://www.meishij.net/chufang/diy/zaocan/" target="_blank" rel="noopener">早餐</a> 页面中的菜名以及作者名，保存到TXT文件中</p></li><li><p>1、首先引入所需要的包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.common.action_chains <span class="keyword">import</span> ActionChains <span class="comment">#模拟鼠标</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure></li><li><p>2、打开美食杰的首页，隐式等待十秒，等待页面加载完成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'https://www.meishij.net/'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></li><li><p>3、通过查找到&lt;菜谱大全&gt;在网页中的位置，模拟鼠标移动到&lt;菜谱大全&gt;上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cai_pu = driver.find_element_by_css_selector(<span class="string">'li.hasmore a.link.pngFix'</span>)</span><br><span class="line">ActionChains(driver).move_to_element(cai_pu).perform()</span><br></pre></td></tr></table></figure></li><li><p>4、找到&lt;早餐&gt;,并自动点击跳转到&lt;早餐&gt;页面上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_link_text(<span class="string">'早餐'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></li><li><p>5、模拟鼠标下拉滑动条</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用js控制滑动条</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">7</span>,<span class="number">2</span>):</span><br><span class="line">    x = float(row) / <span class="number">6</span></span><br><span class="line">    js = <span class="string">'document.documentElement.scrollTop = document.documentElement.scrollHeight * %f'</span>%x</span><br><span class="line">    driver.execute_script(js)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p>6、获取早餐美食的信息，保存到meishijie.txt 文件中</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">info_lists = driver.find_elements_by_css_selector(<span class="string">'div.c1'</span>)</span><br><span class="line"><span class="keyword">for</span> info <span class="keyword">in</span> info_lists:</span><br><span class="line">    name = info.find_element_by_tag_name(<span class="string">'strong'</span>).text</span><br><span class="line">    author = info.find_element_by_tag_name(<span class="string">'em'</span>).text</span><br><span class="line">    <span class="comment"># print(name + "--&gt;" +author)</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'meishijie.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(name+<span class="string">"--&gt;"</span>+author+<span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure><ul><li>7、以下是完整代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.common.action_chains <span class="keyword">import</span> ActionChains <span class="comment">#模拟鼠标</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'https://www.meishij.net/'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">cai_pu = driver.find_element_by_css_selector(<span class="string">'li.hasmore a.link.pngFix'</span>)</span><br><span class="line">ActionChains(driver).move_to_element(cai_pu).perform()</span><br><span class="line">driver.find_element_by_link_text(<span class="string">'早餐'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#只获取前三页数据，要获取多页只需修改range值</span></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>):</span><br><span class="line">    print(<span class="string">f"正在获取第<span class="subst">&#123;page&#125;</span>页"</span>)</span><br><span class="line">    <span class="comment"># 使用js控制滑动条</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">7</span>,<span class="number">2</span>):</span><br><span class="line">        x = float(row) / <span class="number">6</span></span><br><span class="line">        js = <span class="string">'document.documentElement.scrollTop = document.documentElement.scrollHeight * %f'</span>%x</span><br><span class="line">        driver.execute_script(js)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    info_lists = driver.find_elements_by_css_selector(<span class="string">'div.c1'</span>)</span><br><span class="line">    <span class="keyword">for</span> info <span class="keyword">in</span> info_lists:</span><br><span class="line">        name = info.find_element_by_tag_name(<span class="string">'strong'</span>).text</span><br><span class="line">        author = info.find_element_by_tag_name(<span class="string">'em'</span>).text</span><br><span class="line">        <span class="comment"># print(name + "--&gt;" +author)</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'meishijie.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(name+<span class="string">"--&gt;"</span>+author+<span class="string">"\n"</span>)</span><br><span class="line">    <span class="comment"># 点击下一页链接</span></span><br><span class="line">    next_page = driver.find_element_by_class_name(<span class="string">'next'</span>)</span><br><span class="line">    <span class="keyword">if</span> next_page:</span><br><span class="line">        next_page.click()</span><br><span class="line">    <span class="keyword">else</span>:print(<span class="string">"已经最后一页了"</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">driver.quit()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/21.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>selenium基础用法</title>
    <link href="https://acczmt.top/2018/08/02/selenium%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/"/>
    <id>https://acczmt.top/2018/08/02/selenium基础用法/</id>
    <published>2018-08-01T19:30:20.000Z</published>
    <updated>2018-08-16T03:01:21.049Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/22.jpg?imageView2/2/h/600"><br></div><ul><li><p>在上篇笔记中已经写下如何安装selenium以及配置浏览器驱动，传送门<a href="https://acczmt.top/2018/07/31/selenium%E5%AE%89%E8%A3%85/#more">selenium 安装</a>,下面会介绍selenium的基础用法。</p></li><li><p>以百度链接为例，由于selenium加载受到网速的影响，所以网速差运行可能会较慢或者出错</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="1、查找元素的方法"><a href="#1、查找元素的方法" class="headerlink" title="1、查找元素的方法"></a>1、查找元素的方法</h2><ul><li><p>selenium提供了查找元素的方法 find_<figure class="highlight plain"><figcaption><span>和find_```elements```_by_XXX,注意这两种的区别，一个后面有s,一个没有s。这个问题很容易就出错。</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* find_```element```_by_XXX 表示查找第一个符合条件的元素</span><br><span class="line">```python</span><br><span class="line"># driver.find_element_by_class_name() 根据标签中的class属性进行查找</span><br><span class="line"># driver.find_element_by_id() 根据标签中的id属性进行查找</span><br><span class="line"># driver.find_element_by_name()  根据标签中的name属性进行查找</span><br><span class="line"># driver.find_element_by_tag_name() 根据标签名进行查找</span><br><span class="line"># driver.find_element_by_css_selector()  根据css选择器进行查找</span><br><span class="line"># driver.find_element_by_xpath()  根据xpath语法进行查找</span><br><span class="line"># driver.find_element_by_link_text()  根据链接中的文本内容进行查找</span><br><span class="line"># driver.find_element_by_partial_link_text()  根据链接中的部分文本内容进行查找</span><br></pre></td></tr></table></figure></p></li><li><p>find_<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* 获取文本框的id属性值，在网页中定位到文本框的位置，清空文本框中的值，然后在输入selenium，如下所示：</span><br><span class="line">```python</span><br><span class="line">driver.find_element_by_id(&apos;kw&apos;).clear() #clear() 表示清空当前文本框的值</span><br><span class="line">driver.find_element_by_id(&apos;kw&apos;).send_keys(&apos;selenium&apos;) #send_keys()表示在文本框中输入内容</span><br></pre></td></tr></table></figure></p></li><li><p>定位到该按钮的位置，然后模拟点击</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_id(<span class="string">'su'</span>).click()  <span class="comment">#click() 表示点击一次</span></span><br></pre></td></tr></table></figure></li><li><p>简单的模拟浏览器就完成啦，接下来学习各个查找元素方法的使用</p></li><li><p>以获取百度首页中的新闻为例，各种方法的使用如下，如果想使用哪种需要解注释，然后将其它注释掉即可</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)  <span class="comment">#隐式等待十秒 </span></span><br><span class="line"> </span><br><span class="line">driver.find_element_by_class_name(<span class="string">'mnav'</span>).click()</span><br><span class="line"><span class="comment"># driver.find_element_by_name("tj_trnews").click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_css_selector('#u1 a').click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_xpath('//div[@id="u1"]/a').click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_link_text('新闻').click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_partial_link_text('新').click()</span></span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br><span class="line">driver.close() <span class="comment">#关闭窗口</span></span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">driver.quit()  <span class="comment">#关闭浏览器</span></span><br></pre></td></tr></table></figure><h2 id="2、获取属性值与文本内容"><a href="#2、获取属性值与文本内容" class="headerlink" title="2、获取属性值与文本内容"></a>2、获取属性值与文本内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)  <span class="comment">#隐式等待十秒</span></span><br><span class="line"> </span><br><span class="line">content = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).text <span class="comment">#获取文本text的值 </span></span><br><span class="line">print(content)</span><br><span class="line">name_attr = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).get_attribute(<span class="string">'name'</span>) <span class="comment">#获取name属性值</span></span><br><span class="line">print(name_attr)</span><br><span class="line">class_attr = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).get_attribute(<span class="string">'class'</span>)  <span class="comment">#获取class属性值</span></span><br><span class="line">print(class_attr)</span><br><span class="line">href_attr = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).get_attribute(<span class="string">'href'</span>)  <span class="comment">#获取href属性值</span></span><br><span class="line">print(href_attr)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出结果为：</span></span><br><span class="line"><span class="comment"># 新闻</span></span><br><span class="line"><span class="comment"># tj_trnews</span></span><br><span class="line"><span class="comment"># mnav</span></span><br><span class="line"><span class="comment"># http://news.baidu.com/</span></span><br></pre></td></tr></table></figure><h2 id="3、window切换"><a href="#3、window切换" class="headerlink" title="3、window切换"></a>3、window切换</h2><ul><li>主要练习对窗口的切换，代码中有注释</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Chrome()  <span class="comment">#个人火狐浏览器加载不出来，所以使用谷歌</span></span><br><span class="line">driver.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取当前的window对象</span></span><br><span class="line">current_win = driver.current_window_handle</span><br><span class="line"><span class="comment"># current_win 当前网页的编号 driver.title 网页标题</span></span><br><span class="line">print(current_win,driver.title)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 点击首页新闻链接</span></span><br><span class="line">driver.find_element_by_link_text(<span class="string">'新闻'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 找到第一篇文章，然后点击查看</span></span><br><span class="line">driver.find_element_by_css_selector(<span class="string">'li.hdline0 a'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 此时浏览器会有两个窗口</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取所有的窗口</span></span><br><span class="line">all_windows = driver.window_handles</span><br><span class="line"><span class="comment"># 判断</span></span><br><span class="line"><span class="keyword">for</span> window <span class="keyword">in</span> all_windows:</span><br><span class="line">    <span class="keyword">if</span> window != current_win:</span><br><span class="line">        <span class="comment"># 切换到第二个窗口</span></span><br><span class="line">        driver.switch_to.window(window)</span><br><span class="line"><span class="comment"># 获取新闻标题 并输出，验证是否切换成功</span></span><br><span class="line">title = driver.find_element_by_css_selector(<span class="string">'.text_title h1'</span>).text</span><br><span class="line">print(title)</span><br><span class="line"><span class="comment"># 关闭当前窗口，即关闭新闻详细页面的窗口</span></span><br><span class="line">driver.close()</span><br><span class="line"><span class="comment"># 切换到新闻首页窗口</span></span><br><span class="line">driver.switch_to.window(current_win)</span><br><span class="line"><span class="comment"># 输出一条信息，验证是否切换成功</span></span><br><span class="line">print(driver.find_element_by_css_selector(<span class="string">'#footer span'</span>).text)</span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">driver.quit()</span><br></pre></td></tr></table></figure><h3 id="学习到这里只是selenium的冰山一角，更多功能还会继续学习"><a href="#学习到这里只是selenium的冰山一角，更多功能还会继续学习" class="headerlink" title="学习到这里只是selenium的冰山一角，更多功能还会继续学习"></a>学习到这里只是selenium的冰山一角，更多功能还会继续学习</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/22.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>selenium安装</title>
    <link href="https://acczmt.top/2018/07/31/selenium%E5%AE%89%E8%A3%85/"/>
    <id>https://acczmt.top/2018/07/31/selenium安装/</id>
    <published>2018-07-31T13:50:20.000Z</published>
    <updated>2018-08-16T03:00:52.311Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/23.jpg?imageView2/2/h/600"><br></div><h2 id="selenium-是一个自动化测试工具"><a href="#selenium-是一个自动化测试工具" class="headerlink" title="selenium 是一个自动化测试工具"></a>selenium 是一个自动化测试工具</h2><h2 id="selenium的特点："><a href="#selenium的特点：" class="headerlink" title="selenium的特点："></a>selenium的特点：</h2><ul><li>1.由程序控制浏览器进行操作，而不是手动操作浏览器</li><li>2.程序控制浏览器进行操作的时候，速度非常慢，所以要谨慎使用selenium</li><li>3.使用selenium控制浏览器的时候，需要下载浏览器对应的驱动程序</li><li>4.selenium为开源，免费，但是更新速度没有浏览器快，不是selenium<br>  更新慢，而是浏览器更新快，要注意selenium和浏览器之间的对应关系</li></ul><p>windows安装可以采用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure></p><p>如果电脑同时安装了python3 和python2 把pip 改成pip3 或者pip2 就可以了</p><p>然后我们创建一个py文件，使用selenium  <code>注意：文件名一定不要和python包的名字相同，否则会报错</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">'kw'</span>).send_keys(<span class="string">'selenium'</span>)</span><br></pre></td></tr></table></figure></p><p>运行发现会报错，因为我们没有安装浏览器驱动，下载之前先检查谷歌和火狐浏览器的版本，然后根据版本号下载对应的驱动。</p><p>可以从该<a href="http://chromedriver.chromium.org/downloads" target="_blank" rel="noopener">chromedriver</a>网站下载对应chromedriver的驱动,从<a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">geckodriver</a>下载对应版本的驱动。</p><p>下载完之后将两个压缩包解压，将两个 [ .exe ] 文件放到python同级目录下，与python.exe文件平级即可，比如我的文件路径为 D:\python\Anaconda ，只需要将两个[ .exe ] 文件放到该目录下</p><p>再次运行上面代码，如果出现错误将编译器关闭，重新打开。</p><p>如果出现下面错误，可能是因为网速慢，页面还没有加载出来，程序就执行完毕，导致获取不到element元素<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">selenium.common.exceptions.NoSuchElementException:Message: Unable to locate element: [id=&quot;kw&quot;]</span><br></pre></td></tr></table></figure></p><p>解决办法：可以让程序隐式等待10秒，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>) <span class="comment">#程序隐式等待10秒</span></span><br><span class="line">driver.find_element_by_id(<span class="string">'kw'</span>).send_keys(<span class="string">'selenium'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="无头浏览器PhantomJS的安装"><a href="#无头浏览器PhantomJS的安装" class="headerlink" title="无头浏览器PhantomJS的安装"></a>无头浏览器PhantomJS的安装</h3><p>首先下载<a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">PhantomJS</a><br>第一种</p><ul><li>下载完成后，放到合适的文件夹下解压，将其路径添加到环境变量中，路径如：D:\python\phantomjs-2.1.1-windows\bin<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">driver = webdriver.PhantomJS(executable_path=<span class="string">r'D:\python\phantomjs-2.1.1-windows\bin\phantomjs.exe'</span>)</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></li></ul><p>第二种</p><ul><li>下载完成后，解压，将phantomjs.exe放到与python.exe同级目录下，与python.exe文件平级即可<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">driver = webdriver.PhantomJS()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></li></ul><p>个人推荐使用第二种，比较方便</p>]]></content>
    
    <summary type="html">
    
      python学习
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>奇书网小说信息</title>
    <link href="https://acczmt.top/2018/07/31/%E5%A5%87%E4%B9%A6%E7%BD%91%E5%B0%8F%E8%AF%B4%E4%BF%A1%E6%81%AF/"/>
    <id>https://acczmt.top/2018/07/31/奇书网小说信息/</id>
    <published>2018-07-30T16:20:20.000Z</published>
    <updated>2018-08-16T03:02:08.248Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/24.jpg?imageView2/2/h/600"><br></div></p><h2 id="获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据"><a href="#获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据" class="headerlink" title="获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据"></a>获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据</h2><p>运行效果如下所示:<br><img src="/assets/img/奇书网.png" alt="效果图" title="效果图展示"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># url = "https://www.qisuu.la/soft/sort01/index_1.html"</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QiShuWang</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.base_url = <span class="string">"https://www.qisuu.la"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>:UserAgent().random</span><br><span class="line">        &#125;</span><br><span class="line">        self.work_book = <span class="keyword">None</span></span><br><span class="line">        self.sheet = <span class="keyword">None</span></span><br><span class="line">        self.record = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.open_execl()</span><br><span class="line">        self.get_code_with_url()</span><br><span class="line">        self.work_book.save(<span class="string">"奇书网小说.xls"</span>)</span><br><span class="line">    <span class="comment"># 默认url为第一页</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code_with_url</span><span class="params">(self,url=<span class="string">"/soft/sort01/index_1.html"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""获取网页源码 并获取下一页链接"""</span></span><br><span class="line">        full_url = self.base_url + url</span><br><span class="line">        response = requests.get(full_url,headers=self.headers)</span><br><span class="line">        code = etree.HTML(response.text)</span><br><span class="line">        detail_href = code.xpath(<span class="string">'//div[@class="listBox"]/ul/li/a/@href'</span>)</span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> detail_href:</span><br><span class="line">            novel_url = self.base_url + href</span><br><span class="line">            <span class="comment"># 将获取的小说详情页传递给该函数</span></span><br><span class="line">            self.get_novel_info(novel_url)</span><br><span class="line"></span><br><span class="line">        next_page_element = code.xpath(<span class="string">'//div[@class="tspage"]/a[last()-1]'</span>)[<span class="number">0</span>]</span><br><span class="line">        next_page = next_page_element.get(<span class="string">'href'</span>)</span><br><span class="line">        print(next_page)</span><br><span class="line">        text = next_page_element.xpath(<span class="string">'.//text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> text != <span class="string">"下一页"</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 循环调用该函数 直到不满足条件为止</span></span><br><span class="line">        self.get_code_with_url(next_page)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_novel_info</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        <span class="string">"""获取小说的信息 并保存到Excel中"""</span></span><br><span class="line">        info_list = <span class="keyword">None</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        response.encoding=<span class="string">"utf-8"</span></span><br><span class="line">        code = etree.HTML(response.text)</span><br><span class="line">        novel_name = code.xpath(<span class="string">'//div[@class="detail_right"]/h1/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        info = code.xpath(<span class="string">'//div[@class="detail_right"]/ul/li[@class="small"]/text()'</span>)[:<span class="number">-1</span>]</span><br><span class="line">        click_num = info[<span class="number">0</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        file_size = info[<span class="number">1</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        book_type = info[<span class="number">2</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        update_time = info[<span class="number">3</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        state = info[<span class="number">4</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        author = info[<span class="number">5</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        novel_intro = code.xpath(<span class="string">'//div[@class="showInfo"]/p/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        download = code.xpath(<span class="string">'//div[@class="showDown"]/ul/li[last()]/script/text()'</span>)[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">1</span>].replace(<span class="string">"'"</span>,<span class="string">""</span>)</span><br><span class="line">        info_list = [novel_name,click_num, file_size, book_type, update_time, state, author,novel_intro,download]</span><br><span class="line">        <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(info_list):</span><br><span class="line">            self.sheet.write(self.record,index,data)</span><br><span class="line">        self.record += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_execl</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""创建一个execl表"""</span></span><br><span class="line">        self.work_book = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        self.sheet = self.work_book.add_sheet(<span class="string">'小说信息'</span>)</span><br><span class="line">        title = [<span class="string">'小说名字'</span>,<span class="string">'点击次数'</span>, <span class="string">'文件大小'</span>, <span class="string">'书籍类型'</span>, <span class="string">'更新日期'</span>, <span class="string">'连载状态'</span>, <span class="string">'书籍作者'</span>,<span class="string">'小说介绍'</span>,<span class="string">'下载地址'</span>]</span><br><span class="line">        <span class="keyword">for</span> i ,data <span class="keyword">in</span> enumerate(title):</span><br><span class="line">            self.sheet.write(<span class="number">0</span>,i,data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    qsw = QiShuWang()</span><br><span class="line">    qsw.start_spider()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/24.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="xpath" scheme="https://acczmt.top/tags/xpath/"/>
    
  </entry>
  
  <entry>
    <title>豆瓣电影top250</title>
    <link href="https://acczmt.top/2018/07/28/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1top250/"/>
    <id>https://acczmt.top/2018/07/28/豆瓣电影top250/</id>
    <published>2018-07-28T08:20:20.000Z</published>
    <updated>2018-08-16T03:01:45.208Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/25.jpg?imageView2/2/h/600"><br></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">""" 豆瓣具有反爬机制，如果出现需登录时 就要先登录获取cookie 使用代理ip能够被检测出来 """</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># 随机一个UserAgent</span></span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouBanMovieTop</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.base_url = <span class="string">"https://movie.douban.com/top250"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>:UserAgent().random,</span><br><span class="line">            <span class="comment"># 模拟cookie 如果报错，需要登录 登录豆瓣账号 将cookie 复制粘贴到此处 如何查找cookie自行搜索</span></span><br><span class="line">            <span class="string">"Cookie"</span>:<span class="string">'将自己的cookie粘贴此处'</span></span><br><span class="line">        &#125;</span><br><span class="line">        self.work_book = <span class="keyword">None</span></span><br><span class="line">        self.sheet = <span class="keyword">None</span></span><br><span class="line">        self.record = <span class="number">1</span>  <span class="comment"># 保存execl的行号</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_load_dbmovie</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""主程序"""</span></span><br><span class="line">        self.get_execl()</span><br><span class="line">        self.get_code_with_url()</span><br><span class="line">        self.work_book.save(<span class="string">"豆瓣Top250.xls"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_execl</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""创建一个execl"""</span></span><br><span class="line">        self.work_book = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        self.sheet = self.work_book.add_sheet(<span class="string">"电影排行top250"</span>)</span><br><span class="line">        title = [<span class="string">'排名'</span>,<span class="string">'电影名'</span>,<span class="string">'导演和演员'</span>,<span class="string">'评分'</span>,<span class="string">'评论人数'</span>]</span><br><span class="line">        <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(title):</span><br><span class="line">            self.sheet.write(<span class="number">0</span>,index,data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code_with_url</span><span class="params">(self,url=<span class="string">''</span>)</span>:</span></span><br><span class="line">        <span class="string">"""获取网页数据并保存到execl中</span></span><br><span class="line"><span class="string">        self.get_code_with_url 与 self.get_next_page 循环调用 直到不满足条件为止"""</span></span><br><span class="line">        full_url = self.base_url+url</span><br><span class="line">        response = requests.get(full_url,headers=self.headers)</span><br><span class="line">        code = etree.HTML(response.text)</span><br><span class="line">        item_div = code.xpath(<span class="string">'//div[@class="item"]'</span>)</span><br><span class="line">        <span class="keyword">for</span> tag <span class="keyword">in</span> item_div:</span><br><span class="line">            data_list = <span class="keyword">None</span></span><br><span class="line">            rank = tag.xpath(<span class="string">'.//em/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">            movie_name = tag.xpath(<span class="string">'.//div[@class="hd"]/a/span/text()'</span>)</span><br><span class="line">            movie_name = <span class="string">""</span>.join(movie_name)</span><br><span class="line">            creater = tag.xpath(<span class="string">'.//div[@class="bd"]/p/text()'</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            star = tag.xpath(<span class="string">'.//div[@class="star"]/span[@class="rating_num"]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">            comment = tag.xpath(<span class="string">'.//div[@class="star"]/span[last()]/text()'</span>)[<span class="number">0</span>][<span class="number">0</span>:<span class="number">-3</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将数据写入execl中</span></span><br><span class="line">            data_list = [rank,movie_name,creater,star,comment]</span><br><span class="line">            <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(data_list):</span><br><span class="line">                self.sheet.write(self.record, index,data)</span><br><span class="line">            self.record += <span class="number">1</span></span><br><span class="line">        self.get_next_page(code)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_next_page</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        <span class="string">"""获取下一页的链接"""</span></span><br><span class="line">        next_page = code.xpath(<span class="string">'//span[@class="next"]/a/@href'</span>)</span><br><span class="line">        <span class="comment"># 判断是否存在下一页 没有则退出  存在则继续执行 self.get_code_with_url(next_page[0])</span></span><br><span class="line">        <span class="keyword">if</span> len(next_page) == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"已经到最后一页了"</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.get_code_with_url(next_page[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个对象并调用方法执行</span></span><br><span class="line">db_movie = DouBanMovieTop()</span><br><span class="line">db_movie.start_load_dbmovie()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/25.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="xpath" scheme="https://acczmt.top/tags/xpath/"/>
    
  </entry>
  
  <entry>
    <title>169we壁纸</title>
    <link href="https://acczmt.top/2018/07/27/169we%E5%A3%81%E7%BA%B8/"/>
    <id>https://acczmt.top/2018/07/27/169we壁纸/</id>
    <published>2018-07-27T14:30:20.000Z</published>
    <updated>2018-08-16T02:58:26.246Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/26.jpg?imageView2/2/h/600"><br></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""根据输入的类别，获取www.169we.com中的所有图片,代码有些累赘 ，可以进行简化"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests,os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># base_url = "http://www.169we.com/diannaobizhi/list_7_1.html"</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pic169Spider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,category)</span>:</span></span><br><span class="line">        self.category = category</span><br><span class="line">        self.base_url = <span class="string">"http://www.169we.com/&#123;&#125;/"</span>.format(self.category)</span><br><span class="line"></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>:UserAgent().random,</span><br><span class="line">            <span class="string">"Host"</span>:<span class="string">"www.169we.com"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        self.img_headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: UserAgent().random,</span><br><span class="line">            <span class="string">"Host"</span>: <span class="string">"724.169pp.net"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        self.dic = &#123;</span><br><span class="line">        <span class="string">"diannaobizhi"</span>:<span class="string">"7"</span>,</span><br><span class="line">        <span class="string">"shoujibizhi"</span>:<span class="string">"6"</span>,</span><br><span class="line">        <span class="string">"wangyouzipai"</span>:<span class="string">"2"</span>,</span><br><span class="line">        <span class="string">"gaogensiwa"</span>:<span class="string">"3"</span>,</span><br><span class="line">        <span class="string">"xiyangmeinv"</span>:<span class="string">"4"</span>,</span><br><span class="line">        <span class="string">"guoneimeinv"</span>:<span class="string">"5"</span>,</span><br><span class="line">        <span class="string">"xingganmeinv"</span>:<span class="string">"1"</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIndexPage</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        <span class="string">"""获取图片分类的总页数"""</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        soup = BeautifulSoup(response.text,<span class="string">"lxml"</span>)</span><br><span class="line">        page_all = soup.select(<span class="string">'body  div.page  ul li a'</span>)</span><br><span class="line">        <span class="keyword">return</span> page_all[<span class="number">-3</span>].get_text()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        <span class="string">"""获取图片的总页数"""</span></span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        response.encoding=<span class="string">"gbk"</span></span><br><span class="line">        total_page = int(re.findall(<span class="string">r'.*?共(.*?)页'</span>,response.text,re.S)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> total_page</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIndexImgHref</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        response.encoding=<span class="string">"gbk"</span></span><br><span class="line">        data = re.findall(<span class="string">r'&lt;li&gt;&lt;a href="(.*?)" class="pic".*?&gt;.*?&lt;p&gt;(.*?)&lt;/p&gt;'</span>,response.text,re.S)</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getImgUrl</span><span class="params">(self,url,dirname,index)</span>:</span></span><br><span class="line">        <span class="string">"""获取图片的src"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(self.category + <span class="string">"/"</span> +dirname):</span><br><span class="line">            os.makedirs(self.category + <span class="string">"/"</span> +dirname)</span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        <span class="comment"># response.encoding = "gbk"</span></span><br><span class="line">        img_urls = re.findall(<span class="string">r'&lt;p align="center"&gt;.*?&lt;img src="(.*?)".*?&lt;/p&gt;'</span>,response.text,re.S)</span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> img_urls:</span><br><span class="line">            self.saveImg(img_url,dirname,index)</span><br><span class="line">            index+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveImg</span><span class="params">(self,img_url,dirname,index)</span>:</span></span><br><span class="line">        <span class="string">"""保存图片到本地"""</span></span><br><span class="line"></span><br><span class="line">        result = requests.get(img_url,headers=self.img_headers)</span><br><span class="line">        <span class="keyword">with</span> open(self.category + <span class="string">"/"</span> + dirname +<span class="string">"/"</span>+ str(index) + <span class="string">".jpg"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(result.content)</span><br><span class="line">            <span class="comment"># time.sleep(1)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""主函数"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(self.category):</span><br><span class="line">            os.makedirs(self.category)</span><br><span class="line">        pages = int(self.getIndexPage(self.base_url))</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,pages+<span class="number">1</span>):</span><br><span class="line">            print(page)</span><br><span class="line">            num = self.dic[self.category]</span><br><span class="line">            url = <span class="string">"http://www.169we.com/&#123;&#125;/list_&#123;&#125;_&#123;&#125;.html"</span>.format(self.category,num,page)</span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> self.getIndexImgHref(url):</span><br><span class="line">                old_url = data[<span class="number">0</span>]</span><br><span class="line">                pattern = re.compile(<span class="string">r'&lt;.*?&gt;'</span>,re.S)</span><br><span class="line">                dirname = re.sub(pattern,<span class="string">''</span>,data[<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,int(self.getPage(old_url))+<span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                        new_url = old_url</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        lista = old_url.split(<span class="string">"."</span>)</span><br><span class="line">                        lista[<span class="number">-2</span>] = lista[<span class="number">-2</span>] + <span class="string">"_&#123;&#125;"</span>.format(i)</span><br><span class="line">                        new_url = <span class="string">"."</span>.join(lista)</span><br><span class="line">                    self.getImgUrl(new_url,dirname,i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    msg = <span class="string">"""</span></span><br><span class="line"><span class="string">            提示信息：</span></span><br><span class="line"><span class="string">            diannaobizhi--——&gt;电脑壁纸</span></span><br><span class="line"><span class="string">            shoujibizhi--——&gt;手机壁纸</span></span><br><span class="line"><span class="string">            wangyouzipai--——&gt;网友自拍</span></span><br><span class="line"><span class="string">            gaogensiwa--——&gt;高跟丝袜</span></span><br><span class="line"><span class="string">            xiyangmeinv--——&gt;西洋美女</span></span><br><span class="line"><span class="string">            guoneimeinv--——&gt;国内美女</span></span><br><span class="line"><span class="string">            xingganmeinv--——&gt;性感美女</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    print(msg)</span><br><span class="line">    category = input(<span class="string">"请输入你要获取的类别名："</span>)</span><br><span class="line">    diannaobizhi = Pic169Spider(category)</span><br><span class="line">    diannaobizhi.main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/26.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="下载图片" scheme="https://acczmt.top/tags/%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>美食杰爬虫</title>
    <link href="https://acczmt.top/2018/07/27/%E7%BE%8E%E9%A3%9F%E6%9D%B0%E7%88%AC%E8%99%AB/"/>
    <id>https://acczmt.top/2018/07/27/美食杰爬虫/</id>
    <published>2018-07-26T20:06:20.000Z</published>
    <updated>2018-08-16T03:01:57.383Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/87.jpg?imageView2/2/h/600"><br></div></p><ul><li>美食杰  使用cookie模拟登陆 获取网页源码s</li><li>使用xpath得到用户信息 存储到excel表格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># from lxml import etree</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request,HTTPCookieProcessor,build_opener</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> CookieJar,LWPCookieJar</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line"><span class="comment"># ssl._create_default_https_content = ssl._create_unverified_context</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeiShiJie</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.login_url = <span class="string">"https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fi.meishi.cc%2Flogin.php%3Fac%3Dzhuce"</span></span><br><span class="line">        <span class="comment"># self.login_url = "https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fwww.meishij.net%2F"</span></span><br><span class="line">        self.index_url = <span class="string">"https://www.meishij.net&#123;&#125;?&amp;page=&#123;&#125;"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"</span></span><br><span class="line">        &#125;</span><br><span class="line">        self.total_page = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_cookies</span><span class="params">(self)</span>:</span></span><br><span class="line">        cookie = LWPCookieJar(filename=<span class="string">"mei_shi_jie.txt"</span>)</span><br><span class="line">        cookie_handler = HTTPCookieProcessor(cookie)</span><br><span class="line">        opener = build_opener(cookie_handler)</span><br><span class="line">        login_data = urlencode(&#123;</span><br><span class="line">            <span class="comment"># "redirect":"https://www.meishij.net/",</span></span><br><span class="line">            <span class="string">"username"</span>:<span class="string">"1797190195@qq.com"</span>,</span><br><span class="line">            <span class="string">"password"</span>:<span class="string">"qwert12345"</span></span><br><span class="line">        &#125;)</span><br><span class="line">        request = Request(self.login_url,bytes(login_data,encoding=<span class="string">"utf-8"</span>))</span><br><span class="line">        response = opener.open(request).read().decode()</span><br><span class="line"></span><br><span class="line">        cookie.save(ignore_discard=<span class="keyword">True</span>,ignore_expires=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code</span><span class="params">(self,path,page_index)</span>:</span></span><br><span class="line">        cookie = LWPCookieJar()</span><br><span class="line">        cookie.load(<span class="string">"mei_shi_jie.txt"</span>,ignore_expires=<span class="keyword">True</span> ,ignore_discard=<span class="keyword">True</span>)</span><br><span class="line">        cookie_handler = HTTPCookieProcessor(cookie)</span><br><span class="line">        opener = build_opener(cookie_handler)</span><br><span class="line">        url = self.index_url.format(path,str(page_index))</span><br><span class="line">        request = Request(url,headers=self.headers)</span><br><span class="line">        response = opener.open(request)</span><br><span class="line">        <span class="keyword">return</span> response.read().decode()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_total_page</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        root = etree.HTML(code)</span><br><span class="line">        self.total_page = int(root.xpath(<span class="string">'//span/form/text()'</span>)[<span class="number">0</span>][<span class="number">1</span>:<span class="number">-5</span>])</span><br><span class="line">    <span class="comment"># def get_menu_url(self,code):</span></span><br><span class="line">    <span class="comment">#     root = etree.HTML(code)</span></span><br><span class="line">    <span class="comment">#     hrefs = root.xpath('//ul[@class="listnav_ul"]/li/a/@href')</span></span><br><span class="line">    <span class="comment">#     print(hrefs[:-2])</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data_from_code</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        root = etree.HTML(code)</span><br><span class="line">        cai_names = root.xpath(<span class="string">'//div[@class="c1"]/strong/text()'</span>)</span><br><span class="line">        comment_and_love = root.xpath(<span class="string">'//div[@class="c1"]/span/text()'</span>)</span><br><span class="line">        comments,loves = [],[]</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> comment_and_love:</span><br><span class="line">            comment = re.findall(<span class="string">r'(\d+) 评论'</span>,data,re.S)</span><br><span class="line">            comments.append(comment[<span class="number">0</span>])</span><br><span class="line">            love = re.findall(<span class="string">r'评论  (\d+) 人气'</span>,data,re.S)</span><br><span class="line">            loves.append(love[<span class="number">0</span>])</span><br><span class="line">        authors = root.xpath(<span class="string">'//div[@class="c1"]/em/text()'</span>)</span><br><span class="line">        <span class="keyword">return</span> cai_names,authors,comments,loves</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.get_cookies()</span><br><span class="line">        workBook = xlwt.Workbook(encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        des_list = [<span class="string">"印象中的那些妈妈的味道"</span>, <span class="string">"了解咱餐饮文化大国，看中华八大菜系"</span>, <span class="string">"不出家门，也能吃遍大江南北"</span>, <span class="string">"看着菜谱做洋餐，做国际美食达人"</span>, <span class="string">"把爱卷进面团，让它到烤箱里继续升温"</span>]</span><br><span class="line">        href_list = [<span class="string">'/chufang/diy/'</span>, <span class="string">'/china-food/caixi/'</span>, <span class="string">'/china-food/xiaochi/'</span>, <span class="string">'/chufang/diy/guowaicaipu1/'</span>,<span class="string">'/hongpei/'</span>]</span><br><span class="line">        <span class="keyword">for</span> index, dec <span class="keyword">in</span> enumerate(des_list):</span><br><span class="line">            sheet = workBook.add_sheet(dec)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">0</span>, <span class="string">"菜名"</span>)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">1</span>, <span class="string">"作者"</span>)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">2</span>, <span class="string">"评论数"</span>)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">3</span>, <span class="string">"人气数"</span>)</span><br><span class="line">            code = self.get_code(href_list[index], <span class="number">1</span>)</span><br><span class="line">            self.get_total_page(code)</span><br><span class="line">            x = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,self.total_page+<span class="number">1</span>):</span><br><span class="line">                print(x)</span><br><span class="line">                code = self.get_code(href_list[index],i)</span><br><span class="line">                cai_names, authors, comments, loves = self.get_data_from_code(code)</span><br><span class="line">                <span class="keyword">for</span> cai_name,author,comment,love <span class="keyword">in</span> zip(cai_names,authors,comments,loves):</span><br><span class="line">                    sheet.write(x,<span class="number">0</span>,cai_name)</span><br><span class="line">                    sheet.write(x,<span class="number">1</span>,author)</span><br><span class="line">                    sheet.write(x,<span class="number">2</span>,comment)</span><br><span class="line">                    sheet.write(x,<span class="number">3</span>,love)</span><br><span class="line">                    x += <span class="number">1</span></span><br><span class="line">            workBook.save(<span class="string">"美食杰食谱2.xls"</span>)</span><br><span class="line"></span><br><span class="line">meishi = MeiShiJie()</span><br><span class="line">meishi.start_spider()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      练习
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="xlwt" scheme="https://acczmt.top/tags/xlwt/"/>
    
  </entry>
  
  <entry>
    <title>51Job</title>
    <link href="https://acczmt.top/2018/07/27/Job51/"/>
    <id>https://acczmt.top/2018/07/27/Job51/</id>
    <published>2018-07-26T17:50:20.000Z</published>
    <updated>2018-08-16T02:59:01.416Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/55.jpg?imageView2/2/h/600"><br></div><ul><li>51job</li><li>爬取任意城市的python岗位</li><li>包含公司名称</li><li>存入execl中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request,urlopen</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,cityList=[],workName=<span class="string">""</span>)</span>:</span></span><br><span class="line">        self.old_work_name = workName</span><br><span class="line">        self.base_url = <span class="string">"https://search.51job.com/list/&#123;&#125;,000000,0000,00,9,99,&#123;&#125;,2,&#123;&#125;.html"</span></span><br><span class="line">        self.total_page = <span class="number">1</span></span><br><span class="line">        self.cityString = <span class="string">""</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 将获取的字典反转</span></span><br><span class="line">        self.cityDic = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.get_city_info().items()&#125;</span><br><span class="line">        <span class="comment"># 或者使用通过 值获取对应的键 list(dic.keys())[list(dic.values()).index(2)]</span></span><br><span class="line">        <span class="comment"># 如果没有选择城市默认为全国</span></span><br><span class="line">        <span class="keyword">if</span> len(cityList) == <span class="number">0</span>:</span><br><span class="line">            self.cityString = <span class="string">'000000'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 以下代码为：如果城市名输入错误进行错误处理</span></span><br><span class="line">            <span class="keyword">for</span> cityName <span class="keyword">in</span> cityList:</span><br><span class="line">                <span class="keyword">if</span> cityName <span class="keyword">in</span> self.cityDic:</span><br><span class="line">                    <span class="keyword">if</span> cityName == cityList[<span class="number">-1</span>]:</span><br><span class="line">                        self.cityString+=self.cityDic[cityName]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        self.cityString += self.cityDic[cityName] + <span class="string">"%252C"</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">"******&#123;&#125;城市输入错误******"</span>.format(cityName))</span><br><span class="line">            <span class="keyword">if</span> len(self.cityString) == <span class="number">0</span>:</span><br><span class="line">                self.cityString = <span class="string">'000000'</span></span><br><span class="line">        <span class="comment"># 职位处理</span></span><br><span class="line">        <span class="keyword">if</span> len(workName) == <span class="number">0</span>:</span><br><span class="line">            self.workName = <span class="string">'%2520'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.workName = quote(workName,string.printable)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_city_info</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 获取城市对应的ID</span></span><br><span class="line">        url = <span class="string">"https://js.51jobcdn.com/in/js/2016/layer/area_array_c.js?20180319"</span></span><br><span class="line">        request = Request(url,headers=self.headers)</span><br><span class="line">        code = urlopen(request).read().decode(<span class="string">"gbk"</span>)</span><br><span class="line">        pattern = re.compile(<span class="string">r'.*?area=(.*?);'</span>,re.S)</span><br><span class="line">        result = pattern.findall(code)</span><br><span class="line">        <span class="keyword">return</span> json.loads(result[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code</span><span class="params">(self,pageIndex=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># 获取网页源码</span></span><br><span class="line">        url = self.base_url.format(self.cityString,self.workName,pageIndex)</span><br><span class="line">        print(url)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            request = Request(url,headers=self.headers)</span><br><span class="line">            code = urlopen(request).read().decode(<span class="string">"gbk"</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"请求失败"</span>,e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> code</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_total_page</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        <span class="comment"># 获取所有页数</span></span><br><span class="line">        pattern = re.compile(<span class="string">r'共(\d+)页，到第'</span>,re.S)</span><br><span class="line">        total_page = pattern.findall(code)[<span class="number">0</span>]</span><br><span class="line">        self.total_page=int(total_page)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_data</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        <span class="comment"># 提取数据</span></span><br><span class="line">        pattern = re.compile(<span class="string">r'&lt;p class="t1 "&gt;.*?&lt;a.*?title="(.*?)".*?&gt;.*?&lt;span class="t2"&gt;.*?&lt;a.*?title="(.*?)".*?&gt;.*?&lt;span class="t3"&gt;(.*?)&lt;/span&gt;.*?&lt;span class="t4"&gt;(.*?)&lt;/span&gt;'</span>,re.S)</span><br><span class="line">        result = pattern.findall(code)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_sheet_table</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 创建execl表</span></span><br><span class="line">        workBook = xlwt.Workbook(encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        sheet = workBook.add_sheet(self.old_work_name+<span class="string">"职位"</span>)</span><br><span class="line">        lista = [<span class="string">"职位名"</span>,<span class="string">"公司名"</span>,<span class="string">"工作地点"</span>,<span class="string">"薪资"</span>]</span><br><span class="line">        <span class="keyword">for</span> y,i <span class="keyword">in</span> enumerate(lista):</span><br><span class="line">            sheet.write(<span class="number">0</span>,y,i)</span><br><span class="line">        <span class="keyword">return</span> sheet,workBook</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 程序入口</span></span><br><span class="line">        code = self.get_code(<span class="number">1</span>)</span><br><span class="line">        self.get_total_page(code)</span><br><span class="line">        sheet,workBook = self.open_sheet_table()</span><br><span class="line">        x = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(<span class="number">1</span>,self.total_page+<span class="number">1</span>): <span class="comment">#self.total_page+1</span></span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            code = self.get_code(index)</span><br><span class="line">            results = self.get_all_data(code)</span><br><span class="line">            <span class="keyword">if</span> len(results) == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"对不起，没有找到符合你条件的职位！"</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">                <span class="keyword">for</span> y,res <span class="keyword">in</span> enumerate(result):</span><br><span class="line">                    <span class="comment"># x 代表行，y代表列  res代表值</span></span><br><span class="line">                    sheet.write(x,y,res)</span><br><span class="line">                x += <span class="number">1</span></span><br><span class="line">            workBook.save(<span class="string">"51job招聘信息4.xls"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    cityList = []</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        city = input(<span class="string">"请输入你想去的城市,按Q退出："</span>)</span><br><span class="line">        <span class="keyword">if</span> city == <span class="string">"Q"</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        cityList.append(city)</span><br><span class="line">    work = input(<span class="string">"请输入你喜欢的工作："</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># job = JobSpider(["北京","上海"],"python")</span></span><br><span class="line">    job = JobSpider(cityList,work)</span><br><span class="line">    job.start_spider()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/55.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Bing壁纸爬取</title>
    <link href="https://acczmt.top/2018/07/19/Bing%E5%A3%81%E7%BA%B8%E7%88%AC%E5%8F%96/"/>
    <id>https://acczmt.top/2018/07/19/Bing壁纸爬取/</id>
    <published>2018-07-18T17:50:20.000Z</published>
    <updated>2018-08-16T02:55:39.222Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/99.jpg?imageView2/2/h/600"><br></div><br>本次爬取采用<a href="https://github.com/xCss/bing" title="GitHub" target="_blank" rel="noopener">xCss</a>大大提供的接口</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">pname = <span class="number">0</span></span><br><span class="line">day = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    day +=<span class="number">1</span></span><br><span class="line">    url = <span class="string">'https://bing.ioliu.cn/v1?d=&#123;&#125;&amp;w=1280'</span>.format(day)</span><br><span class="line"></span><br><span class="line">    response = urlopen(url)</span><br><span class="line">    responseStr = response.read()</span><br><span class="line"></span><br><span class="line">    pname +=<span class="number">1</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'C:/Users/45125/Downloads/Bing_1280/&#123;&#125;.jpg'</span>.format(pname),<span class="string">'wb'</span>)<span class="keyword">as</span> f:</span><br><span class="line">        f.write(responseStr)</span><br><span class="line">        f.close()</span><br><span class="line">    time.sleep(<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/99.jpg?imageView2/2/h/600&quot;&gt;&lt;br
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>markdown_sync</title>
    <link href="https://acczmt.top/2018/07/17/markdown_sync/"/>
    <id>https://acczmt.top/2018/07/17/markdown_sync/</id>
    <published>2018-07-17T10:32:20.000Z</published>
    <updated>2018-08-16T02:51:59.926Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img src="/img/Bing_1280/86.jpg" height="600"><br></div><p>README</p><p>该文件用来测试和展示书写README的各种markdown语法。GitHub的markdown语法在标准的markdown语法基础上做了扩充，称之为<code>GitHub Flavored Markdown</code>。简称<code>GFM</code>，GFM在GitHub上有广泛应用，除了README文件外，issues和wiki均支持markdown语法。</p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#横线">横线</a></li><li><a href="#标题">标题</a></li><li><a href="#文本">文本</a><ul><li>普通文本</li><li>单行文本</li><li>多行文本</li><li>文字高亮</li><li>换行</li><li>斜体</li><li>粗体</li><li>删除线</li></ul></li><li><a href="#图片">图片</a><ul><li>来源于网络的图片</li><li>GitHub仓库中的图片</li></ul></li><li><a href="#链接">链接</a> <ul><li>文字超链接<ul><li>链接外部URL</li><li>链接本仓库里的URL</li></ul></li><li>锚点</li><li><a href="#图片链接">图片链接</a></li></ul></li><li><a href="#列表">列表</a><ul><li>无序列表</li><li>有序列表</li><li>复选框列表</li></ul></li><li><a href="#块引用">块引用</a></li><li><a href="#代码高亮">代码高亮</a></li><li><a href="#表格">表格</a> </li><li><a href="#表情">表情</a></li><li><a href="#diff语法">diff语法</a></li></ul><h3 id="横线"><a href="#横线" class="headerlink" title="横线"></a>横线</h3><hr><p>***、—、___可以显示横线效果</p><hr><hr><hr><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6><h2 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h2><h3 id="普通文本"><a href="#普通文本" class="headerlink" title="普通文本"></a>普通文本</h3><p>这是一段普通的文本</p><h3 id="单行文本"><a href="#单行文本" class="headerlink" title="单行文本"></a>单行文本</h3><pre><code>Hello,大家好，我是果冻虾仁。</code></pre><p>在一行开头加入1个Tab或者4个空格。</p><h3 id="文本块"><a href="#文本块" class="headerlink" title="文本块"></a>文本块</h3><h4 id="语法1"><a href="#语法1" class="headerlink" title="语法1"></a>语法1</h4><p>在连续几行的文本开头加入1个Tab或者4个空格。</p><pre><code>欢迎到访很高兴见到您祝您，早上好，中午好，下午好，晚安</code></pre><h4 id="语法2"><a href="#语法2" class="headerlink" title="语法2"></a>语法2</h4><p>使用一对各三个的反引号：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">欢迎到访</span><br><span class="line">我是C++码农</span><br><span class="line">你可以在知乎、CSDN、简书搜索【果冻虾仁】找到我</span><br></pre></td></tr></table></figure></p><p>该语法也可以实现代码高亮，见<a href="#代码高亮">代码高亮</a></p><h3 id="文字高亮"><a href="#文字高亮" class="headerlink" title="文字高亮"></a>文字高亮</h3><p>文字高亮功能能使行内部分文字高亮，使用一对反引号。<br>语法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`linux` `网络编程` `socket` `epoll`</span><br></pre></td></tr></table></figure></p><p>效果：<code>linux</code> <code>网络编程</code> <code>socket</code> <code>epoll</code></p><p>也适合做一篇文章的tag</p><h4 id="换行"><a href="#换行" class="headerlink" title="换行"></a>换行</h4><p>直接回车不能换行，<br>可以在上一行文本后面补两个空格，<br>这样下一行的文本就换行了。</p><p>或者就是在两行文本直接加一个空行。</p><p>也能实现换行效果，不过这个行间距有点大。</p><h4 id="斜体、粗体、删除线"><a href="#斜体、粗体、删除线" class="headerlink" title="斜体、粗体、删除线"></a>斜体、粗体、删除线</h4><table><thead><tr><th>语法</th><th>效果</th></tr></thead><tbody><tr><td><code>*斜体1*</code></td><td><em>斜体1</em></td></tr><tr><td><code>_斜体2_</code></td><td><em>斜体2</em></td></tr><tr><td><code>**粗体1**</code></td><td><strong>粗体1</strong></td></tr><tr><td><code>__粗体2__</code></td><td><strong>粗体2</strong></td></tr><tr><td><code>这是一个 ~~删除线~~</code></td><td>这是一个 <del>删除线</del></td></tr><tr><td><code>***斜粗体1***</code></td><td><strong><em>斜粗体1</em></strong></td></tr><tr><td><code>___斜粗体2___</code></td><td><strong><em>斜粗体2</em></strong></td></tr><tr><td><code>***~~斜粗体删除线1~~***</code></td><td><strong><em><del>斜粗体删除线1</del></em></strong></td></tr><tr><td><code>~~***斜粗体删除线2***~~</code></td><td><del><strong><em>斜粗体删除线2</em></strong></del></td></tr></tbody></table><pre><code>斜体、粗体、删除线可混合使用</code></pre><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>基本格式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![alt](URL title)</span><br></pre></td></tr></table></figure></p><p>alt和title即对应HTML中的alt和title属性（都可省略）：</p><ul><li>alt表示图片显示失败时的替换文本</li><li>title表示鼠标悬停在图片时的显示文本（注意这里要加引号）</li></ul><p>URL即图片的url地址，如果引用本仓库中的图片，直接使用<strong>相对路径</strong>就可了，如果引用其他github仓库中的图片要注意格式，即：<code>仓库地址/raw/分支名/图片路径</code>，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/guodongxiaren/ImageCache/raw/master/Logo/foryou.gif</span><br></pre></td></tr></table></figure></p><table><thead><tr><th>#</th><th>语法</th><th>效果</th></tr></thead><tbody><tr><td>1</td><td><code>![baidu](http://www.baidu.com/img/bdlogo.gif &quot;百度logo&quot;)</code></td><td><img src="http://www.baidu.com/img/bdlogo.gif" alt="baidu" title="百度logo"></td></tr><tr><td>2</td><td><code>![][foryou]</code></td><td><img src="https://github.com/guodongxiaren/ImageCache/raw/master/Logo/foryou.gif" alt=""></td></tr></tbody></table><p>注意例2的写法使用了<strong>URL标识符</strong>的形式，在<a href="#链接">链接</a>一节有介绍。</p><blockquote><p>在文末有foryou的定义：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[foryou]:https://github.com/guodongxiaren/ImageCache/raw/master/Logo/foryou.gif</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><h3 id="链接外部URL"><a href="#链接外部URL" class="headerlink" title="链接外部URL"></a>链接外部URL</h3><table><thead><tr><th>#</th><th>语法</th><th>效果</th></tr></thead><tbody><tr><td>1</td><td><code>[我的博客](http://blog.csdn.net/guodongxiaren &quot;悬停显示&quot;)</code></td><td><a href="http://blog.csdn.net/guodongxiaren" title="悬停显示" target="_blank" rel="noopener">我的博客</a></td></tr><tr><td>2</td><td><code>[我的知乎][zhihu]</code></td><td><a href="https://www.zhihu.com/people/jellywong" title="我的知乎，欢迎关注" target="_blank" rel="noopener">我的知乎</a></td></tr></tbody></table><p>语法2由两部分组成：</p><ul><li>第一部分使用两个中括号，[ ]里的标识符（本例中zhihu），可以是数字，字母等的组合，标识符上下对应就行了（<strong>姑且称之为URL标识符</strong>）</li><li>第二部分标记实际URL。</li></ul><blockquote><p>使用URL标识符能达到复用的目的，一般把全文所有的URL标识符统一放在文章末尾，这样看起来比较干净。</p><blockquote><p>URL标识符是我起的名字，不知道是否准确。囧。。</p></blockquote></blockquote><h3 id="链接本仓库里的URL"><a href="#链接本仓库里的URL" class="headerlink" title="链接本仓库里的URL"></a>链接本仓库里的URL</h3><table><thead><tr><th>语法</th><th>效果</th></tr></thead><tbody><tr><td><code>[我的简介](/example/profile.md)</code></td><td><a href="/example/profile.md">我的简介</a></td></tr><tr><td><code>[example](./example)</code></td><td><a href="./example">example</a></td></tr></tbody></table><h3 id="图片链接"><a href="#图片链接" class="headerlink" title="图片链接"></a>图片链接</h3><p>给图片加链接的本质是混合图片显示语法和普通的链接语法。普通的链接中[ ]内部是链接要显示的文本，而图片链接[ ]里面则是要显示的图片。<br>直接混合两种语法当然可以，但是十分啰嗦，为此我们可以使用URL标识符的形式。</p><table><thead><tr><th>#</th><th>语法</th><th style="text-align:center">效果</th></tr></thead><tbody><tr><td>1</td><td><code>[![weibo-logo]](http://weibo.com/linpiaochen)</code></td><td style="text-align:center"><a href="http://weibo.com/linpiaochen" target="_blank" rel="noopener"><img src="/img/weibo.png" alt="weibo-logo" title="点击图片进入我的微博"></a></td></tr><tr><td>2</td><td><code>[![](/img/zhihu.png &quot;我的知乎，欢迎关注&quot;)][zhihu]</code></td><td style="text-align:center"><a href="https://www.zhihu.com/people/jellywong" title="我的知乎，欢迎关注" target="_blank" rel="noopener"><img src="/img/zhihu.png" alt="" title="我的知乎，欢迎关注"></a></td></tr><tr><td>3</td><td><code>[![csdn-logo]][csdn]</code></td><td style="text-align:center"><a href="http://blog.csdn.net/guodongxiaren" title="我的博客" target="_blank" rel="noopener"><img src="/img/csdn.png" alt="csdn-logo" title="我的CSDN博客"></a></td></tr></tbody></table><p>因为图片本身和链接本身都支持URL标识符的形式，所以图片链接也可以很简洁（见例3）。<br>注意，此时鼠标悬停时显示的文字是图片的title，而非链接本身的title了。</p><blockquote><p>本文URL标识符都放置于文末</p></blockquote><h3 id="锚点"><a href="#锚点" class="headerlink" title="锚点"></a>锚点</h3><p>其实呢，每一个标题都是一个锚点，和HTML的锚点（<code>#</code>）类似，比如我们 </p><table><thead><tr><th>语法</th><th>效果</th></tr></thead><tbody><tr><td><code>[回到顶部](#readme)</code></td><td><a href="#readme">回到顶部</a></td></tr></tbody></table><p>不过要注意，标题中的英文字母都被转化为<strong>小写字母</strong>了。</p><blockquote><p>以前GitHub对中文支持的不好，所以中文标题不能正确识别为锚点，但是现在已经没问题啦！</p></blockquote><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><ul><li>昵称：果冻虾仁</li></ul><ul><li>别名：隔壁老王</li></ul><ul><li>英文名：Jelly</li></ul><h3 id="多级无序列表"><a href="#多级无序列表" class="headerlink" title="多级无序列表"></a>多级无序列表</h3><ul><li>编程语言<ul><li>脚本语言<ul><li>Python</li></ul></li></ul></li></ul><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><h4 id="一般效果"><a href="#一般效果" class="headerlink" title="一般效果"></a>一般效果</h4><p>就是在数字后面加一个点，再加一个空格。不过看起来起来可能不够明显。<br>面向对象的三个基本特征：</p><ol><li>封装</li><li>继承</li><li>多态</li></ol><h4 id="多级有序列表"><a href="#多级有序列表" class="headerlink" title="多级有序列表"></a>多级有序列表</h4><p>和无序列表一样，有序列表也有多级结构：  </p><ol><li>这是一级的有序列表，数字1还是1<ol><li>这是二级的有序列表，阿拉伯数字在显示的时候变成了罗马数字<ol><li>这是三级的有序列表，数字在显示的时候变成了英文字母</li></ol></li></ol></li></ol><h3 id="复选框列表"><a href="#复选框列表" class="headerlink" title="复选框列表"></a>复选框列表</h3><ul><li style="list-style: none"><input type="checkbox" checked> 需求分析</li><li style="list-style: none"><input type="checkbox" checked> 系统设计</li><li style="list-style: none"><input type="checkbox" checked> 详细设计</li><li style="list-style: none"><input type="checkbox"> 编码</li><li style="list-style: none"><input type="checkbox"> 测试</li><li style="list-style: none"><input type="checkbox"> 交付</li></ul><p>您可以使用这个功能来标注某个项目各项任务的完成情况。</p><blockquote><p>Tip:</p><blockquote><p>在GitHub的<strong>issue</strong>中使用该语法是可以实时点击复选框来勾选或解除勾选的，而无需修改issue原文。</p></blockquote></blockquote><h2 id="块引用"><a href="#块引用" class="headerlink" title="块引用"></a>块引用</h2><h3 id="常用于引用文本"><a href="#常用于引用文本" class="headerlink" title="常用于引用文本"></a>常用于引用文本</h3><h4 id="文本摘自《深入理解计算机系统》P27"><a href="#文本摘自《深入理解计算机系统》P27" class="headerlink" title="文本摘自《深入理解计算机系统》P27"></a>文本摘自《深入理解计算机系统》P27</h4><p>　令人吃惊的是，在哪种字节顺序是合适的这个问题上，人们表现得非常情绪化。实际上术语“little endian”（小端）和“big endian”（大端）出自Jonathan Swift的《格利佛游记》一书，其中交战的两个派别无法就应该从哪一端打开一个半熟的鸡蛋达成一致。因此，争论沦为关于社会政治的争论。只要选择了一种规则并且始终如一的坚持，其实对于哪种字节排序的选择都是任意的。</p><blockquote><p><strong>“端”（endian）的起源</strong><br>以下是Jonathan Swift在1726年关于大小端之争历史的描述：<br>“……下面我要告诉你的是，Lilliput和Blefuscu这两大强国在过去36个月里一直在苦战。战争开始是由于以下的原因：我们大家都认为，吃鸡蛋前，原始的方法是打破鸡蛋较大的一端，可是当今的皇帝的祖父小时候吃鸡蛋，一次按古法打鸡蛋时碰巧将一个手指弄破了，因此他的父亲，当时的皇帝，就下了一道敕令，命令全体臣民吃鸡蛋时打破较小的一端，违令者重罚。”</p></blockquote><h3 id="块引用有多级结构"><a href="#块引用有多级结构" class="headerlink" title="块引用有多级结构"></a>块引用有多级结构</h3><blockquote><p>数据结构</p><blockquote><p>树</p><blockquote><p>二叉树</p><blockquote><p>平衡二叉树</p><blockquote><p>满二叉树</p></blockquote></blockquote></blockquote></blockquote></blockquote><h2 id="代码高亮"><a href="#代码高亮" class="headerlink" title="代码高亮"></a>代码高亮</h2><p>在三个反引号后面加上编程语言的名字，另起一行开始写代码，最后一行再加上三个反引号。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[]args)</span></span>&#123;&#125; <span class="comment">//Java</span></span><br></pre></td></tr></table></figure></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> <span class="comment">//C</span></span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"hello GitHub"</span> <span class="comment">#Bash</span></span><br></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">document</span>.getElementById(<span class="string">"myH1"</span>).innerHTML=<span class="string">"Welcome to my Homepage"</span>; <span class="comment">//javascipt</span></span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">string</span> &amp;<span class="keyword">operator</span>+(<span class="keyword">const</span> <span class="built_in">string</span>&amp; A,<span class="keyword">const</span> <span class="built_in">string</span>&amp; B) <span class="comment">//cpp</span></span><br></pre></td></tr></table></figure><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><table><thead><tr><th>表头1</th><th>表头2</th></tr></thead><tbody><tr><td>表格单元</td><td>表格单元</td><td></td></tr><tr><td>表格单元</td><td>表格单元</td><td></td></tr></tbody></table><table><thead><tr><th>表头1</th><th>表头2</th></tr></thead><tbody><tr><td>表格单元</td><td>表格单元</td></tr><tr><td>表格单元</td><td>表格单元</td></tr></tbody></table><h3 id="对齐"><a href="#对齐" class="headerlink" title="对齐"></a>对齐</h3><p>表格可以指定对齐方式</p><table><thead><tr><th style="text-align:left">左对齐</th><th style="text-align:center">居中</th><th style="text-align:right">右对齐</th></tr></thead><tbody><tr><td style="text-align:left">col 3 is</td><td style="text-align:center">some wordy text</td><td style="text-align:right">$1600</td></tr><tr><td style="text-align:left">col 2 is</td><td style="text-align:center">centered</td><td style="text-align:right">$12</td></tr><tr><td style="text-align:left">zebra stripes</td><td style="text-align:center">are neat</td><td style="text-align:right">$1</td></tr></tbody></table><h3 id="混合其他语法"><a href="#混合其他语法" class="headerlink" title="混合其他语法"></a>混合其他语法</h3><p>表格单元中的内容可以和其他大多数GFM语法配合使用，如：  </p><h4 id="使用普通文本的删除线，斜体等效果"><a href="#使用普通文本的删除线，斜体等效果" class="headerlink" title="使用普通文本的删除线，斜体等效果"></a>使用普通文本的删除线，斜体等效果</h4><table><thead><tr><th>名字</th><th>描述</th></tr></thead><tbody><tr><td>Help</td><td><del>Display the</del> help window.</td></tr><tr><td>Close</td><td><em>Closes</em> a window</td></tr></tbody></table><h4 id="表格中嵌入图片（链接）"><a href="#表格中嵌入图片（链接）" class="headerlink" title="表格中嵌入图片（链接）"></a>表格中嵌入图片（链接）</h4><p>其实前面介绍图片显示、图片链接的时候为了清晰就是放在在表格中显示的。</p><table><thead><tr><th>图片</th><th>描述</th></tr></thead><tbody><tr><td><img src="http://www.baidu.com/img/bdlogo.gif" alt="baidu" title="百度logo"></td><td>百度</td></tr></tbody></table><h2 id="表情"><a href="#表情" class="headerlink" title="表情"></a>表情</h2><p>Github的Markdown语法支持添加emoji表情，输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情。</p><p>比如<code>:blush:</code>，可以显示:blush:。</p><p>具体每一个表情的符号码，可以查询GitHub的官方网页<a href="http://www.emoji-cheat-sheet.com" target="_blank" rel="noopener">http://www.emoji-cheat-sheet.com</a>。</p><p>但是这个网页每次都打开<strong>奇慢</strong>。。所以我整理到了本repo中，大家可以直接在此查看<a href="./emoji.md">emoji</a>。</p><h2 id="diff语法"><a href="#diff语法" class="headerlink" title="diff语法"></a>diff语法</h2><p>版本控制的系统中都少不了diff的功能，即展示一个文件内容的增加与删除。<br>GFM中可以显示的展示diff效果。使用绿色表示新增，红色表示删除。</p><p>其语法与代码高亮类似，只是在三个反引号后面写diff，<br>并且其内容中，以 <code>+</code>开头表示新增，<code>-</code>开头表示删除。</p><p>效果如下：</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="addition">+ 鸟宿池边树，僧敲月下门</span></span><br><span class="line"><span class="deletion">- 鸟宿池边树，僧推月下门</span></span><br></pre></td></tr></table></figure><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;/img/Bing_1280/86.jpg&quot; height=&quot;600&quot;&gt;&lt;br&gt;&lt;/div&gt;



&lt;p&gt;README&lt;/p&gt;
&lt;p&gt;该文件用来测试和展示书写README的各种markdown语法。GitHub的
      
    
    </summary>
    
    
      <category term="markdown" scheme="https://acczmt.top/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>无悔的选择</title>
    <link href="https://acczmt.top/2018/07/03/%E6%96%B0%E7%9A%84%E5%BC%80%E5%A7%8B/"/>
    <id>https://acczmt.top/2018/07/03/新的开始/</id>
    <published>2018-07-02T16:00:00.000Z</published>
    <updated>2018-08-16T03:02:29.751Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img src="/img/Bing_1280/101.jpg" height="600"><br></div><h2 id="新的一天-新的开始"><a href="#新的一天-新的开始" class="headerlink" title="新的一天 新的开始"></a>新的一天 新的开始</h2><ul><li>既然已经选择这条路，那就努力去实现自己的梦想。</li><li>不要让自己后悔，你已经过了后悔的年龄了。</li><li>你已不是那个少年，少年也已不再是你。</li><li>只有你努力奋斗，才能给她想要的未来。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;/img/Bing_1280/101.jpg&quot; height=&quot;600&quot;&gt;&lt;br&gt;&lt;/div&gt;


&lt;h2 id=&quot;新的一天-新的开始&quot;&gt;&lt;a href=&quot;#新的一天-新的开始&quot; class=&quot;headerlin
      
    
    </summary>
    
    
      <category term="随笔" scheme="https://acczmt.top/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
