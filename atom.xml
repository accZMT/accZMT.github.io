<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>llt</title>
  
  <subtitle>只想挽起你的手 戎马一生挥毫只为你</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://acczmt.top/"/>
  <updated>2018-10-08T08:51:43.830Z</updated>
  <id>https://acczmt.top/</id>
  
  <author>
    <name>李岚天</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>PEP8规范</title>
    <link href="https://acczmt.top/2018/09/28/%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    <id>https://acczmt.top/2018/09/28/编码规范/</id>
    <published>2018-09-28T07:30:00.000Z</published>
    <updated>2018-10-08T08:51:43.830Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PEP8规范"><a href="#PEP8规范" class="headerlink" title="PEP8规范"></a>PEP8规范</h1><p>（一） 代码的编排<br>1、 缩进。每行需要4个空格的缩进，不要使用Tap键，更不能混合使用Tap键和空格。<br>2、 每行最大长度79，换行可以使用反斜杠，但最好使用圆括号。换行点要在操作符的后边敲回车。<br>3、 类和top-level函数定义之间空两行；类中的方法定义之间空一行；函数内逻辑无关段落之间空一行；其他地方尽量不要再空行。</p><p>（二 ）文档的编排<br>1、 模块内容的顺序：模块说明和docstring—import—globals&amp;constants—其他定义。其中import部分，又按标准、第三方和自己编写顺序依次排放，之间空一行。</p><p>from django.db import models<br>from datetime import datetime</p><p>from django.contrib.auth.models import AbstractUser</p><h1 id="自己定义代码放置处"><a href="#自己定义代码放置处" class="headerlink" title="自己定义代码放置处"></a>自己定义代码放置处</h1><p>2、 要在一行import多个库，比如import os, sys，虽说没有错误但是并不推荐。<br>3、 如果采用from xx import xx的方式来引用某个库，可以省略module.，但是可能会出现命名的冲突，所以这时就要采用import xx的方式。</p><p>（三）空格的使用<br>总体原则，避免不必要的空格。<br>1、 各种右括号前不要加空格。<br>2、 逗号、冒号、分号前不要加空格。<br>3、 函数的左括号前不要加空格。如function(1)。<br>4、 序列的左括号前不要加空格。如list[2]。<br>5、 操作符左右各加一个空格，不要为了对齐增加空格。<br>6、 函数默认参数使用的赋值符左右省略空格。<br>7、 不要将多句语句写在同一行，尽管使用；允许。<br>8、 if/for/while语句中，即使执行语句只有一句，也必须另起一行。</p><p>（四）命名的规范<br>总体原则，新编代码必须按下面命名风格进行，现有库的编码尽量保持风格。<br>1、 尽量单独使用小写字母‘l’，大写字母‘O’等容易混淆的字母。<br>2、 模块命名尽量短小，使用全部小写的方式，可以使用下划线。<br>3、 包命名尽量短小，使用全部小写的方式，不可以使用下划线。<br>4、 类的命名使用CapWords的方式，模块内部使用的类采用_CapWords的方式。<br>5、 异常命名使用CapWords+Error后缀的方式。<br>6、 全局变量尽量只在模块内有效，类似C语言中的static。实现方法有两种，一是all机制;二是前缀一个下划线。<br>7、 函数命名使用全部小写的方式，可以使用下划线。<br>8、 常量命名使用全部大写的方式，可以使用下划线。<br>9、 类的属性（方法和变量）命名使用全部小写的方式，可以使用下划线。<br>10、 类的属性有3种作用域public、non-public和subclass API，可以理解成C++中的public、private、protected，non-public属性前，前缀一条下划线。<br>11、 类的属性若与关键字名字冲突，后缀一下划线，尽量不要使用缩略等其他方式。<br>12、 为避免与子类属性命名冲突，在类的一些属性前，前缀两条下划线。比如：类Foo中声明<strong>a,访问时，只能通过Foo._Foo</strong>a，避免歧义。如果子类也叫Foo，那就无能为力了。<br>13、 类的方法第一个参数必须是self，而静态方法第一个参数必须是cls。</p><p>（五）编码的建议<br>1、 编码中考虑到其他python实现的效率等问题，比如运算符‘+’在CPython（Python）中效率很高，都是Jython中却非常低，所以应该采用.join()的方式。<br>2、 尽可能使用‘is’‘is not’取代‘==’，比如if x is not None 要优于if x。<br>3、 使用基于类的异常，每个模块或包都有自己的异常类，此异常类继承自Exception。<br>4、 异常中不要使用裸露的except，except后跟具体的exceptions。<br>5、 异常中try的代码尽可能少。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">value = collection[key]</span><br><span class="line">except KeyError:</span><br><span class="line">return key_not_found(key)</span><br><span class="line">else:</span><br><span class="line">return handle_value(value)</span><br></pre></td></tr></table></figure><p>要优于</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line"># Too broad!</span><br><span class="line">return handle_value(collection[key])</span><br><span class="line">except KeyError:</span><br><span class="line"># Will also catch KeyError raised by handle_value()</span><br><span class="line">return key_not_found(key)</span><br></pre></td></tr></table></figure><p>6 、使用startswith() and endswith()代替切片进行序列前缀或后缀的检查。比如:<br>Yes: if foo.startswith(‘bar’):优于No: if foo[:3] == ‘bar’:<br>7 、使用isinstance()比较对象的类型。比如:<br>Yes: if isinstance(obj, int):优于No: if type(obj) is type(1):<br>8、 判断序列空或不空，有如下规则:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Yes: if not seq:</span><br><span class="line">if seq:</span><br><span class="line">优于</span><br><span class="line"></span><br><span class="line">No: if len(seq)</span><br><span class="line">if not len(seq)</span><br></pre></td></tr></table></figure></p><p>9、 字符串不要以空格收尾。<br>10、 二进制数据判断使用 if boolvalue的方式。</p><p>如果你想获得更多关于PEP8的信息，可以查阅这篇信息PEP8 Python 编码规范整理或者官方文档PEP8的官方文档</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;PEP8规范&quot;&gt;&lt;a href=&quot;#PEP8规范&quot; class=&quot;headerlink&quot; title=&quot;PEP8规范&quot;&gt;&lt;/a&gt;PEP8规范&lt;/h1&gt;&lt;p&gt;（一） 代码的编排&lt;br&gt;1、 缩进。每行需要4个空格的缩进，不要使用Tap键，更不能混合使用Tap键和空格
      
    
    </summary>
    
    
      <category term="python" scheme="https://acczmt.top/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>scrapy + selenium爬取淘宝商品信息</title>
    <link href="https://acczmt.top/2018/08/30/scrapy%E7%88%AC%E5%8F%96%E6%B7%98%E5%AE%9D%E4%BF%A1%E6%81%AF/"/>
    <id>https://acczmt.top/2018/08/30/scrapy爬取淘宝信息/</id>
    <published>2018-08-30T13:00:00.000Z</published>
    <updated>2018-08-30T14:29:49.364Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br>    <img src="http://pdhrh6d6j.bkt.clouddn.com/images/az/10.jpg?imageView/2/2/h/600"><br></div><p><code>学习目的</code> 使用scrapy框架获取动态网站信息，以淘宝为例， 获取商品的[描述,价格,商店，图片链接]将获取的信息保存到execl表，或者json文件，数据库中。</p><p>打开淘宝首页搜索一加手机，获取<strong>第一页url</strong>为<code>https://s.taobao.com/search?q=%E4%B8%80%E5%8A%A0%E6%89%8B%E6%9C%BA&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20180830&amp;ie=utf8</code>，</p><p>点击下一页获取<strong>第二页url</strong>为<code>https://s.taobao.com/search?q=%E4%B8%80%E5%8A%A0%E6%89%8B%E6%9C%BA&amp;imgfile=&amp;js=1&amp;stats_click=search_radio_all%3A1&amp;initiative_id=staobaoz_20180830&amp;ie=utf8&amp;bcoffset=4&amp;p4ppushleft=1%2C48&amp;s=44&amp;ntoffset=4</code></p><p>通过对比分析下一页的url主要通过<strong>s</strong>变化，每次增加44，所以url可以简化为<code>https://s.taobao.com/search?q=%E4%B8%80%E5%8A%A0%E6%89%8B%E6%9C%BA&amp;s=0</code></p><p>下面开始写代码了</p><blockquote><p>新建一个项目文件</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject taobao</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> taobao </span><br><span class="line">scrapy genspider phone s.taobao.com</span><br></pre></td></tr></table></figure><blockquote><p>item.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaobaoItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    img_src = scrapy.Field()</span><br><span class="line">    info = scrapy.Field()</span><br><span class="line">    price = scrapy.Field()</span><br><span class="line">    shop = scrapy.Field()</span><br></pre></td></tr></table></figure><blockquote><p>spiders/phone.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> TaobaoItem</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PhoneSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'phone'</span></span><br><span class="line">    allowed_domains = [<span class="string">'s.taobao.com'</span>]</span><br><span class="line"></span><br><span class="line">    total_page = <span class="number">20</span></span><br><span class="line">    start_urls = [<span class="string">'https://s.taobao.com/search?q=%E4%B8%80%E5%8A%A0%E6%89%8B%E6%9C%BA&amp;s=&#123;&#125;'</span>.format(i*<span class="number">44</span>) <span class="keyword">for</span> i <span class="keyword">in</span> range(total_page)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 配置谷歌浏览器无图和无界面模式</span></span><br><span class="line">        self.options = webdriver.ChromeOptions()</span><br><span class="line">        self.prefs = &#123;</span><br><span class="line">            <span class="string">'profile.default_content_setting_values'</span>:&#123;<span class="string">'images'</span>:<span class="number">2</span>&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        self.options.add_argument(<span class="string">'--headless'</span>)</span><br><span class="line">        self.options.add_argument(<span class="string">'--disable-gpu'</span>)</span><br><span class="line">        self.options.add_experimental_option(<span class="string">'prefs'</span>,self.prefs)</span><br><span class="line"></span><br><span class="line">        self.driver = webdriver.Chrome(chrome_options=self.options)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        data_list = response.xpath(<span class="string">'//div[@class="item J_MouserOnverReq  "]'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line"></span><br><span class="line">            info = <span class="string">''</span>.join(data.xpath(<span class="string">'.//div[@class="row row-2 title"]/a/text()'</span>).extract()).strip().replace(<span class="string">'/'</span>,<span class="string">''</span>)</span><br><span class="line">            price = data.xpath(<span class="string">'.//div[@class="price g_price g_price-highlight"]/strong/text()'</span>).extract_first()</span><br><span class="line">            shop = data.xpath(<span class="string">'.//a[@class="shopname J_MouseEneterLeave J_ShopInfo"]/span[2]/text()'</span>).extract_first()</span><br><span class="line">            img_src = <span class="string">"https:"</span> + data.xpath(<span class="string">'.//a[@class="pic-link J_ClickStat J_ItemPicA"]/img/@data-src'</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            item = TaobaoItem()</span><br><span class="line"></span><br><span class="line">            item[<span class="string">'info'</span>] = info</span><br><span class="line">            item[<span class="string">'price'</span>] = price</span><br><span class="line">            item[<span class="string">'shop'</span>] = shop</span><br><span class="line">            item[<span class="string">'img_src'</span>] = [img_src]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取总页数</span></span><br><span class="line">        <span class="comment"># self.total_page = response.xpath('//div[@class="total"]/text()').re_first('\d+')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(spider, reason)</span>:</span></span><br><span class="line"></span><br><span class="line">        spider.driver.close()</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure><blockquote><p>pipelines.py </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlretrieve</span><br><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonItemExporter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UrllibPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        urlretrieve(item[<span class="string">"img_src"</span>][<span class="number">0</span>],<span class="string">"imgs/"</span>+item[<span class="string">"info"</span>]+<span class="string">".jpg"</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonFilePipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'taobao.json'</span>,<span class="string">'wb'</span>)</span><br><span class="line">        self.exporter = JsonItemExporter(self.file,ensure_ascii=<span class="keyword">False</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.exporter.start_exporting()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self,item,spider)</span>:</span></span><br><span class="line">        self.exporter.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.exporter.finish_exporting()</span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TaobaoPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.workbook = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        self.sheet = self.workbook.add_sheet(<span class="string">'一加手机'</span>)</span><br><span class="line">        self.info_list = [<span class="string">'info'</span>,<span class="string">'price'</span>,<span class="string">'shop'</span>,<span class="string">'img_src'</span>]</span><br><span class="line">        self.row = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> index,info <span class="keyword">in</span> enumerate(self.info_list):</span><br><span class="line">            self.sheet.write(<span class="number">0</span>,index,info)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.workbook.save(<span class="string">"Taobao.xlsx"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        data_list = [item[<span class="string">"info"</span>],item[<span class="string">"price"</span>],item[<span class="string">"shop"</span>],item[<span class="string">"img_src"</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(data_list):</span><br><span class="line">            self.sheet.write(self.row,index,data)</span><br><span class="line">        self.row += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SqlitePipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.conn = sqlite3.connect(<span class="string">'taobaoDB'</span>)</span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.cursor.execute(<span class="string">'create table if not exists phone (img text,info text,price text,shop text)'</span>)</span><br><span class="line">        self.conn.commit()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self,item,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.cursor.execute(<span class="string">f'insert into phone VALUES ("<span class="subst">&#123;item[<span class="string">"img_src"</span>]&#125;</span>","<span class="subst">&#123;item[<span class="string">"info"</span>]&#125;</span>","<span class="subst">&#123;item[<span class="string">"price"</span>]&#125;</span>","<span class="subst">&#123;item[<span class="string">"shop"</span>]&#125;</span>")'</span>)</span><br><span class="line">        self.conn.commit()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure><blockquote><p>middlewares.py  此文件为中间件文件 ，在此添加一个下载中间件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">from</span> scrapy.http.response.html <span class="keyword">import</span> HtmlResponse</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SeleniumMiddleware</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self,request,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> spider.name == <span class="string">"phone"</span>:</span><br><span class="line">            spider.driver.get(request.url)</span><br><span class="line">            spider.driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">            response = HtmlResponse(url=spider.driver.current_url,</span><br><span class="line">                                    request=request,</span><br><span class="line">                                    body=spider.driver.page_source,</span><br><span class="line">                                    encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">            <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure><blockquote><p>修改settings.py </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">   <span class="comment"># 'taobao.middlewares.TaobaoDownloaderMiddleware': 543,</span></span><br><span class="line">   <span class="string">'taobao.middlewares.SeleniumMiddleware'</span>: <span class="number">2</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'taobao.pipelines.TaobaoPipeline'</span>: <span class="number">1</span>,</span><br><span class="line">   <span class="string">'taobao.pipelines.JsonFilePipeline'</span>: <span class="number">2</span>,</span><br><span class="line">   <span class="string">'taobao.pipelines.SqlitePipeline'</span>: <span class="number">4</span>,</span><br><span class="line">   <span class="comment"># 如果想要下载图片只需将下面一行解注释即可</span></span><br><span class="line">   <span class="comment"># 'taobao.pipelines.UrllibPipeline': 56,</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">IMAGES_STORE = <span class="string">'imgs'</span></span><br></pre></td></tr></table></figure><blockquote><p>在spiders同级目录下新建main.py文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl phone'</span>.split())</span><br></pre></td></tr></table></figure><p>直接运行main.py文件即可。</p><p>源码放到GitHub上–&gt; <a href="https://github.com/accZMT/python_study/tree/master/taobao" target="_blank" rel="noopener">点击获取</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;    &lt;img src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/10.jpg?imageView/2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;p&gt;&lt;code&gt;学习目的&lt;/code
      
    
    </summary>
    
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>node.js简单使用</title>
    <link href="https://acczmt.top/2018/08/29/node.js/"/>
    <id>https://acczmt.top/2018/08/29/node.js/</id>
    <published>2018-08-29T12:00:00.000Z</published>
    <updated>2018-08-30T01:10:22.609Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br>    <img src="http://pdhrh6d6j.bkt.clouddn.com/images/az/11.jpg?imageView2/2/h/600"><br></div><ul><li><a href="#node.js安装">node.js安装</a></li><li><a href="#创建项目">创建一个项目</a></li><li><a href="#安装express">安装express</a></li><li><a href="#注册与登录">注册与登录</a></li><li><a href="#注意">注意</a></li></ul><blockquote><h4 id="node-js安装"><a href="#node-js安装" class="headerlink" title="node.js安装"></a>node.js安装</h4></blockquote><p>进入<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">nodejs.org</a>下载对应版本，点击安装。</p><p>安装完成后，检查node.js版本，在命令行中输入以下内容。如果成功显示代表安装配置成功。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node --version</span><br></pre></td></tr></table></figure></p><p>或者<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure></p><p>检查完成后，需要重启电脑，使npm命令生效。<br>安装node.js时，会自动安装npm。运行 <strong>npm -v</strong>检查版本，如果版本不匹配，使用以下命令升级</p><blockquote><p>npm install npm@latest -g</p></blockquote><blockquote><h4 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h4></blockquote><p>进入到指定的目录下，新建一个文件夹，如：regist-and-login,进入到给文件夹下shift+鼠标右键 选择“在此处打开命令窗口” 输入<strong>npm init</strong> 当需要输入信息时可以根据提示输入，也可以直接enter键选择默认的。结束后会自动生成package.json文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">c:/Users/Administrator/Desktop/regist-and-login&gt;npm init</span><br><span class="line">This utility will walk you through creating a package.json file.</span><br><span class="line">It only covers the most common items, and tries to guess sensible defaults.</span><br><span class="line"></span><br><span class="line">See `npm <span class="built_in">help</span> json` <span class="keyword">for</span> definitive documentation on these fields</span><br><span class="line">and exactly what they <span class="keyword">do</span>.</span><br><span class="line"></span><br><span class="line">Use `npm install &lt;pkg&gt;` afterwards to install a package and</span><br><span class="line">save it as a dependency <span class="keyword">in</span> the package.json file.</span><br><span class="line"></span><br><span class="line">Press ^C at any time to quit.</span><br><span class="line">package name: (registandlogin)</span><br><span class="line">version: (1.0.0)</span><br><span class="line">description:</span><br><span class="line">git repository:</span><br><span class="line">keywords:</span><br><span class="line">author:</span><br><span class="line">license: (ISC)</span><br><span class="line">About to write to c:/Users/Administrator/Desktop/regist-and-login/package.json:</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: <span class="string">"registandlogin"</span>,</span><br><span class="line">  <span class="string">"version"</span>: <span class="string">"1.0.0"</span>,</span><br><span class="line">  <span class="string">"main"</span>: <span class="string">"index.js"</span>,</span><br><span class="line">  <span class="string">"scripts"</span>: &#123;</span><br><span class="line">    <span class="string">"test"</span>: <span class="string">"echo \"Error: no test specified\" &amp;&amp; exit 1"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"author"</span>: <span class="string">""</span>,</span><br><span class="line">  <span class="string">"license"</span>: <span class="string">"ISC"</span>,</span><br><span class="line">  <span class="string">"dependencies"</span>: &#123;</span><br><span class="line">    <span class="string">"express"</span>: <span class="string">"^4.16.3"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"devDependencies"</span>: &#123;&#125;,</span><br><span class="line">  <span class="string">"description"</span>: <span class="string">""</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Is this ok? (yes)</span><br></pre></td></tr></table></figure></p><blockquote><h4 id="安装express"><a href="#安装express" class="headerlink" title="安装express"></a>安装express</h4></blockquote><p>接着上面的操作执行以下步骤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c:/Users/Administrator/Desktop/regist-and-login&gt;npm install express</span><br></pre></td></tr></table></figure><p>如果遇到Timeout错误，使用以下方法：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry http://registry.cnpmjs.org</span><br><span class="line">npm info underscore</span><br><span class="line">npm install express</span><br></pre></td></tr></table></figure></p><blockquote><h4 id="注册与登录"><a href="#注册与登录" class="headerlink" title="注册与登录"></a>注册与登录</h4></blockquote><p>在regist-and-login 下新建public/index.html 与 index.js 文件</p><blockquote><p>index.html文件 body添加以下代码：</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/regist"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">""</span>&gt;</span>账号<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">id</span>=<span class="string">""</span> <span class="attr">placeholder</span>=<span class="string">"请输入账号"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">""</span>&gt;</span>密码<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">placeholder</span>=<span class="string">"请输入密码"</span> <span class="attr">name</span>=<span class="string">"psw"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">""</span>&gt;</span>重复密码<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">placeholder</span>=<span class="string">"请重复密码"</span> <span class="attr">name</span>=<span class="string">"pswa"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">""</span>&gt;</span>提交<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">placeholder</span>=<span class="string">"注册"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">"/login"</span> <span class="attr">method</span>=<span class="string">"POST"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">""</span>&gt;</span>用户名:<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">"user"</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">placeholder</span>=<span class="string">"请输入用户名"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">""</span>&gt;</span>密码<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">name</span>=<span class="string">"password"</span> <span class="attr">type</span>=<span class="string">"password"</span> <span class="attr">placeholder</span>=<span class="string">"请输入密码"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"submit"</span> <span class="attr">name</span>=<span class="string">""</span> <span class="attr">id</span>=<span class="string">""</span> <span class="attr">value</span>=<span class="string">"登录"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>index.js 文件</p></blockquote><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> express = <span class="built_in">require</span>(<span class="string">'express'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// post 请求方式会将参数放入到请求体当中</span></span><br><span class="line"><span class="comment">// 所以需要引入解析请求体的模块body-parser</span></span><br><span class="line"><span class="keyword">var</span> bodyParser = <span class="built_in">require</span>(<span class="string">'body-parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> web = express()</span><br><span class="line"></span><br><span class="line">web.use(express.static(<span class="string">'public'</span>))</span><br><span class="line"><span class="comment">// 设置对url进行编码 并且不允许url进行扩展</span></span><br><span class="line"><span class="comment">// 如果设置为false 那么参数只能为数组或者字符串</span></span><br><span class="line"><span class="comment">// 如果为True 那么参数为任意类型</span></span><br><span class="line">web.use(bodyParser.urlencoded(&#123;<span class="attr">extended</span>:<span class="literal">false</span>&#125;))</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> account = <span class="string">''</span></span><br><span class="line"><span class="keyword">var</span> psw = <span class="string">''</span></span><br><span class="line">web.get(<span class="string">'/regist'</span>,<span class="function"><span class="keyword">function</span>(<span class="params">req,res</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> password = req.query.psw </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">var</span> password2 = req.query.pswa</span><br><span class="line">  <span class="keyword">var</span> user = req.query.user</span><br><span class="line">  <span class="keyword">if</span> (user != account &amp;&amp; password==password2)&#123;</span><br><span class="line">      account = user</span><br><span class="line">      psw = password</span><br><span class="line">      res.send(<span class="string">'注册成功！账号是'</span>+user+<span class="string">'密码是'</span>+password + <span class="string">',请妥善保管'</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span>&#123;</span><br><span class="line">      res.send(<span class="string">'注册失败，账号已经注册或者密码不一致'</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">console</span>.log(password,password2)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">web.post(<span class="string">'/login'</span>,<span class="function"><span class="keyword">function</span>(<span class="params">req,res</span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> name = req.body.user</span><br><span class="line">    <span class="keyword">var</span> password = req.body.password</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(name==account &amp;&amp; password==psw)&#123;</span><br><span class="line">        res.send(<span class="string">'登陆成功'</span>)</span><br><span class="line">        <span class="built_in">console</span>.log(name,password)</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        res.send(<span class="string">'登录失败，请检查账号密码'</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">web.listen(<span class="string">'8080'</span>,<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">'服务器启动。。'</span>)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>代码写完之后依然在命令行 下执行 <strong>node index</strong> 显示 “服务器启动。。”。</p><p>在浏览器中打开<strong>index.html</strong>,输入信息进行测试。</p><blockquote><h4 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h4><p>1、当index.js文件修改后 ，需要重新启动，并且刷新localhost:8080页面。<br>2、当index.html文件修改后 ，服务器可以不用重启，需要刷新localhost:8080页面。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;    &lt;img src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/11.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#n
      
    
    </summary>
    
    
      <category term="node.js" scheme="https://acczmt.top/tags/node-js/"/>
    
  </entry>
  
  <entry>
    <title>打字小游戏</title>
    <link href="https://acczmt.top/2018/08/29/%E6%89%93%E5%AD%97%E5%B0%8F%E6%B8%B8%E6%88%8F/"/>
    <id>https://acczmt.top/2018/08/29/打字小游戏/</id>
    <published>2018-08-29T03:00:00.000Z</published>
    <updated>2018-08-29T11:24:50.531Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br>    <img src="http://pdhrh6d6j.bkt.clouddn.com/images/az/12.jpg?imageView2/2/h/600"><br></div><blockquote><p>制作一个打字小游戏,效果图如下：</p></blockquote><div align="center"><br>    <img alt="打字效果图" src="http://pdhrh6d6j.bkt.clouddn.com/images/dazi.jpg?imageView2/2/h/600"><br></div><blockquote><p>新建一个文件夹 ，添加animate.css 和 jquery.js 文件。 新建index.html文件，完整代码与所需文件在底部GitHub中。</p></blockquote><p>由效果图可以分析出内容由两部分组成，一是字母，二是正确率。可以写成两个div标签，在body标签中写以下代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">main</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"char"</span> <span class="attr">class</span>=<span class="string">"animated"</span>&gt;</span>H<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"result"</span>&gt;</span>正确个数:0,错误个数:0,正确率:100%<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">main</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>添加CSS样式：</p></blockquote><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&lt;link rel="stylesheet" href="animate.css"&gt;</span><br><span class="line">&lt;title&gt;打字游戏&lt;/title&gt;</span><br><span class="line">&lt;<span class="selector-tag">style</span>&gt;</span><br><span class="line">    <span class="selector-tag">html</span>,</span><br><span class="line">    <span class="selector-tag">body</span>&#123;</span><br><span class="line">        <span class="attribute">margin</span>: <span class="number">0</span>;</span><br><span class="line">        <span class="attribute">height</span>: <span class="number">100%</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="selector-tag">body</span>&#123;</span><br><span class="line">        <span class="comment">/* 设置背景为径向渐变 默认为椭圆形circle*/</span></span><br><span class="line">        <span class="attribute">background</span>: <span class="built_in">radial-gradient</span>(circle,#333,#222,#000);</span><br><span class="line">        <span class="attribute">display</span>: flex;</span><br><span class="line">        <span class="attribute">justify-content</span>: center;</span><br><span class="line">        <span class="attribute">align-items</span>: center;</span><br><span class="line">        <span class="attribute">text-align</span>: center;       </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="selector-id">#char</span>&#123;</span><br><span class="line">        <span class="attribute">color</span>: greenyellow;</span><br><span class="line">        <span class="attribute">font-size</span>: <span class="number">300px</span>;</span><br><span class="line">        <span class="attribute">text-shadow</span>: <span class="number">0px</span> <span class="number">0px</span> <span class="number">20px</span> red;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="selector-id">#result</span>&#123;</span><br><span class="line">        <span class="attribute">color</span>: red;</span><br><span class="line">        <span class="attribute">font-size</span>: <span class="number">40px</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="selector-id">#char</span><span class="selector-class">.error</span>&#123;</span><br><span class="line">        <span class="attribute">color</span>: red;</span><br><span class="line">        <span class="attribute">text-shadow</span>: <span class="number">0px</span> <span class="number">0px</span> <span class="number">20px</span> greenyellow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&lt;/style&gt;</span><br></pre></td></tr></table></figure><blockquote><p>添加script:</p></blockquote><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"jquery.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> char = <span class="built_in">document</span>.getElementById(<span class="string">'char'</span>)</span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> result = <span class="built_in">document</span>.getElementById(<span class="string">'result'</span>)</span></span><br><span class="line"><span class="undefined">    </span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> correct = <span class="number">0</span></span></span><br><span class="line"><span class="javascript">    <span class="keyword">var</span> error = <span class="number">0</span></span></span><br><span class="line"><span class="undefined">    </span></span><br><span class="line"><span class="javascript">    <span class="function"><span class="keyword">function</span> <span class="title">showChar</span>(<span class="params"></span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> random = <span class="built_in">Math</span>.random() * <span class="number">26</span></span></span><br><span class="line"><span class="javascript">        random = <span class="built_in">Math</span>.floor(random) + <span class="number">65</span></span></span><br><span class="line"><span class="javascript">        <span class="comment">// 获取数字在ASCII表中所对应的字母</span></span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> zimu = <span class="built_in">String</span>.fromCharCode(random)</span></span><br><span class="line"><span class="undefined">        char.innerText = zimu</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="javascript">    <span class="comment">// 方法一:</span></span></span><br><span class="line"><span class="javascript">    <span class="built_in">window</span>.onkeyup = <span class="function"><span class="keyword">function</span>(<span class="params">e</span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">if</span>(e.key.toUpperCase() == char.innerText)&#123;</span></span><br><span class="line"><span class="javascript">            char.className = <span class="string">'animated zoomIn'</span></span></span><br><span class="line"><span class="undefined">            showChar()</span></span><br><span class="line"><span class="undefined">            correct += 1 </span></span><br><span class="line"><span class="undefined">            setTimeout(clearAnimation,300)</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">else</span>&#123;</span></span><br><span class="line"><span class="javascript">            char.className = <span class="string">'animated shake error'</span></span></span><br><span class="line"><span class="undefined">            error += 1</span></span><br><span class="line"><span class="undefined">            setTimeout(clearAnimation,300)</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> rate = correct / (correct+error) * <span class="number">100</span></span></span><br><span class="line"><span class="javascript">        result.innerText = <span class="string">'正确个数:'</span>+ correct +<span class="string">',错误个数:'</span>+ error +<span class="string">',正确率:'</span>+rate.toFixed(<span class="number">2</span>)+<span class="string">'%'</span></span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="javascript">    <span class="function"><span class="keyword">function</span> <span class="title">clearAnimation</span>(<span class="params"></span>)</span>&#123;</span></span><br><span class="line"><span class="javascript">        char.className = <span class="string">'animated'</span></span></span><br><span class="line"><span class="undefined">    &#125;  </span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    /*</span></span><br><span class="line"><span class="javascript">    <span class="comment">//   方法二:</span></span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="javascript">    <span class="built_in">window</span>.onkeyup = <span class="function"><span class="keyword">function</span>(<span class="params">e</span>)</span>&#123;  </span></span><br><span class="line"><span class="javascript">        <span class="keyword">if</span>(e.key.toUpperCase() == char.innerText)&#123;</span></span><br><span class="line"><span class="javascript">            $(<span class="string">'#char'</span>).addClass(<span class="string">'zoomIn'</span>)</span></span><br><span class="line"><span class="undefined">            showChar()</span></span><br><span class="line"><span class="javascript">            <span class="comment">// 延时0.3秒钟以后清除动画效果</span></span></span><br><span class="line"><span class="javascript">            <span class="comment">// 否则标签一直有之前的动画效果，那么就不再执行新的动画</span></span></span><br><span class="line"><span class="javascript">            setTimeout(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;$(<span class="string">'#char'</span>).removeClass(<span class="string">'zoomIn'</span>)&#125;,<span class="number">300</span>)</span></span><br><span class="line"><span class="undefined">            correct += 1</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="javascript">        <span class="keyword">else</span>&#123;</span></span><br><span class="line"><span class="javascript">            $(<span class="string">'#char'</span>).addClass(<span class="string">'shake'</span>)</span></span><br><span class="line"><span class="javascript">            $(<span class="string">'#char'</span>).css(<span class="string">'color'</span>,<span class="string">'red'</span>).css(<span class="string">'text-shadow'</span>,<span class="string">'0 0 20px greenyellow'</span>)</span></span><br><span class="line"><span class="javascript">            setTimeout(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;$(<span class="string">'#char'</span>).removeClass(<span class="string">'shake'</span>).css(<span class="string">'color'</span>,<span class="string">'greenyellow'</span>).css(<span class="string">'text-shadow'</span>,<span class="string">'0 0 20px red'</span>)&#125;,<span class="number">300</span>)                 </span></span><br><span class="line"><span class="undefined">            error += 1      </span></span><br><span class="line"><span class="undefined">        &#125;        </span></span><br><span class="line"><span class="javascript">        <span class="keyword">var</span> rate = <span class="built_in">Math</span>.round(correct / (correct+error) * <span class="number">100</span>)</span></span><br><span class="line"><span class="javascript">        $(<span class="string">'#result'</span>).text(<span class="string">'正确个数:'</span>+ correct +<span class="string">',错误个数:'</span>+ error +<span class="string">',正确率:'</span>+rate+<span class="string">'%'</span>)         </span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">    */   </span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>完整代码与样式文件: <a href="https://github.com/accZMT/python_study/tree/html/%E6%89%93%E5%AD%97%E6%B8%B8%E6%88%8F" target="_blank" rel="noopener">点击跳转</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;    &lt;img src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/12.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;blockquote&gt;
&lt;p&gt;制作一个
      
    
    </summary>
    
    
      <category term="html5" scheme="https://acczmt.top/tags/html5/"/>
    
      <category term="js" scheme="https://acczmt.top/tags/js/"/>
    
  </entry>
  
  <entry>
    <title>scrapy_redis</title>
    <link href="https://acczmt.top/2018/08/16/scrapy_redis/"/>
    <id>https://acczmt.top/2018/08/16/scrapy_redis/</id>
    <published>2018-08-16T12:15:00.000Z</published>
    <updated>2018-08-17T02:45:04.970Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/13.jpg?imageView2/2/h/600"><br></div><blockquote><p>使用scrapy_redis的步骤总结，本文以<a href="https://sou.zhaopin.com/?p=1&amp;jl=489" target="_blank" rel="noopener">智联招聘</a>网站为例,通过分析查看，该网站数据为动态加载出来，所以直接获取源码无法达到我们想要的结果。<br>有两种方法解决：</p><blockquote><ol><li>使用scrapy+selenium+PhantomJS </li><li>使用api接口，解析json文件</li></ol></blockquote></blockquote><blockquote><p>这里采用第二种方法。(个人认为第二种比较方便，速度也快)</p></blockquote><p>进入<a href="https://sou.zhaopin.com/?p=1&amp;jl=489" target="_blank" rel="noopener">智联招聘</a>,按F12，依次点击Network、XMR，<code>点击第3页</code>，找到<code>sou?pageSize=120&amp;cityId=489</code>开头的文件后点击，之后再点击<code>Preview</code>可以看到有我们想要的数据。</p><p>找到数据，那么开始构造URL</p><p>点击Headers,可以看到General下有Request URL<br>复制此url,如下:<code>https://fe-api.zhaopin.com/c/i/sou?start=180&amp;pageSize=60&amp;cityId=489&amp;workExperience=-1&amp;education=-1&amp;companyType=-1&amp;employmentType=-1&amp;jobWelfareTag=-1&amp;kt=3&amp;lastUrlQuery=%7B%22p%22:4,%22jl%22:%22489%22%7D</code></p><p><strong><code>重中之中：通过分析智联网站手动修改输入框的页数会自动跳到第一页，刷新也会跳到第一页，根据url可以发现其中有三个重要参数start,pageSize,lastUrlQuery，所以通过修改start和pageSize即可得到每页的数据(如果还是出现数据重复，就把url补全)</code></strong>,</p><p>我们将此url简化后也是可以运行的,此时的pageSize的值改为了100是为了每页获取的数据更多<code>https://fe-api.zhaopin.com/c/i/sou?start=0&amp;pageSize=100&amp;cityId=489&amp;lastUrlQuery=%7B%22p%22:1,%22jl%22:%22489%22%7D</code></p><p>拿到URl后就可以解析数据了，本文目的是使用redis分布式爬虫。</p><blockquote><p>在控制台执行以下语句，创建新的爬虫项目：</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject zhilian</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> zhilian</span><br><span class="line"></span><br><span class="line">scrapy genspider zhoapin zhaopin.com</span><br></pre></td></tr></table></figure><blockquote><p>修改items.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.loader.processors <span class="keyword">import</span> TakeFirst</span><br><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhilianItemLoader</span><span class="params">(ItemLoader)</span>:</span></span><br><span class="line"></span><br><span class="line">    default_output_processor = TakeFirst()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhilianItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    company = scrapy.Field()</span><br><span class="line">    salary = scrapy.Field()</span><br><span class="line">    city = scrapy.Field()</span><br></pre></td></tr></table></figure><blockquote><p>修改spiders/zhaopin.py文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy_redis.spiders <span class="keyword">import</span> RedisCrawlSpider</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> ZhilianItemLoader,ZhilianItem</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhaopinSpider</span><span class="params">(RedisCrawlSpider)</span>:</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">'zhaopin'</span></span><br><span class="line">    allowed_domains = [<span class="string">'zhaopin.com'</span>]</span><br><span class="line"></span><br><span class="line">    redis_key =<span class="string">'zhaopin:start_urls'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        datas = json.loads(response.text)</span><br><span class="line">        data_list = datas[<span class="string">'data'</span>][<span class="string">'results'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            item_loader = ZhilianItemLoader(item=ZhilianItem(),response=response)</span><br><span class="line"></span><br><span class="line">            item_loader.add_value(<span class="string">'title'</span>,data[<span class="string">'jobName'</span>])</span><br><span class="line">            item_loader.add_value(<span class="string">'company'</span>,data[<span class="string">'company'</span>][<span class="string">'name'</span>])</span><br><span class="line">            item_loader.add_value(<span class="string">'salary'</span>,data[<span class="string">'salary'</span>])</span><br><span class="line">            item_loader.add_value(<span class="string">'city'</span>,data[<span class="string">'city'</span>][<span class="string">'display'</span>])</span><br><span class="line"></span><br><span class="line">            item = item_loader.load_item()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><blockquote><p>修改pipelines.py 将获取的数据保存为json文件，最后运行实现分布式爬虫也可以分清楚本机爬了多少条数据</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhilianPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 这里写入文件格式 必须是以二进制 </span></span><br><span class="line">        self.file = open(<span class="string">'zhaopin.json'</span>,<span class="string">'wb'</span>)</span><br><span class="line">        self.exporter = JsonItemExporter(self.file,ensure_ascii=<span class="keyword">False</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.exporter.start_exporting()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.exporter.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.exporter.finish_exporting()</span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure><blockquote><p>修改settings.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定使用scrapy_redis的去重</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定使用scrapy_redis的调度器</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定排序爬取地址时使用的队列，</span></span><br><span class="line"><span class="comment"># 默认的 按优先级排序(Scrapy默认)，由sorted set实现的一种非FIFO、LIFO方式。</span></span><br><span class="line"><span class="comment"># SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.SpiderPriorityQueue'</span></span><br><span class="line"><span class="comment"># 可选的 按先进先出排序（FIFO）</span></span><br><span class="line"><span class="comment"># SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.SpiderQueue'</span></span><br><span class="line"><span class="comment"># 可选的 按后进先出排序（LIFO）</span></span><br><span class="line"><span class="comment"># SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.SpiderStack'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在redis中保持scrapy-redis用到的各个队列，从而允许暂停和暂停后恢复，也就是不清理redis queues</span></span><br><span class="line">SCHEDULER_PERSIST = <span class="keyword">True</span></span><br><span class="line"><span class="comment"># 192.168.52.105为作为master的ip地址，6379为端口号</span></span><br><span class="line">REDIS_URL = <span class="string">'redis://root:@192.168.52.105:6379'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># LOG等级</span></span><br><span class="line"><span class="comment"># LOG_LEVEL = 'DEBUG'</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'zhilian.pipelines.ZhilianPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>:<span class="number">400</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在spiders目录下新建一个get_redis_key.py,添加以下内容。<code>注意运行此代码之前必须保证redis服务器开启</code><br><code>运行成功后将此代码注释掉(个人觉得注释掉心里比较放心)</code>，</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" 此文件目的是将url保存到redis数据库中，以后程序运行会提取该url """</span></span><br><span class="line"><span class="keyword">import</span> redis</span><br><span class="line"></span><br><span class="line"><span class="comment"># REDIS_KEY要和spiders/zhaopin.py下的redis_key一致</span></span><br><span class="line">REDIS_KEY = <span class="string">'zhaopin:start_urls'</span></span><br><span class="line">r = redis.StrictRedis(host=<span class="string">'192.168.52.105'</span>,port=<span class="number">6379</span>)</span><br><span class="line"><span class="comment"># 由于不知道总页数，所以暂时获取501页</span></span><br><span class="line"><span class="keyword">for</span> index,start <span class="keyword">in</span> enumerate(range(<span class="number">0</span>,<span class="number">50001</span>,<span class="number">100</span>)):</span><br><span class="line">    url = <span class="string">'https://fe-api.zhaopin.com/c/i/sou?start='</span>+str(start)+<span class="string">'&amp;pageSize=100&amp;cityId=489&amp;lastUrlQuery=&#123;%22p%22:'</span>+str(index+<span class="number">1</span>)+<span class="string">',%22jl%22:%22489%22&#125;'</span></span><br><span class="line">    r.rpush(REDIS_KEY,url)</span><br></pre></td></tr></table></figure><blockquote><p>在spiders文件下新建main.py，<code>注意运行此代码之前必须保证redis服务器开启</code></p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl zhaopin'</span>.split())</span><br></pre></td></tr></table></figure><blockquote><p>可以将代码发送到另外一台电脑(需要有运行代码的环境)，此时两台电脑同时运行main.py文件。结束后可以查看保存的zhaopin.json文件获取多少条数据。</p></blockquote><blockquote><p>源码放到了GitHub上—&gt; <a href="https://github.com/accZMT/python_study/tree/master/zhilian" target="_blank" rel="noopener">传送门</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/13.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="redis" scheme="https://acczmt.top/tags/redis/"/>
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>Redis基本命令</title>
    <link href="https://acczmt.top/2018/08/14/redis%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"/>
    <id>https://acczmt.top/2018/08/14/redis基本命令/</id>
    <published>2018-08-14T09:52:00.000Z</published>
    <updated>2018-08-16T03:00:00.183Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/14.jpg?imageView2/2/h/600"><br></div><p><strong>Redis 是一个速度非常快的非关系型数据库，使用内存作为主存储，内存中的数据也可以被持久化到硬盘。Redis以键值对形式(key-value)存储数据，其中值可以分为以下5中类型：</strong></p><ul><li><a href="#字符串">字符串(string)</a></li><li><a href="#哈希">哈希(hash)</a></li><li><a href="#列表">列表(list)</a></li><li><a href="#集合">集合(set)</a></li><li><a href="#有序集合">有序集合(zset)</a></li><li><a href="#key">key</a></li></ul><h3 id="Redis-基本命令"><a href="#Redis-基本命令" class="headerlink" title="Redis 基本命令"></a>Redis 基本命令</h3><blockquote><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4></blockquote><p>Redis的字符串(string)可以存储字符串、整数、浮点数。String命令及描述如下表所示：</p><table><thead><tr><th>String命令</th><th>描 述</th></tr></thead><tbody><tr><td>set key value</td><td>设置字符串key的值</td></tr><tr><td>get key</td><td>获取字符串key的值</td></tr><tr><td>del key</td><td>删除key</td></tr><tr><td>strlen key</td><td>获取值长度</td></tr><tr><td>mset key1 value1 key2 value2…</td><td>设置多个值</td></tr><tr><td>mget key1 key2…</td><td>获取多个值</td></tr><tr><td>append key value</td><td>追加值</td></tr><tr><td>incr key</td><td>将key对应的值加一</td></tr><tr><td>decr key</td><td>将key对应的值减一</td></tr><tr><td>incrby key intnum</td><td>将key对应的值加整数</td></tr><tr><td>decrby key intnum</td><td>将key对应的值减整数</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; mset age 30 sex man</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; mget age sex</span><br><span class="line">1) <span class="string">"30"</span></span><br><span class="line">2) <span class="string">"man"</span></span><br><span class="line">127.0.0.1:6379&gt; append name lisi</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line"><span class="string">"lisi"</span></span><br><span class="line">127.0.0.1:6379&gt; strlen name</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; incr age</span><br><span class="line">(<span class="built_in">integer</span>) 31</span><br><span class="line">127.0.0.1:6379&gt; incrby age 10</span><br><span class="line">(<span class="built_in">integer</span>) 41</span><br><span class="line">127.0.0.1:6379&gt; decr age</span><br><span class="line">(<span class="built_in">integer</span>) 40</span><br><span class="line">127.0.0.1:6379&gt; decrby age 20</span><br><span class="line">(<span class="built_in">integer</span>) 20</span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure><blockquote><h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4></blockquote><p>Redis的列表(list)可以有序地存储多个字符串。List命令及描述如下所示：</p><blockquote><p>索引值从0开始 ，可以为负数</p></blockquote><table><thead><tr><th>List命令</th><th>描 述</th></tr></thead><tbody><tr><td>lpush key1 value1 value2 …</td><td>在列表key左端插入一个或者多个值</td></tr><tr><td>rpush key1 value1 value2 …</td><td>在列表key又端插入一个或者多个值</td></tr><tr><td>linsert key before/after pivot value</td><td>在一个元素的前/后插入新的元素</td></tr><tr><td>lset key index value</td><td>设置指定索引的元素值</td></tr><tr><td>lpop key</td><td>在列表key左端弹出一个值</td></tr><tr><td>rpop key</td><td>在列表key右端弹出一个值</td></tr><tr><td>llen key</td><td>获取列表key的长度</td></tr><tr><td>lindex key index</td><td>获取列表key中index位置的值</td></tr><tr><td>lrange key start end</td><td>获取列表key中位置在[start,end]范围的值</td></tr><tr><td>ltrim key start end</td><td>裁剪列表，改为元集合的一个子集</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush fond study game sing</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; lrange fond 0 -1</span><br><span class="line">1) <span class="string">"sing"</span></span><br><span class="line">2) <span class="string">"game"</span></span><br><span class="line">3) <span class="string">"study"</span></span><br><span class="line">127.0.0.1:6379&gt; rpush friends Jane Jack</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; linsert friends after Jack kangkang</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; lrange friends 0 -1</span><br><span class="line">1) <span class="string">"Jane"</span></span><br><span class="line">2) <span class="string">"Jack"</span></span><br><span class="line">3) <span class="string">"kangkang"</span></span><br><span class="line">127.0.0.1:6379&gt; lset fond 2 swim</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lpop fond</span><br><span class="line"><span class="string">"sing"</span></span><br><span class="line">127.0.0.1:6379&gt; rpop friends</span><br><span class="line"><span class="string">"kangkang"</span></span><br><span class="line">127.0.0.1:6379&gt; lrange fond 0 -1</span><br><span class="line">1) <span class="string">"game"</span></span><br><span class="line">2) <span class="string">"swim"</span></span><br><span class="line">127.0.0.1:6379&gt; llen fond</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; lindex fond 0</span><br><span class="line"><span class="string">"game"</span></span><br><span class="line">127.0.0.1:6379&gt; ltrim friends 0 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; lrange friends 0 -1</span><br><span class="line">1) <span class="string">"Jane"</span></span><br><span class="line">2) <span class="string">"Jack"</span></span><br></pre></td></tr></table></figure><blockquote><h4 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h4></blockquote><p>Redis的哈希(Hash)可以存储多个键值对，其中的键和值都是字符串。Hash命令及描述如下表所示：</p><table><thead><tr><th>Hash命令</th><th>描述</th></tr></thead><tbody><tr><td>hset key field value</td><td>将哈希key的field字段赋值为value</td></tr><tr><td>hmset key field1 value1 field2 value2…</td><td>设置多个值</td></tr><tr><td>hdel key field1 field2…</td><td>删除哈希key的一个或多个字段</td></tr><tr><td>hget key field</td><td>获取哈希key的field字段的值</td></tr><tr><td>hmget key field1 field2…</td><td>获取多个属性的值</td></tr><tr><td>hgetall key</td><td>获取哈希key的所有字段和值</td></tr><tr><td>hkeys key</td><td>获取所有属性</td></tr><tr><td>hvals key</td><td>获取所有值</td></tr><tr><td>hlen  key</td><td>返回包含数据的个数</td></tr><tr><td>hexists key field</td><td>判断属性是否存在，存在返回1，不存在返回0</td></tr><tr><td>hstrlen key field</td><td>返回值的字符串长度</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset point x 10</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; hmset point y 20</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; hget point y</span><br><span class="line"><span class="string">"20"</span></span><br><span class="line">127.0.0.1:6379&gt; hmget point</span><br><span class="line">(error) ERR wrong number of argu</span><br><span class="line">127.0.0.1:6379&gt; hmget point x z</span><br><span class="line">1) <span class="string">"10"</span></span><br><span class="line">2) <span class="string">"30"</span></span><br><span class="line">127.0.0.1:6379&gt; hgetall point</span><br><span class="line">1) <span class="string">"x"</span></span><br><span class="line">2) <span class="string">"10"</span></span><br><span class="line">3) <span class="string">"y"</span></span><br><span class="line">4) <span class="string">"20"</span></span><br><span class="line">5) <span class="string">"z"</span></span><br><span class="line">6) <span class="string">"30"</span></span><br><span class="line">127.0.0.1:6379&gt; hkeys point</span><br><span class="line">1) <span class="string">"x"</span></span><br><span class="line">2) <span class="string">"y"</span></span><br><span class="line">3) <span class="string">"z"</span></span><br><span class="line">127.0.0.1:6379&gt; hvals point</span><br><span class="line">1) <span class="string">"10"</span></span><br><span class="line">2) <span class="string">"20"</span></span><br><span class="line">3) <span class="string">"30"</span></span><br><span class="line">127.0.0.1:6379&gt; hlen point</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; hexists point w</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379&gt; hstrlen point x</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; hdel point x y z</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br></pre></td></tr></table></figure><blockquote><h4 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h4></blockquote><p>Redis中的集合(set)可以存储多个唯一的字符串。set命令及描述如下表所示：</p><table><thead><tr><th>set命令</th><th>描 述</th></tr></thead><tbody><tr><td>sadd key member1 member2…</td><td>向集合key中添加一个或多个成员</td></tr><tr><td>srem key member1 member2…</td><td>删除集合key中一个或者多个成员</td></tr><tr><td>smembers key</td><td>获取集合key中所有成员</td></tr><tr><td>scard key</td><td>获取集合key中成员数量</td></tr><tr><td>sismember key menber</td><td>判断member是否是集合key的成员</td></tr><tr><td>sinter key1 key2…</td><td>求多个集合的交集</td></tr><tr><td>sdiff  key1 key2…</td><td>求多个集合的差集</td></tr><tr><td>sunion key1 key2…</td><td>求多个集合的合集</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd color red black blue whi</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; smembers color</span><br><span class="line">1) <span class="string">"black"</span></span><br><span class="line">2) <span class="string">"white"</span></span><br><span class="line">3) <span class="string">"blue"</span></span><br><span class="line">4) <span class="string">"red"</span></span><br><span class="line">127.0.0.1:6379&gt; scard color</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; sismember color yellow</span><br><span class="line">(<span class="built_in">integer</span>) 0</span><br><span class="line">127.0.0.1:6379&gt; sadd colors red blue yellow p</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; sinter color colors</span><br><span class="line">1) <span class="string">"blue"</span></span><br><span class="line">2) <span class="string">"red"</span></span><br><span class="line">127.0.0.1:6379&gt; sdiff color colors</span><br><span class="line">1) <span class="string">"black"</span></span><br><span class="line">2) <span class="string">"white"</span></span><br><span class="line">127.0.0.1:6379&gt; sunion color colors</span><br><span class="line">1) <span class="string">"yellow"</span></span><br><span class="line">2) <span class="string">"black"</span></span><br><span class="line">3) <span class="string">"pink"</span></span><br><span class="line">4) <span class="string">"white"</span></span><br><span class="line">5) <span class="string">"blue"</span></span><br><span class="line">6) <span class="string">"red"</span></span><br><span class="line">127.0.0.1:6379&gt; srem color red black</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br></pre></td></tr></table></figure><blockquote><h4 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h4></blockquote><p>Redis中的有序集合(ZSet)与集合(Set)类似，可以存储多个唯一的字符串，但在有序集合中，每个成员都有一个分数，所有成员按给定分数在集合中有序排列。Zset命令及描述如下图所示：</p><table><thead><tr><th>Zset命令</th><th>描 述</th></tr></thead><tbody><tr><td>zadd key score1 member1 score2 member2…</td><td>向有序集合key中添加一个或多个成员</td></tr><tr><td>zrem key member member2 …</td><td>删除有序集合key中一个或多个成员</td></tr><tr><td>zrange key start stop</td><td>获取有序集合key中位置在[start,end]范围的所有成员</td></tr><tr><td>zrangebyscore key min max</td><td>获取有序集合key中分值在[min,max]范围的所有成员</td></tr><tr><td>zcount key key min max</td><td>获取有序集合key中分值在[min,max]范围的个数</td></tr><tr><td>zcard key</td><td>返回元素的个数</td></tr><tr><td>zscore key member</td><td>返回有序集合key中，成员member的分值</td></tr></tbody></table><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd country 1 China 2 Russia 3 India 4 France</span><br><span class="line">(<span class="built_in">integer</span>) 5</span><br><span class="line">127.0.0.1:6379&gt; zrange country 0 -1</span><br><span class="line">1) <span class="string">"China"</span></span><br><span class="line">2) <span class="string">"Russia"</span></span><br><span class="line">3) <span class="string">"India"</span></span><br><span class="line">4) <span class="string">"France"</span></span><br><span class="line">5) <span class="string">"Italy"</span></span><br><span class="line">127.0.0.1:6379&gt; zrangebyscore country 1 3</span><br><span class="line">1) <span class="string">"China"</span></span><br><span class="line">2) <span class="string">"Russia"</span></span><br><span class="line">3) <span class="string">"India"</span></span><br><span class="line">127.0.0.1:6379&gt; zcount country 1 4</span><br><span class="line">(<span class="built_in">integer</span>) 4</span><br><span class="line">127.0.0.1:6379&gt; zcard country</span><br><span class="line">(<span class="built_in">integer</span>) 5</span><br><span class="line">127.0.0.1:6379&gt; zscore country China</span><br><span class="line"><span class="string">"1"</span></span><br></pre></td></tr></table></figure><blockquote><h4 id="key"><a href="#key" class="headerlink" title="key"></a>key</h4></blockquote><table><thead><tr><th>key命令</th><th>描 述</th></tr></thead><tbody><tr><td>keys pattern</td><td>查找键，参数支持正则</td></tr><tr><td>exists key</td><td>判断键是否存在，如果存在返回1，不存在返回0</td></tr><tr><td>type key</td><td>查看键及对应的值</td></tr><tr><td>del key1 key2 …</td><td>删除键及对应的值</td></tr><tr><td>expire key seconds</td><td>设置过期时间，以秒为单位</td></tr><tr><td>ttl key</td><td>查看有效时间，以秒为单位</td></tr></tbody></table><blockquote><ul><li>更多详细命令请参考官网 <a href="https://redis.io" target="_blank" rel="noopener">https://redis.io</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/14.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="redis" scheme="https://acczmt.top/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>scrapy爬取jobbole</title>
    <link href="https://acczmt.top/2018/08/13/scrapy%E7%88%AC%E5%8F%96jobbole/"/>
    <id>https://acczmt.top/2018/08/13/scrapy爬取jobbole/</id>
    <published>2018-08-13T13:00:00.000Z</published>
    <updated>2018-08-16T03:00:36.856Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/15.jpg?imageView2/2/h/600"><br></div></p><blockquote><p>以jobbole为例，获取<a href="http://blog.jobbole.com/all-posts/" target="_blank" rel="noopener">最新文章</a>中的数据，使用ItemLoader清洗数据，并保存为json文件，下载封面图片</p></blockquote><blockquote><p>打开命令行cd到指定的文件夹，依次执行以下命令</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject jobbole</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> jobbole</span><br><span class="line"></span><br><span class="line">scrapy genspider blog blog.jobbole.com</span><br></pre></td></tr></table></figure><blockquote><p>在items.py 中定义一个JobboleItemLoader类继承ItemLoader </p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.loader <span class="keyword">import</span> ItemLoader</span><br><span class="line"><span class="keyword">from</span> scrapy.loader.processors <span class="keyword">import</span> MapCompose,TakeFirst</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobboleItemLoader</span><span class="params">(ItemLoader)</span>:</span></span><br><span class="line">    <span class="comment"># 设置输出内容的类型</span></span><br><span class="line">    <span class="comment"># 默认返回的数据为一个列表 </span></span><br><span class="line">    <span class="comment"># default_output_processor = ItemLoader.default_output_processor()</span></span><br><span class="line">    <span class="comment"># TakeFirst 获取所有数据当中的第一条数据</span></span><br><span class="line">    default_output_processor = TakeFirst()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取评论、收藏中的数字</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_num</span><span class="params">(value)</span>:</span></span><br><span class="line">    value = value.split(<span class="string">' '</span>)[<span class="number">1</span>]</span><br><span class="line">    value = <span class="number">0</span> <span class="keyword">if</span> value==<span class="string">''</span> <span class="keyword">else</span> int(value)</span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobboleItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    img_src = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    date = scrapy.Field(</span><br><span class="line">        input_processor = MapCompose(<span class="keyword">lambda</span> x:x.strip().replace(<span class="string">' ·'</span>,<span class="string">''</span>))</span><br><span class="line">    )</span><br><span class="line">    detail_url = scrapy.Field()</span><br><span class="line">    like = scrapy.Field(input_processor=MapCompose(<span class="keyword">lambda</span> x:int(x)))</span><br><span class="line">    collect = scrapy.Field(</span><br><span class="line">        input_processor = MapCompose(get_num)</span><br><span class="line">    )</span><br><span class="line">    comment = scrapy.Field(input_processor=MapCompose(get_num))</span><br></pre></td></tr></table></figure><blockquote><p>blog.py 文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> JobboleItem</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> JobboleItemLoader</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BlogSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'blog'</span></span><br><span class="line">    allowed_domains = [<span class="string">'blog.jobbole.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://blog.jobbole.com/all-posts/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        data_list = response.xpath(<span class="string">'//div[@class="post floated-thumb"]'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            img_src = data.xpath(<span class="string">'.//div[@class="post-thumb"]/a/img/@src'</span>).get()</span><br><span class="line">            detail_url = data.xpath(<span class="string">'.//div[@class="post-thumb"]/a/@href'</span>).get()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(detail_url,meta=&#123;<span class="string">"img"</span>:img_src&#125;,callback=self.get_detail_info_with_url)</span><br><span class="line">        <span class="comment"># 获取下一页链接  </span></span><br><span class="line">        <span class="comment"># next_page = response.xpath('//a[@class="next page-numbers"]/@href')</span></span><br><span class="line">        <span class="comment"># if len(next_page) != 0:</span></span><br><span class="line">        <span class="comment">#     yield scrapy.Request(next_page.get(),callback=self.parse)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_detail_info_with_url</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建ItemLoader的实例化对象的时候 需要传入两个参数</span></span><br><span class="line">        <span class="comment"># 参数1：item的实例化对象 item里面为还要提取的数据的字段</span></span><br><span class="line">        <span class="comment"># 参数2：网页的源码</span></span><br><span class="line">        item_loader = JobboleItemLoader(item=JobboleItem(),response=response)</span><br><span class="line"></span><br><span class="line">        item_loader.add_xpath(<span class="string">'title'</span>,<span class="string">'//h1/text()'</span>)</span><br><span class="line">        item_loader.add_value(<span class="string">'img_src'</span>,response.meta[<span class="string">'img'</span>])</span><br><span class="line">        item_loader.add_xpath(<span class="string">'date'</span>,<span class="string">'//p[@class="entry-meta-hide-on-mobile"]/text()'</span>)</span><br><span class="line">        item_loader.add_value(<span class="string">'detail_url'</span>,response.url)</span><br><span class="line">        item_loader.add_xpath(<span class="string">'like'</span>,<span class="string">'//h10/text()'</span>)</span><br><span class="line">        item_loader.add_xpath(<span class="string">'collect'</span>,<span class="string">'//span[contains(@class,"bookmark-btn")]/text()'</span>)</span><br><span class="line">        item_loader.add_xpath(<span class="string">'comment'</span>,<span class="string">'//span[@class="btn-bluet-bigger href-style hide-on-480"]/text()'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将item_loader加载器中保存的每一个field数据收集起来，赋值给item </span></span><br><span class="line">        item = item_loader.load_item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><blockquote><p>pipelines.py 文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonItemExporter</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">""" 使用JsonItemExporter保存json文件"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'blog.json'</span>,<span class="string">'wb'</span>)</span><br><span class="line">        self.export = JsonItemExporter(self.file,ensure_ascii=<span class="keyword">False</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        print(<span class="string">"爬虫开始了"</span>)</span><br><span class="line">        self.export.start_exporting()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self,item,spider)</span>:</span></span><br><span class="line">        self.export.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        self.export.finish_exporting()</span><br><span class="line">        self.file.close()</span><br><span class="line">        print(<span class="string">'爬虫结束了'</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DownloadImagesPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="string">"""继承ImagesPipeline 下载封面图片"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        </span><br><span class="line">        src = item[<span class="string">'img_src'</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=src,meta=&#123;<span class="string">'item'</span>:item[<span class="string">'title'</span>]&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 以标题命名</span></span><br><span class="line">        title = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        <span class="keyword">return</span> title + <span class="string">'.jpg'</span></span><br></pre></td></tr></table></figure><blockquote><p>settings.py 文件</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将爬虫协议改为False</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="comment"># 'jobbole.pipelines.JobbolePipeline': 300,</span></span><br><span class="line">   <span class="string">'jobbole.pipelines.JsonPipeline'</span>: <span class="number">1</span>,</span><br><span class="line">   <span class="string">'jobbole.pipelines.DownloadImagesPipeline'</span>: <span class="number">2</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 图片保存路径</span></span><br><span class="line">IMAGES_STORE = <span class="string">'imgs'</span></span><br></pre></td></tr></table></figure><blockquote><p>在jobbole/jobbole下新建一个main.py文件，直接运行main.py 文件即可</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl blog'</span>.split())</span><br></pre></td></tr></table></figure><p>源码放到了GitHub上<a href="https://github.com/accZMT/python_study/tree/master/jobbole/jobbole" target="_blank" rel="noopener">jobbole项目源码</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/15.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;
      
    
    </summary>
    
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>python+smtp发送email</title>
    <link href="https://acczmt.top/2018/08/10/python+smtp%E5%8F%91%E9%80%81email/"/>
    <id>https://acczmt.top/2018/08/10/python+smtp发送email/</id>
    <published>2018-08-10T11:10:00.000Z</published>
    <updated>2018-08-16T02:59:38.599Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/16.jpg?imageView2/2/h/600"><br></div><p>今天刚学过使用smtplib和email发送邮件，感觉挺有意思的，下面为自己的学习总结</p><p><code>使用python+smtp 需要开启smtp服务，这里使用qq邮箱</code><br><code>密码为第三方登录授权码</code></p><p>1.引入所需要的包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> smtplib</span><br><span class="line"><span class="comment"># 创建包含文本数据的邮件体</span></span><br><span class="line"><span class="keyword">from</span> email.mime.text <span class="keyword">import</span> MIMEText </span><br><span class="line"><span class="comment"># 创建包含图片数据的邮件体</span></span><br><span class="line"><span class="keyword">from</span> email.mime.image <span class="keyword">import</span> MIMEImage</span><br><span class="line"><span class="comment"># 作用是生成包含多个部分的邮件体的MIME对象</span></span><br><span class="line"><span class="keyword">from</span> email.mime.multipart <span class="keyword">import</span> MIMEMultipart</span><br></pre></td></tr></table></figure><p>2.发送纯文本信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置邮箱的域名</span></span><br><span class="line">HOST = <span class="string">"smtp.qq.com"</span></span><br><span class="line"><span class="comment"># 邮件标题</span></span><br><span class="line">SUBJECT = <span class="string">"中午有时间吗"</span></span><br><span class="line"><span class="comment"># 发件人的邮箱</span></span><br><span class="line">FROM = <span class="string">"XXX@qq.com"</span></span><br><span class="line"><span class="comment"># 设置收件人的邮箱</span></span><br><span class="line">TO = <span class="string">'XX@qq.com'</span></span><br><span class="line"><span class="comment"># 发送邮件主体到对方的邮箱中</span></span><br><span class="line"><span class="comment"># 参数1 发送的内容  内容为字符串</span></span><br><span class="line"><span class="comment"># 参数2 内容的类型  文本类型默认为plain</span></span><br><span class="line"><span class="comment"># 参数3 内容的编码方式</span></span><br><span class="line">message_text = MIMEText(<span class="string">'中午一起吃鸡啊'</span>,<span class="string">'plain'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 设置邮件发件人</span></span><br><span class="line">message_text[<span class="string">'From'</span>] = FROM</span><br><span class="line">message_text[<span class="string">'To'</span>] = TO</span><br><span class="line">message_text[<span class="string">'Subject'</span>] = SUBJECT</span><br><span class="line"><span class="comment"># 获取简单邮件传输协议的证书</span></span><br><span class="line">email_client = smtplib.SMTP_SSL()</span><br><span class="line"><span class="comment"># 设置发件人邮件的域名和端口</span></span><br><span class="line">email_client.connect(HOST,<span class="string">'465'</span>)</span><br><span class="line"><span class="comment"># 密码为邮箱授权码</span></span><br><span class="line">result = email_client.login(FROM,<span class="string">'xxx'</span>)</span><br><span class="line">print(<span class="string">"登录结果："</span>,result)</span><br><span class="line"><span class="comment"># 参数依次为是发件人、收件人、邮件内容</span></span><br><span class="line">email_client.sendmail(FROM,TO,message_text.as_string())</span><br><span class="line"><span class="comment"># 关闭邮件发送客户端</span></span><br><span class="line">email_client.close()</span><br></pre></td></tr></table></figure></p><p>3.发送附件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">"smtp.qq.com"</span></span><br><span class="line">FROM = <span class="string">"XXX@qq.com"</span></span><br><span class="line">TO = <span class="string">'XX@qq.com'</span></span><br><span class="line">message_xlsx = MIMEText(open(<span class="string">'table.xlsx'</span>,<span class="string">'rb'</span>).read(),<span class="string">'base64'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 设置文件在附件当中的名字</span></span><br><span class="line">message_xlsx[<span class="string">'Content-Disposition'</span>] = <span class="string">'attachment;filename="test11111.xlsx"'</span></span><br><span class="line">message_xlsx[<span class="string">'From'</span>] = FROM</span><br><span class="line">message_xlsx[<span class="string">'To'</span>] = TO</span><br><span class="line">message_xlsx[<span class="string">'Subject'</span>] = SUBJECT</span><br><span class="line">email_client = smtplib.SMTP_SSL()</span><br><span class="line">email_client.connect(HOST,<span class="string">'465'</span>)</span><br><span class="line">result = email_client.login(FROM,<span class="string">'xxx'</span>)</span><br><span class="line">print(<span class="string">"登录结果："</span>,result)</span><br><span class="line">email_client.sendmail(FROM,TO,message_xlsx.as_string())</span><br><span class="line">email_client.close()</span><br></pre></td></tr></table></figure></p><p>4.发送图片<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">HOST = <span class="string">"smtp.qq.com"</span></span><br><span class="line">FROM = <span class="string">"XXX@qq.com"</span></span><br><span class="line">TO = <span class="string">'XX@qq.com'</span></span><br><span class="line"></span><br><span class="line">message = MIMEMultipart(<span class="string">'related'</span>)</span><br><span class="line"></span><br><span class="line">message_text = MIMEText(<span class="string">'&lt;h1 style="color:blue;font-size=100px"&gt;中午一起吃鸡&lt;/h1&gt;&lt;img src="cid:big"&gt;'</span>,<span class="string">'html'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line">message.attach(message_text)</span><br><span class="line"><span class="comment"># ---------添加图片</span></span><br><span class="line">img_data = open(<span class="string">'timg.gif'</span>,<span class="string">'rb'</span>)</span><br><span class="line"><span class="comment"># 设置读取获取的二进制数据</span></span><br><span class="line">message_img = MIMEImage(img_data.read())</span><br><span class="line">img_data.close()</span><br><span class="line"><span class="comment"># 将图片添加到文本中去</span></span><br><span class="line">message_img.add_header(<span class="string">'Content-ID'</span>,<span class="string">'big'</span>)</span><br><span class="line">message.attach(message_img)</span><br><span class="line"><span class="comment"># -------------发送图片第二种 与添加附件文件的方式一样</span></span><br><span class="line">message_img = MIMEText(open(<span class="string">'timg.gif'</span>,<span class="string">'rb'</span>).read(),<span class="string">'base64'</span>,<span class="string">'utf-8'</span>)</span><br><span class="line">message_img[<span class="string">'Content-disposition'</span>] = <span class="string">'attachment;filename="happy.gif"'</span></span><br><span class="line">message.attach(message_img)</span><br><span class="line"></span><br><span class="line">message[<span class="string">'From'</span>] = FROM</span><br><span class="line">message[<span class="string">'To'</span>] = TO</span><br><span class="line">message[<span class="string">'Subject'</span>] = SUBJECT</span><br><span class="line"></span><br><span class="line">email_client = smtplib.SMTP_SSL()</span><br><span class="line">email_client.connect(HOST,<span class="string">'465'</span>)</span><br><span class="line">result = email_client.login(FROM,<span class="string">'xxx'</span>)</span><br><span class="line">print(<span class="string">"登录结果："</span>,result)</span><br><span class="line">email_client.sendmail(FROM,TO,message.as_string())</span><br><span class="line">email_client.close()</span><br></pre></td></tr></table></figure></p><p>5.群发邮件</p><p>只需要修改收件人字段和sendmail里面的TO字段，如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TO = <span class="string">'xxxxx@163.com,xxx@qq.com'</span></span><br><span class="line"></span><br><span class="line">email_client.sendmail(FROM,TO.split(<span class="string">','</span>),message.as_string())</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/16.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="smtp" scheme="https://acczmt.top/tags/smtp/"/>
    
      <category term="email" scheme="https://acczmt.top/tags/email/"/>
    
  </entry>
  
  <entry>
    <title>安装mySQL版本5.6.41.0</title>
    <link href="https://acczmt.top/2018/08/09/%E5%AE%89%E8%A3%85mySQL%E7%89%88%E6%9C%AC5.6/"/>
    <id>https://acczmt.top/2018/08/09/安装mySQL版本5.6/</id>
    <published>2018-08-09T13:30:00.000Z</published>
    <updated>2018-08-10T00:51:41.744Z</updated>
    
    <content type="html"><![CDATA[<p>下载mySQL版本5.6.41.0可以从<a href="https://dev.mysql.com/downloads/windows/installer/5.6.html" target="_blank" rel="noopener">官网</a>下载，也可以选择百度云盘<a href="https://pan.baidu.com/s/1gu3c3xdZUvW2AilnhfZ--Q" target="_blank" rel="noopener">链接</a>密码：habz</p><p>下载完成后直接点击安装，下面为安装步骤：</p><ul><li><p>1.进入第一个界面，点击I accept license terms, 然后点击next</p></li><li><p>2.此时进入下个界面，根据个人需求选择不同的选项，这里选择Developer Default，点击next</p></li></ul><p><img src="/img/mysql/1.jpg" alt="Developer Default"></p><ul><li>3.直接点击next,会弹出一个提示框，点击Yes</li></ul><p><img src="/img/mysql/3.jpg" alt="MySQL Install"></p><ul><li>4.点击Execute,等待下载插件,完成之后点击finish</li></ul><p><img src="/img/mysql/4.jpg" alt="Installation"></p><ul><li>5.一路点击next,直到配置密码，密码根据需要配置如：123456</li></ul><p><img src="/img/mysql/7.jpg" alt="Password"></p><ul><li>6.点击next,至下面界面，点击Execute,安装完成后点击finish</li></ul><p><img src="/img/mysql/8.jpg" alt="Apply Configuration"></p><ul><li>7.一路点击next,在下图Password中输入第五步设置的密码，完成后点击next</li></ul><p><img src="/img/mysql/9.jpg" alt="input password"></p><ul><li>8.点击Execute，等待安装,完成之后点击finish</li></ul><p><img src="/img/mysql/11.png" alt="Apply Configuration"></p><ul><li>9.最后出现以下界面</li></ul><p><img src="/img/mysql/12.png" alt="Apply Configuration"></p><ul><li>10.点击Local instance MySQL56 输入设置的密码进入workbench中</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;下载mySQL版本5.6.41.0可以从&lt;a href=&quot;https://dev.mysql.com/downloads/windows/installer/5.6.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官网&lt;/a&gt;下载，也可以选择百度云
      
    
    </summary>
    
    
      <category term="mySQL" scheme="https://acczmt.top/tags/mySQL/"/>
    
  </entry>
  
  <entry>
    <title>pymysql存储中文数据出错解决方法</title>
    <link href="https://acczmt.top/2018/08/08/pymysql%E5%AD%98%E5%82%A8%E4%B8%AD%E6%96%87%E6%95%B0%E6%8D%AE%E5%87%BA%E9%94%99%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <id>https://acczmt.top/2018/08/08/pymysql存储中文数据出错解决方法/</id>
    <published>2018-08-08T14:30:00.000Z</published>
    <updated>2018-08-16T02:59:21.735Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/17.jpg?imageView2/2/h/600"><br></div><h2 id="pymysql存储中文数据出错解决方法"><a href="#pymysql存储中文数据出错解决方法" class="headerlink" title="pymysql存储中文数据出错解决方法"></a>pymysql存储中文数据出错解决方法</h2><ul><li><p>错误类型：<code>pymysql.err.InternalError: (1366, &quot;Incorrect string value: &#39;\\xE5\\x82\\xB2\\xE5\\xA8\\x87...&#39; for column &#39;name&#39; at row 1&quot;)</code></p></li><li><p>原因为不能把中文存入数据库：但是代码中也添加了charset=”utf8”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">    self.conn = pymysql.connect(host=<span class="string">'localhost'</span>,port=<span class="number">3306</span>,user=<span class="string">'root'</span>,</span><br><span class="line">                                password=<span class="string">'123456'</span>,db=<span class="string">"hongxiudb"</span>,charset=<span class="string">'utf8'</span>)</span><br><span class="line">    self.cursor = self.conn.cursor()</span><br></pre></td></tr></table></figure></li><li><p>之后我将charset改为了charset=”utf-8”，结果还是不如人意，继续出错：</p></li><li><p><code>AttributeError: &#39;NoneType&#39; object has no attribute &#39;encoding&#39;</code></p></li><li><p>找到了自己的原因为创建数据表时没有指定charset。</p></li><li><p><code>解决方法为：</code></p></li><li><p>创建数据表时指定charset=utf8，如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> hongxiudb;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> hongxiu(</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">text</span>,</span><br><span class="line">author <span class="built_in">text</span>,</span><br><span class="line">intro <span class="built_in">text</span></span><br><span class="line">)<span class="keyword">engine</span>=<span class="keyword">InnoDB</span> <span class="keyword">default</span> <span class="keyword">charset</span>=utf8;</span><br></pre></td></tr></table></figure></li><li><p>连接数据代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">    self.conn = pymysql.connect(host=<span class="string">'localhost'</span>,port=<span class="number">3306</span>,user=<span class="string">'root'</span>,</span><br><span class="line">                                password=<span class="string">'123456'</span>,db=<span class="string">"hongxiudb"</span>,charset=<span class="string">'utf8'</span>)</span><br><span class="line">    self.cursor = self.conn.cursor()</span><br></pre></td></tr></table></figure></li><li><p>最后程序完美的执行结束。</p></li><li><p>出错原因还是因为自己不细心，没有好的编码规范。下次一定要将代码写全，不要因为少写几句代码而出错耽误更多的时间。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/17.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="python" scheme="https://acczmt.top/tags/python/"/>
    
      <category term="pymysql" scheme="https://acczmt.top/tags/pymysql/"/>
    
  </entry>
  
  <entry>
    <title>scrapy + json保存</title>
    <link href="https://acczmt.top/2018/08/07/scrapy+json%E4%BF%9D%E5%AD%98/"/>
    <id>https://acczmt.top/2018/08/07/scrapy+json保存/</id>
    <published>2018-08-07T14:23:00.000Z</published>
    <updated>2018-08-17T01:13:28.138Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/18.jpg?imageView2/2/h/600"><br></div><h3 id="本篇博客目的："><a href="#本篇博客目的：" class="headerlink" title="* 本篇博客目的："></a>* 本篇博客目的：</h3><p>练习使用scrapy，并将获取的信息存储为json格式，以获取<a href="http://www.hongxiu.com/all?gender=2&amp;catId=-1" target="_blank" rel="noopener">红袖小说</a>信息为例</p><ul><li><strong>在命令行新建一个项目</strong>  </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject hongxiu</span><br><span class="line">cd hongxiu</span><br><span class="line">scrapy genspider novel www.hongxiu.com</span><br></pre></td></tr></table></figure><ul><li><strong>打开编辑器修改items.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HongxiuItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    img_src = scrapy.Field()</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    novel_type = scrapy.Field()</span><br><span class="line">    vip = scrapy.Field()</span><br><span class="line">    total_word = scrapy.Field()</span><br><span class="line">    total_collect = scrapy.Field()</span><br><span class="line">    total_click = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure><ul><li><strong>spiders/novel.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> HongxiuItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NovelSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'novel'</span></span><br><span class="line">    allowed_domains = [<span class="string">'www.hongxiu.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://www.hongxiu.com/all?gender=2&amp;catId=-1'</span>]</span><br><span class="line">    base_url = <span class="string">'http://www.hongxiu.com'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        <span class="string">"""获取分类的Id，每个分类的第一页链接"""</span></span><br><span class="line">        type_list_url = response.xpath(<span class="string">'//ul[@type="category"]/li/a/@href'</span>).extract()</span><br><span class="line">        catid = response.xpath(<span class="string">'//ul[@type="category"]/li/@data-id'</span>).extract()</span><br><span class="line">        <span class="keyword">del</span> type_list_url[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">del</span> catid[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> x,t <span class="keyword">in</span> zip(type_list_url,catid):</span><br><span class="line">            url = self.base_url + x</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url,meta=&#123;<span class="string">"type"</span>:t&#125;,callback=self.get_content_with_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_content_with_url</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        <span class="string">"""获取十个分类的前十页链接"""</span></span><br><span class="line">        <span class="keyword">for</span> page_num <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">11</span>):</span><br><span class="line">            catId = response.meta[<span class="string">'type'</span>]</span><br><span class="line">            url = <span class="string">f"https://www.hongxiu.com/all?pageNum=<span class="subst">&#123;page_num&#125;</span>&amp;pageSize=10&amp;gender=2&amp;catId=<span class="subst">&#123;catId&#125;</span>&amp;isFinish=-1&amp;isVip=-1&amp;size=-1&amp;updT=-1&amp;orderBy=0"</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url,callback=self.get_novel_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_novel_url</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""获取小说的详情链接"""</span></span><br><span class="line">        novel_url_list = response.xpath(<span class="string">'//div[@class="book-info"]/h3/a/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> novel_url <span class="keyword">in</span> novel_url_list:</span><br><span class="line">            url = self.base_url + novel_url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.get_novel_detail_info)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_novel_detail_info</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""获取小说信息"""</span></span><br><span class="line">        <span class="comment"># 注意：response.xpath('//div[@class="book-img"]/a/img/@src').extract()[0]获取到的src值后面有一个\r,所以使用replace('\r', '')</span></span><br><span class="line">        img_src = <span class="string">'https:'</span> + response.xpath(<span class="string">'//div[@class="book-img"]/a/img/@src'</span>).extract()[<span class="number">0</span>].replace(<span class="string">'\r'</span>, <span class="string">''</span>)</span><br><span class="line">        title = response.xpath(<span class="string">'//h1/em/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        author = response.xpath(<span class="string">'//h1/a/text()'</span>).extract()[<span class="number">0</span>].split()[<span class="number">0</span>]</span><br><span class="line">        tags = response.xpath(<span class="string">'//p[@class="tag-box"]/span[@class="tag"]'</span>)[<span class="number">0</span>]</span><br><span class="line">        novel_type = tags.xpath(<span class="string">'//i[@class="blue"]/text()'</span>)[<span class="number">0</span>].extract()</span><br><span class="line">        vip = tags.xpath(<span class="string">'//i[@class="org"]/text()'</span>).extract()</span><br><span class="line">        vip = <span class="string">"免费"</span> <span class="keyword">if</span> len(vip) == <span class="number">0</span> <span class="keyword">else</span> vip[<span class="number">0</span>]</span><br><span class="line">        total_word = response.xpath(<span class="string">'//p[@class="total"]/span[1]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        total_collect = response.xpath(<span class="string">'//p[@class="total"]/span[2]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        total_click = response.xpath(<span class="string">'//p[@class="total"]/span[last()]/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        content = <span class="string">''</span></span><br><span class="line">        content_list = response.xpath(<span class="string">'//div[@class="book-information cf"]//p[@class="intro"]/text()'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> con <span class="keyword">in</span> content_list:</span><br><span class="line">            content += con</span><br><span class="line"></span><br><span class="line">        item = HongxiuItem()</span><br><span class="line">        item[<span class="string">'img_src'</span>] = [img_src]</span><br><span class="line">        item[<span class="string">"title"</span>] = title</span><br><span class="line">        item[<span class="string">"author"</span>] = author</span><br><span class="line">        item[<span class="string">"novel_type"</span>] = novel_type</span><br><span class="line">        item[<span class="string">'vip'</span>] = vip</span><br><span class="line">        item[<span class="string">"total_word"</span>] = total_word</span><br><span class="line">        item[<span class="string">"total_collect"</span>] = total_collect</span><br><span class="line">        item[<span class="string">"total_click"</span>] = total_click</span><br><span class="line">        item[<span class="string">"content"</span>] = content</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><ul><li><strong>修改pipelines.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用来打开指定文件 并且对文件进行转码 防止出现乱码问题</span></span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XiaoshuoPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># w+ ,r+ 读写文件</span></span><br><span class="line">        <span class="comment"># 前者读写文件 如果文件不存在 则创建</span></span><br><span class="line">        <span class="comment"># 后者读写文件 如果文件不存在 则抛出异常</span></span><br><span class="line">        self.file = codecs.open(filename=<span class="string">'book.json'</span>,mode=<span class="string">'w+'</span>,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment">#     如果想要将数据写入本地或者是使用数据库的时候，这个方法需要保留</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="string">"""spider打开时（处理数据前）回调该方法，</span></span><br><span class="line"><span class="string">        通常该方法用于在开始处理数据之前，完成某些初始化工作"""</span></span><br><span class="line">        self.file.write(<span class="string">'&#123;"list":['</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="string">"""spider关闭时（处理数据后）回调该方法，</span></span><br><span class="line"><span class="string">        通常该方法用于在处理完所有数据之后，完成某些清理工作"""</span></span><br><span class="line">        print(<span class="string">"爬虫结束了"</span>)</span><br><span class="line">        self.file.seek(<span class="number">-1</span>,os.SEEK_END)</span><br><span class="line">        self.file.truncate()</span><br><span class="line">        self.file.seek(<span class="number">-1</span>,os.SEEK_END)</span><br><span class="line">        self.file.truncate()</span><br><span class="line">        self.file.write(<span class="string">']&#125;'</span>)</span><br><span class="line">        self.file.close()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># dumps 将字典对象转化为字符串  ASCII编码是否可用</span></span><br><span class="line">        <span class="comment"># 如果 直接将字典形式的数据写入文件当中 会发生错误</span></span><br><span class="line">        <span class="comment"># 所以需要将字典形式的值 转化成字符串的格式写入文件当中</span></span><br><span class="line">        result = json.dumps(dict(item),ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">        self.file.write(result)</span><br><span class="line">        self.file.write(<span class="string">",\n"</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>settings.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'hongxiu.pipelines.HongxiuPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>在spiders文件下新建main.py文件，添加内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl novel'</span>.split())</span><br></pre></td></tr></table></figure><ul><li><strong>最后右键运行main.py文件即可,运行结束之后会生成一个book.json文件</strong></li><li><strong>验证是否为json文件，将book.json文件拖入火狐浏览器查看，如下所示即为成功</strong><br><img src="/img/sucai/json验证.jpg" alt="json验证"></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/18.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>scrapy实现下载图片</title>
    <link href="https://acczmt.top/2018/08/07/scrapy%E7%BB%83%E4%B9%A0/"/>
    <id>https://acczmt.top/2018/08/07/scrapy练习/</id>
    <published>2018-08-07T11:30:00.000Z</published>
    <updated>2018-08-17T02:06:28.538Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/19.jpg?imageView2/2/h/600"><br></div></p><h3 id="本篇博客目的："><a href="#本篇博客目的：" class="headerlink" title="* 本篇博客目的："></a>* 本篇博客目的：</h3><p>练习使用scrapy，获取站长素材中的所有<a href="http://sc.chinaz.com/tubiao/" target="_blank" rel="noopener">图标</a>图片,并重写ImagesPipeline，实现分类保存</p><ul><li><strong>在命令行新建一个项目</strong>  </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject zhanzhangsucai</span><br><span class="line">cd zhanzhangsucai</span><br><span class="line">scrapy genspider chinaz sc.chinaz.com</span><br></pre></td></tr></table></figure><ul><li><strong>打开编辑器修改items.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZhanzhangsucaiItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line"></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    src = scrapy.Field()</span><br></pre></td></tr></table></figure><ul><li><strong>spiders/chinaz.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span> ZhanzhangsucaiItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ChinazSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'chinaz'</span></span><br><span class="line">    allowed_domains = [<span class="string">'sc.chinaz.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://sc.chinaz.com/tubiao/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">"""获取所有图片"""</span></span><br><span class="line">        href_list = response.xpath(<span class="string">'//li/span/a/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> href_list:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=href,callback=self.get_detail_img_url)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取下一页</span></span><br><span class="line">        next_page = response.xpath(<span class="string">'//a[@class="nextpage"]/@href'</span>).extract()</span><br><span class="line">        <span class="keyword">if</span> len(next_page) != <span class="number">0</span>:</span><br><span class="line">            next_url = <span class="string">'http://sc.chinaz.com/tubiao/'</span> + next_page[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_detail_img_url</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        title = response.xpath(<span class="string">'//div[@class="text_wrap"]/h2/a/text()'</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        srcs = response.xpath(<span class="string">'//div[@class="png_pic"]/img/@src'</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> src <span class="keyword">in</span> srcs:</span><br><span class="line">            item = ZhanzhangsucaiItem()</span><br><span class="line">            item[<span class="string">'title'</span>] = title</span><br><span class="line">            item[<span class="string">'src'</span>] = [src]</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><ul><li><strong>pipelines.py文件,删除原来的内容，添加新的内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IconPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="comment"># for src in item['src']:</span></span><br><span class="line">        src = item[<span class="string">'src'</span>][<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=src,meta=&#123;<span class="string">'item'</span>:item&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 管道里面提供了一系列的内置方法，这些方法会自动从第一个执行到最后一个</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line"></span><br><span class="line">        item = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        title = item[<span class="string">'title'</span>]</span><br><span class="line">        src = item[<span class="string">'src'</span>][<span class="number">0</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># for index,src in enumerate(srcs):</span></span><br><span class="line">        path = <span class="string">'%s/%s.ico'</span> % (title,src)</span><br><span class="line">        <span class="keyword">return</span> path</span><br></pre></td></tr></table></figure><ul><li><strong>settings.py文件内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">False</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'zhanzhangsucai.pipelines.IconPipeline'</span>: <span class="number">1</span>,</span><br><span class="line">&#125;</span><br><span class="line">IMAGES_STORE = <span class="string">'../imgs'</span></span><br></pre></td></tr></table></figure><ul><li><strong>在spiders文件下新建main.py文件，添加内容为：</strong> </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> cmdline</span><br><span class="line"></span><br><span class="line">cmdline.execute(<span class="string">'scrapy crawl chinaz'</span>.split())</span><br></pre></td></tr></table></figure><ul><li><strong>最后右键运行main.py文件即可，图片最少有14万张，比较费时</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/19.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="scrapy" scheme="https://acczmt.top/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>selenium基础用法</title>
    <link href="https://acczmt.top/2018/08/02/selenium%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/"/>
    <id>https://acczmt.top/2018/08/02/selenium基础用法/</id>
    <published>2018-08-01T19:30:20.000Z</published>
    <updated>2018-08-17T02:03:47.435Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/22.jpg?imageView2/2/h/600"><br></div><ul><li><p>在上篇笔记中已经写下如何安装selenium以及配置浏览器驱动，传送门<a href="https://acczmt.top/2018/07/31/selenium%E5%AE%89%E8%A3%85/#more">selenium 安装</a>,下面会介绍selenium的基础用法。</p></li><li><p>以百度链接为例，由于selenium加载受到网速的影响，所以网速差运行可能会较慢或者出错</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="1、查找元素的方法"><a href="#1、查找元素的方法" class="headerlink" title="1、查找元素的方法"></a>1、查找元素的方法</h2><ul><li><p>selenium提供了查找元素的方法 find_<figure class="highlight plain"><figcaption><span>和find_```elements```_by_XXX,注意这两种的区别，一个后面有s,一个没有s。这个问题很容易就出错。</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">* find_```element```_by_XXX 表示查找第一个符合条件的元素</span><br><span class="line">```python</span><br><span class="line"># driver.find_element_by_class_name() 根据标签中的class属性进行查找</span><br><span class="line"># driver.find_element_by_id() 根据标签中的id属性进行查找</span><br><span class="line"># driver.find_element_by_name()  根据标签中的name属性进行查找</span><br><span class="line"># driver.find_element_by_tag_name() 根据标签名进行查找</span><br><span class="line"># driver.find_element_by_css_selector()  根据css选择器进行查找</span><br><span class="line"># driver.find_element_by_xpath()  根据xpath语法进行查找</span><br><span class="line"># driver.find_element_by_link_text()  根据链接中的文本内容进行查找</span><br><span class="line"># driver.find_element_by_partial_link_text()  根据链接中的部分文本内容进行查找</span><br></pre></td></tr></table></figure></p></li><li><p>find_<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">* 获取文本框的id属性值，在网页中定位到文本框的位置，清空文本框中的值，然后在输入selenium，如下所示：</span><br><span class="line">```python</span><br><span class="line">driver.find_element_by_id(&apos;kw&apos;).clear() #clear() 表示清空当前文本框的值</span><br><span class="line">driver.find_element_by_id(&apos;kw&apos;).send_keys(&apos;selenium&apos;) #send_keys()表示在文本框中输入内容</span><br></pre></td></tr></table></figure></p></li><li><p>定位到该按钮的位置，然后模拟点击</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_id(<span class="string">'su'</span>).click()  <span class="comment">#click() 表示点击一次</span></span><br></pre></td></tr></table></figure></li><li><p>简单的模拟浏览器就完成啦，接下来学习各个查找元素方法的使用</p></li><li><p>以获取百度首页中的新闻为例，各种方法的使用如下，如果想使用哪种需要解注释，然后将其它注释掉即可</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)  <span class="comment">#隐式等待十秒 </span></span><br><span class="line"> </span><br><span class="line">driver.find_element_by_class_name(<span class="string">'mnav'</span>).click()</span><br><span class="line"><span class="comment"># driver.find_element_by_name("tj_trnews").click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_css_selector('#u1 a').click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_xpath('//div[@id="u1"]/a').click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_link_text('新闻').click()</span></span><br><span class="line"><span class="comment"># driver.find_element_by_partial_link_text('新').click()</span></span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br><span class="line">driver.close() <span class="comment">#关闭窗口</span></span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">driver.quit()  <span class="comment">#关闭浏览器</span></span><br></pre></td></tr></table></figure><h2 id="2、获取属性值与文本内容"><a href="#2、获取属性值与文本内容" class="headerlink" title="2、获取属性值与文本内容"></a>2、获取属性值与文本内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)  <span class="comment">#隐式等待十秒</span></span><br><span class="line"> </span><br><span class="line">content = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).text <span class="comment">#获取文本text的值 </span></span><br><span class="line">print(content)</span><br><span class="line">name_attr = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).get_attribute(<span class="string">'name'</span>) <span class="comment">#获取name属性值</span></span><br><span class="line">print(name_attr)</span><br><span class="line">class_attr = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).get_attribute(<span class="string">'class'</span>)  <span class="comment">#获取class属性值</span></span><br><span class="line">print(class_attr)</span><br><span class="line">href_attr = driver.find_element_by_xpath(<span class="string">'//div[@id="u1"]/a'</span>).get_attribute(<span class="string">'href'</span>)  <span class="comment">#获取href属性值</span></span><br><span class="line">print(href_attr)</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出结果为：</span></span><br><span class="line"><span class="comment"># 新闻</span></span><br><span class="line"><span class="comment"># tj_trnews</span></span><br><span class="line"><span class="comment"># mnav</span></span><br><span class="line"><span class="comment"># http://news.baidu.com/</span></span><br></pre></td></tr></table></figure><h2 id="3、window切换"><a href="#3、window切换" class="headerlink" title="3、window切换"></a>3、window切换</h2><ul><li>主要练习对窗口的切换，代码中有注释</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Chrome()  <span class="comment">#个人火狐浏览器加载不出来，所以使用谷歌</span></span><br><span class="line">driver.get(<span class="string">"http://www.baidu.com"</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取当前的window对象</span></span><br><span class="line">current_win = driver.current_window_handle</span><br><span class="line"><span class="comment"># current_win 当前网页的编号 driver.title 网页标题</span></span><br><span class="line">print(current_win,driver.title)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 点击首页新闻链接</span></span><br><span class="line">driver.find_element_by_link_text(<span class="string">'新闻'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 找到第一篇文章，然后点击查看</span></span><br><span class="line">driver.find_element_by_css_selector(<span class="string">'li.hdline0 a'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 此时浏览器会有两个窗口</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 获取所有的窗口</span></span><br><span class="line">all_windows = driver.window_handles</span><br><span class="line"><span class="comment"># 判断</span></span><br><span class="line"><span class="keyword">for</span> window <span class="keyword">in</span> all_windows:</span><br><span class="line">    <span class="keyword">if</span> window != current_win:</span><br><span class="line">        <span class="comment"># 切换到第二个窗口</span></span><br><span class="line">        driver.switch_to.window(window)</span><br><span class="line"><span class="comment"># 获取新闻标题 并输出，验证是否切换成功</span></span><br><span class="line">title = driver.find_element_by_css_selector(<span class="string">'.text_title h1'</span>).text</span><br><span class="line">print(title)</span><br><span class="line"><span class="comment"># 关闭当前窗口，即关闭新闻详细页面的窗口</span></span><br><span class="line">driver.close()</span><br><span class="line"><span class="comment"># 切换到新闻首页窗口</span></span><br><span class="line">driver.switch_to.window(current_win)</span><br><span class="line"><span class="comment"># 输出一条信息，验证是否切换成功</span></span><br><span class="line">print(driver.find_element_by_css_selector(<span class="string">'#footer span'</span>).text)</span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">driver.quit()</span><br></pre></td></tr></table></figure><h3 id="学习到这里只是selenium的冰山一角，更多功能还会继续学习"><a href="#学习到这里只是selenium的冰山一角，更多功能还会继续学习" class="headerlink" title="学习到这里只是selenium的冰山一角，更多功能还会继续学习"></a>学习到这里只是selenium的冰山一角，更多功能还会继续学习</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/22.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>selenium获取美食杰信息</title>
    <link href="https://acczmt.top/2018/08/01/selenium%E8%8E%B7%E5%8F%96%E7%BE%8E%E9%A3%9F%E6%9D%B0%E4%BF%A1%E6%81%AF/"/>
    <id>https://acczmt.top/2018/08/01/selenium获取美食杰信息/</id>
    <published>2018-08-01T15:10:00.000Z</published>
    <updated>2018-08-17T02:05:44.649Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/21.jpg?imageView2/2/h/600"><br></div><ul><li><p>学习目的：练习selenium的用法，获取<a href="http://www.meishij.net/" target="_blank" rel="noopener">美食杰</a>—&gt;菜谱大全—&gt;<a href="https://www.meishij.net/chufang/diy/zaocan/" target="_blank" rel="noopener">早餐</a> 页面中的菜名以及作者名，保存到TXT文件中</p></li><li><p>1、首先引入所需要的包</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.common.action_chains <span class="keyword">import</span> ActionChains <span class="comment">#模拟鼠标</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br></pre></td></tr></table></figure></li><li><p>2、打开美食杰的首页，隐式等待十秒，等待页面加载完成</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'https://www.meishij.net/'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></li><li><p>3、通过查找到&lt;菜谱大全&gt;在网页中的位置，模拟鼠标移动到&lt;菜谱大全&gt;上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cai_pu = driver.find_element_by_css_selector(<span class="string">'li.hasmore a.link.pngFix'</span>)</span><br><span class="line">ActionChains(driver).move_to_element(cai_pu).perform()</span><br></pre></td></tr></table></figure></li><li><p>4、找到&lt;早餐&gt;,并自动点击跳转到&lt;早餐&gt;页面上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">driver.find_element_by_link_text(<span class="string">'早餐'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br></pre></td></tr></table></figure></li><li><p>5、模拟鼠标下拉滑动条</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用js控制滑动条</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">7</span>,<span class="number">2</span>):</span><br><span class="line">    x = float(row) / <span class="number">6</span></span><br><span class="line">    js = <span class="string">'document.documentElement.scrollTop = document.documentElement.scrollHeight * %f'</span>%x</span><br><span class="line">    driver.execute_script(js)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p>6、获取早餐美食的信息，保存到meishijie.txt 文件中</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">info_lists = driver.find_elements_by_css_selector(<span class="string">'div.c1'</span>)</span><br><span class="line"><span class="keyword">for</span> info <span class="keyword">in</span> info_lists:</span><br><span class="line">    name = info.find_element_by_tag_name(<span class="string">'strong'</span>).text</span><br><span class="line">    author = info.find_element_by_tag_name(<span class="string">'em'</span>).text</span><br><span class="line">    <span class="comment"># print(name + "--&gt;" +author)</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'meishijie.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(name+<span class="string">"--&gt;"</span>+author+<span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure><ul><li>7、以下是完整代码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.common.action_chains <span class="keyword">import</span> ActionChains <span class="comment">#模拟鼠标</span></span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'https://www.meishij.net/'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line">cai_pu = driver.find_element_by_css_selector(<span class="string">'li.hasmore a.link.pngFix'</span>)</span><br><span class="line">ActionChains(driver).move_to_element(cai_pu).perform()</span><br><span class="line">driver.find_element_by_link_text(<span class="string">'早餐'</span>).click()</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#只获取前三页数据，要获取多页只需修改range值</span></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">4</span>):</span><br><span class="line">    print(<span class="string">f"正在获取第<span class="subst">&#123;page&#125;</span>页"</span>)</span><br><span class="line">    <span class="comment"># 使用js控制滑动条</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">7</span>,<span class="number">2</span>):</span><br><span class="line">        x = float(row) / <span class="number">6</span></span><br><span class="line">        js = <span class="string">'document.documentElement.scrollTop = document.documentElement.scrollHeight * %f'</span>%x</span><br><span class="line">        driver.execute_script(js)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">    info_lists = driver.find_elements_by_css_selector(<span class="string">'div.c1'</span>)</span><br><span class="line">    <span class="keyword">for</span> info <span class="keyword">in</span> info_lists:</span><br><span class="line">        name = info.find_element_by_tag_name(<span class="string">'strong'</span>).text</span><br><span class="line">        author = info.find_element_by_tag_name(<span class="string">'em'</span>).text</span><br><span class="line">        <span class="comment"># print(name + "--&gt;" +author)</span></span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'meishijie.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(name+<span class="string">"--&gt;"</span>+author+<span class="string">"\n"</span>)</span><br><span class="line">    <span class="comment"># 点击下一页链接</span></span><br><span class="line">    next_page = driver.find_element_by_class_name(<span class="string">'next'</span>)</span><br><span class="line">    <span class="keyword">if</span> next_page:</span><br><span class="line">        next_page.click()</span><br><span class="line">    <span class="keyword">else</span>:print(<span class="string">"已经最后一页了"</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">driver.quit()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/21.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>selenium安装</title>
    <link href="https://acczmt.top/2018/07/31/selenium%E5%AE%89%E8%A3%85/"/>
    <id>https://acczmt.top/2018/07/31/selenium安装/</id>
    <published>2018-07-31T13:50:00.000Z</published>
    <updated>2018-08-17T02:05:31.736Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/23.jpg?imageView2/2/h/600"><br></div><h2 id="selenium-是一个自动化测试工具"><a href="#selenium-是一个自动化测试工具" class="headerlink" title="selenium 是一个自动化测试工具"></a>selenium 是一个自动化测试工具</h2><h2 id="selenium的特点："><a href="#selenium的特点：" class="headerlink" title="selenium的特点："></a>selenium的特点：</h2><ul><li>1.由程序控制浏览器进行操作，而不是手动操作浏览器</li><li>2.程序控制浏览器进行操作的时候，速度非常慢，所以要谨慎使用selenium</li><li>3.使用selenium控制浏览器的时候，需要下载浏览器对应的驱动程序</li><li>4.selenium为开源，免费，但是更新速度没有浏览器快，不是selenium<br>  更新慢，而是浏览器更新快，要注意selenium和浏览器之间的对应关系</li></ul><p>windows安装可以采用<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install selenium</span><br></pre></td></tr></table></figure></p><p>如果电脑同时安装了python3 和python2 把pip 改成pip3 或者pip2 就可以了</p><p>然后我们创建一个py文件，使用selenium  <code>注意：文件名一定不要和python包的名字相同，否则会报错</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.find_element_by_id(<span class="string">'kw'</span>).send_keys(<span class="string">'selenium'</span>)</span><br></pre></td></tr></table></figure></p><p>运行发现会报错，因为我们没有安装浏览器驱动，下载之前先检查谷歌和火狐浏览器的版本，然后根据版本号下载对应的驱动。</p><p>可以从该<a href="http://chromedriver.chromium.org/downloads" target="_blank" rel="noopener">chromedriver</a>网站下载对应chromedriver的驱动,从<a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">geckodriver</a>下载对应版本的驱动。</p><p>下载完之后将两个压缩包解压，将两个 [ .exe ] 文件放到python同级目录下，与python.exe文件平级即可，比如我的文件路径为 D:\python\Anaconda ，只需要将两个[ .exe ] 文件放到该目录下</p><p>再次运行上面代码，如果出现错误将编译器关闭，重新打开。</p><p>如果出现下面错误，可能是因为网速慢，页面还没有加载出来，程序就执行完毕，导致获取不到element元素<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">selenium.common.exceptions.NoSuchElementException:Message: Unable to locate element: [id=&quot;kw&quot;]</span><br></pre></td></tr></table></figure></p><p>解决办法：可以让程序隐式等待10秒，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">driver = webdriver.Firefox()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">driver.implicitly_wait(<span class="number">10</span>) <span class="comment">#程序隐式等待10秒</span></span><br><span class="line">driver.find_element_by_id(<span class="string">'kw'</span>).send_keys(<span class="string">'selenium'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="无头浏览器PhantomJS的安装"><a href="#无头浏览器PhantomJS的安装" class="headerlink" title="无头浏览器PhantomJS的安装"></a>无头浏览器PhantomJS的安装</h3><p>首先下载<a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">PhantomJS</a><br>第一种</p><ul><li>下载完成后，放到合适的文件夹下解压，将其路径添加到环境变量中，路径如：D:\python\phantomjs-2.1.1-windows\bin<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">driver = webdriver.PhantomJS(executable_path=<span class="string">r'D:\python\phantomjs-2.1.1-windows\bin\phantomjs.exe'</span>)</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></li></ul><p>第二种</p><ul><li>下载完成后，解压，将phantomjs.exe放到与python.exe同级目录下，与python.exe文件平级即可<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">driver = webdriver.PhantomJS()</span><br><span class="line">driver.get(<span class="string">'http://www.baidu.com'</span>)</span><br></pre></td></tr></table></figure></li></ul><p>个人推荐使用第二种，比较方便</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/23.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="selenium" scheme="https://acczmt.top/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>奇书网小说信息</title>
    <link href="https://acczmt.top/2018/07/31/%E5%A5%87%E4%B9%A6%E7%BD%91%E5%B0%8F%E8%AF%B4%E4%BF%A1%E6%81%AF/"/>
    <id>https://acczmt.top/2018/07/31/奇书网小说信息/</id>
    <published>2018-07-30T16:20:20.000Z</published>
    <updated>2018-08-16T03:02:08.248Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/24.jpg?imageView2/2/h/600"><br></div></p><h2 id="获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据"><a href="#获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据" class="headerlink" title="获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据"></a>获取奇书网中玄幻奇幻的小说信息，并保存到execl中，也可以修改链接获取不同的数据</h2><p>运行效果如下所示:<br><img src="/assets/img/奇书网.png" alt="效果图" title="效果图展示"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># url = "https://www.qisuu.la/soft/sort01/index_1.html"</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QiShuWang</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.base_url = <span class="string">"https://www.qisuu.la"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>:UserAgent().random</span><br><span class="line">        &#125;</span><br><span class="line">        self.work_book = <span class="keyword">None</span></span><br><span class="line">        self.sheet = <span class="keyword">None</span></span><br><span class="line">        self.record = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.open_execl()</span><br><span class="line">        self.get_code_with_url()</span><br><span class="line">        self.work_book.save(<span class="string">"奇书网小说.xls"</span>)</span><br><span class="line">    <span class="comment"># 默认url为第一页</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code_with_url</span><span class="params">(self,url=<span class="string">"/soft/sort01/index_1.html"</span>)</span>:</span></span><br><span class="line">        <span class="string">"""获取网页源码 并获取下一页链接"""</span></span><br><span class="line">        full_url = self.base_url + url</span><br><span class="line">        response = requests.get(full_url,headers=self.headers)</span><br><span class="line">        code = etree.HTML(response.text)</span><br><span class="line">        detail_href = code.xpath(<span class="string">'//div[@class="listBox"]/ul/li/a/@href'</span>)</span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> detail_href:</span><br><span class="line">            novel_url = self.base_url + href</span><br><span class="line">            <span class="comment"># 将获取的小说详情页传递给该函数</span></span><br><span class="line">            self.get_novel_info(novel_url)</span><br><span class="line"></span><br><span class="line">        next_page_element = code.xpath(<span class="string">'//div[@class="tspage"]/a[last()-1]'</span>)[<span class="number">0</span>]</span><br><span class="line">        next_page = next_page_element.get(<span class="string">'href'</span>)</span><br><span class="line">        print(next_page)</span><br><span class="line">        text = next_page_element.xpath(<span class="string">'.//text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> text != <span class="string">"下一页"</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># 循环调用该函数 直到不满足条件为止</span></span><br><span class="line">        self.get_code_with_url(next_page)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_novel_info</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        <span class="string">"""获取小说的信息 并保存到Excel中"""</span></span><br><span class="line">        info_list = <span class="keyword">None</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        response.encoding=<span class="string">"utf-8"</span></span><br><span class="line">        code = etree.HTML(response.text)</span><br><span class="line">        novel_name = code.xpath(<span class="string">'//div[@class="detail_right"]/h1/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        info = code.xpath(<span class="string">'//div[@class="detail_right"]/ul/li[@class="small"]/text()'</span>)[:<span class="number">-1</span>]</span><br><span class="line">        click_num = info[<span class="number">0</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        file_size = info[<span class="number">1</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        book_type = info[<span class="number">2</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        update_time = info[<span class="number">3</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        state = info[<span class="number">4</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        author = info[<span class="number">5</span>].split(<span class="string">'：'</span>)[<span class="number">-1</span>]</span><br><span class="line">        novel_intro = code.xpath(<span class="string">'//div[@class="showInfo"]/p/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        download = code.xpath(<span class="string">'//div[@class="showDown"]/ul/li[last()]/script/text()'</span>)[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">1</span>].replace(<span class="string">"'"</span>,<span class="string">""</span>)</span><br><span class="line">        info_list = [novel_name,click_num, file_size, book_type, update_time, state, author,novel_intro,download]</span><br><span class="line">        <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(info_list):</span><br><span class="line">            self.sheet.write(self.record,index,data)</span><br><span class="line">        self.record += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_execl</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""创建一个execl表"""</span></span><br><span class="line">        self.work_book = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        self.sheet = self.work_book.add_sheet(<span class="string">'小说信息'</span>)</span><br><span class="line">        title = [<span class="string">'小说名字'</span>,<span class="string">'点击次数'</span>, <span class="string">'文件大小'</span>, <span class="string">'书籍类型'</span>, <span class="string">'更新日期'</span>, <span class="string">'连载状态'</span>, <span class="string">'书籍作者'</span>,<span class="string">'小说介绍'</span>,<span class="string">'下载地址'</span>]</span><br><span class="line">        <span class="keyword">for</span> i ,data <span class="keyword">in</span> enumerate(title):</span><br><span class="line">            self.sheet.write(<span class="number">0</span>,i,data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    qsw = QiShuWang()</span><br><span class="line">    qsw.start_spider()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/24.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="xpath" scheme="https://acczmt.top/tags/xpath/"/>
    
  </entry>
  
  <entry>
    <title>豆瓣电影top250</title>
    <link href="https://acczmt.top/2018/07/28/%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1top250/"/>
    <id>https://acczmt.top/2018/07/28/豆瓣电影top250/</id>
    <published>2018-07-28T08:20:20.000Z</published>
    <updated>2018-08-16T03:01:45.208Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/az/25.jpg?imageView2/2/h/600"><br></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">""" 豆瓣具有反爬机制，如果出现需登录时 就要先登录获取cookie 使用代理ip能够被检测出来 """</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># 随机一个UserAgent</span></span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouBanMovieTop</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.base_url = <span class="string">"https://movie.douban.com/top250"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>:UserAgent().random,</span><br><span class="line">            <span class="comment"># 模拟cookie 如果报错，需要登录 登录豆瓣账号 将cookie 复制粘贴到此处 如何查找cookie自行搜索</span></span><br><span class="line">            <span class="string">"Cookie"</span>:<span class="string">'将自己的cookie粘贴此处'</span></span><br><span class="line">        &#125;</span><br><span class="line">        self.work_book = <span class="keyword">None</span></span><br><span class="line">        self.sheet = <span class="keyword">None</span></span><br><span class="line">        self.record = <span class="number">1</span>  <span class="comment"># 保存execl的行号</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_load_dbmovie</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""主程序"""</span></span><br><span class="line">        self.get_execl()</span><br><span class="line">        self.get_code_with_url()</span><br><span class="line">        self.work_book.save(<span class="string">"豆瓣Top250.xls"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_execl</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""创建一个execl"""</span></span><br><span class="line">        self.work_book = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">        self.sheet = self.work_book.add_sheet(<span class="string">"电影排行top250"</span>)</span><br><span class="line">        title = [<span class="string">'排名'</span>,<span class="string">'电影名'</span>,<span class="string">'导演和演员'</span>,<span class="string">'评分'</span>,<span class="string">'评论人数'</span>]</span><br><span class="line">        <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(title):</span><br><span class="line">            self.sheet.write(<span class="number">0</span>,index,data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code_with_url</span><span class="params">(self,url=<span class="string">''</span>)</span>:</span></span><br><span class="line">        <span class="string">"""获取网页数据并保存到execl中</span></span><br><span class="line"><span class="string">        self.get_code_with_url 与 self.get_next_page 循环调用 直到不满足条件为止"""</span></span><br><span class="line">        full_url = self.base_url+url</span><br><span class="line">        response = requests.get(full_url,headers=self.headers)</span><br><span class="line">        code = etree.HTML(response.text)</span><br><span class="line">        item_div = code.xpath(<span class="string">'//div[@class="item"]'</span>)</span><br><span class="line">        <span class="keyword">for</span> tag <span class="keyword">in</span> item_div:</span><br><span class="line">            data_list = <span class="keyword">None</span></span><br><span class="line">            rank = tag.xpath(<span class="string">'.//em/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">            movie_name = tag.xpath(<span class="string">'.//div[@class="hd"]/a/span/text()'</span>)</span><br><span class="line">            movie_name = <span class="string">""</span>.join(movie_name)</span><br><span class="line">            creater = tag.xpath(<span class="string">'.//div[@class="bd"]/p/text()'</span>)[<span class="number">0</span>].strip()</span><br><span class="line">            star = tag.xpath(<span class="string">'.//div[@class="star"]/span[@class="rating_num"]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">            comment = tag.xpath(<span class="string">'.//div[@class="star"]/span[last()]/text()'</span>)[<span class="number">0</span>][<span class="number">0</span>:<span class="number">-3</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将数据写入execl中</span></span><br><span class="line">            data_list = [rank,movie_name,creater,star,comment]</span><br><span class="line">            <span class="keyword">for</span> index,data <span class="keyword">in</span> enumerate(data_list):</span><br><span class="line">                self.sheet.write(self.record, index,data)</span><br><span class="line">            self.record += <span class="number">1</span></span><br><span class="line">        self.get_next_page(code)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_next_page</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        <span class="string">"""获取下一页的链接"""</span></span><br><span class="line">        next_page = code.xpath(<span class="string">'//span[@class="next"]/a/@href'</span>)</span><br><span class="line">        <span class="comment"># 判断是否存在下一页 没有则退出  存在则继续执行 self.get_code_with_url(next_page[0])</span></span><br><span class="line">        <span class="keyword">if</span> len(next_page) == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">"已经到最后一页了"</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.get_code_with_url(next_page[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个对象并调用方法执行</span></span><br><span class="line">db_movie = DouBanMovieTop()</span><br><span class="line">db_movie.start_load_dbmovie()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/az/25.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/div&gt;

&lt;
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="xpath" scheme="https://acczmt.top/tags/xpath/"/>
    
  </entry>
  
  <entry>
    <title>169we壁纸</title>
    <link href="https://acczmt.top/2018/07/27/169we%E5%A3%81%E7%BA%B8/"/>
    <id>https://acczmt.top/2018/07/27/169we壁纸/</id>
    <published>2018-07-27T09:30:00.000Z</published>
    <updated>2018-08-17T02:08:40.202Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/26.jpg?imageView2/2/h/600"><br></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""根据输入的类别，获取www.169we.com中的所有图片,代码有些累赘 ，可以进行简化"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests,os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># base_url = "http://www.169we.com/diannaobizhi/list_7_1.html"</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pic169Spider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,category)</span>:</span></span><br><span class="line">        self.category = category</span><br><span class="line">        self.base_url = <span class="string">"http://www.169we.com/&#123;&#125;/"</span>.format(self.category)</span><br><span class="line"></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>:UserAgent().random,</span><br><span class="line">            <span class="string">"Host"</span>:<span class="string">"www.169we.com"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        self.img_headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: UserAgent().random,</span><br><span class="line">            <span class="string">"Host"</span>: <span class="string">"724.169pp.net"</span>,</span><br><span class="line">        &#125;</span><br><span class="line">        self.dic = &#123;</span><br><span class="line">        <span class="string">"diannaobizhi"</span>:<span class="string">"7"</span>,</span><br><span class="line">        <span class="string">"shoujibizhi"</span>:<span class="string">"6"</span>,</span><br><span class="line">        <span class="string">"wangyouzipai"</span>:<span class="string">"2"</span>,</span><br><span class="line">        <span class="string">"gaogensiwa"</span>:<span class="string">"3"</span>,</span><br><span class="line">        <span class="string">"xiyangmeinv"</span>:<span class="string">"4"</span>,</span><br><span class="line">        <span class="string">"guoneimeinv"</span>:<span class="string">"5"</span>,</span><br><span class="line">        <span class="string">"xingganmeinv"</span>:<span class="string">"1"</span></span><br><span class="line">        &#125;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIndexPage</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        <span class="string">"""获取图片分类的总页数"""</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        soup = BeautifulSoup(response.text,<span class="string">"lxml"</span>)</span><br><span class="line">        page_all = soup.select(<span class="string">'body  div.page  ul li a'</span>)</span><br><span class="line">        <span class="keyword">return</span> page_all[<span class="number">-3</span>].get_text()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        <span class="string">"""获取图片的总页数"""</span></span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        response.encoding=<span class="string">"gbk"</span></span><br><span class="line">        total_page = int(re.findall(<span class="string">r'.*?共(.*?)页'</span>,response.text,re.S)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> total_page</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getIndexImgHref</span><span class="params">(self,url)</span>:</span></span><br><span class="line">        response = requests.get(url,headers=self.headers)</span><br><span class="line">        response.encoding=<span class="string">"gbk"</span></span><br><span class="line">        data = re.findall(<span class="string">r'&lt;li&gt;&lt;a href="(.*?)" class="pic".*?&gt;.*?&lt;p&gt;(.*?)&lt;/p&gt;'</span>,response.text,re.S)</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getImgUrl</span><span class="params">(self,url,dirname,index)</span>:</span></span><br><span class="line">        <span class="string">"""获取图片的src"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(self.category + <span class="string">"/"</span> +dirname):</span><br><span class="line">            os.makedirs(self.category + <span class="string">"/"</span> +dirname)</span><br><span class="line">        response = requests.get(url, headers=self.headers)</span><br><span class="line">        <span class="comment"># response.encoding = "gbk"</span></span><br><span class="line">        img_urls = re.findall(<span class="string">r'&lt;p align="center"&gt;.*?&lt;img src="(.*?)".*?&lt;/p&gt;'</span>,response.text,re.S)</span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> img_urls:</span><br><span class="line">            self.saveImg(img_url,dirname,index)</span><br><span class="line">            index+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">saveImg</span><span class="params">(self,img_url,dirname,index)</span>:</span></span><br><span class="line">        <span class="string">"""保存图片到本地"""</span></span><br><span class="line"></span><br><span class="line">        result = requests.get(img_url,headers=self.img_headers)</span><br><span class="line">        <span class="keyword">with</span> open(self.category + <span class="string">"/"</span> + dirname +<span class="string">"/"</span>+ str(index) + <span class="string">".jpg"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(result.content)</span><br><span class="line">            <span class="comment"># time.sleep(1)</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""主函数"""</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(self.category):</span><br><span class="line">            os.makedirs(self.category)</span><br><span class="line">        pages = int(self.getIndexPage(self.base_url))</span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>,pages+<span class="number">1</span>):</span><br><span class="line">            print(page)</span><br><span class="line">            num = self.dic[self.category]</span><br><span class="line">            url = <span class="string">"http://www.169we.com/&#123;&#125;/list_&#123;&#125;_&#123;&#125;.html"</span>.format(self.category,num,page)</span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> self.getIndexImgHref(url):</span><br><span class="line">                old_url = data[<span class="number">0</span>]</span><br><span class="line">                pattern = re.compile(<span class="string">r'&lt;.*?&gt;'</span>,re.S)</span><br><span class="line">                dirname = re.sub(pattern,<span class="string">''</span>,data[<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,int(self.getPage(old_url))+<span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">if</span> i == <span class="number">1</span>:</span><br><span class="line">                        new_url = old_url</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        lista = old_url.split(<span class="string">"."</span>)</span><br><span class="line">                        lista[<span class="number">-2</span>] = lista[<span class="number">-2</span>] + <span class="string">"_&#123;&#125;"</span>.format(i)</span><br><span class="line">                        new_url = <span class="string">"."</span>.join(lista)</span><br><span class="line">                    self.getImgUrl(new_url,dirname,i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    msg = <span class="string">"""</span></span><br><span class="line"><span class="string">            提示信息：</span></span><br><span class="line"><span class="string">            diannaobizhi--——&gt;电脑壁纸</span></span><br><span class="line"><span class="string">            shoujibizhi--——&gt;手机壁纸</span></span><br><span class="line"><span class="string">            wangyouzipai--——&gt;网友自拍</span></span><br><span class="line"><span class="string">            gaogensiwa--——&gt;高跟丝袜</span></span><br><span class="line"><span class="string">            xiyangmeinv--——&gt;西洋美女</span></span><br><span class="line"><span class="string">            guoneimeinv--——&gt;国内美女</span></span><br><span class="line"><span class="string">            xingganmeinv--——&gt;性感美女</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    print(msg)</span><br><span class="line">    category = input(<span class="string">"请输入你要获取的类别名："</span>)</span><br><span class="line">    diannaobizhi = Pic169Spider(category)</span><br><span class="line">    diannaobizhi.main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/26.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="下载图片" scheme="https://acczmt.top/tags/%E4%B8%8B%E8%BD%BD%E5%9B%BE%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>美食杰爬虫</title>
    <link href="https://acczmt.top/2018/07/26/%E7%BE%8E%E9%A3%9F%E6%9D%B0%E7%88%AC%E8%99%AB/"/>
    <id>https://acczmt.top/2018/07/26/美食杰爬虫/</id>
    <published>2018-07-26T15:06:00.000Z</published>
    <updated>2018-08-17T01:17:12.473Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/87.jpg?imageView2/2/h/600"><br></div></p><ul><li>美食杰  使用cookie模拟登陆 获取网页源码s</li><li>使用xpath得到用户信息 存储到excel表格</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># from lxml import etree</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request,HTTPCookieProcessor,build_opener</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> http.cookiejar <span class="keyword">import</span> CookieJar,LWPCookieJar</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br><span class="line"><span class="comment"># ssl._create_default_https_content = ssl._create_unverified_context</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeiShiJie</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.login_url = <span class="string">"https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fi.meishi.cc%2Flogin.php%3Fac%3Dzhuce"</span></span><br><span class="line">        <span class="comment"># self.login_url = "https://i.meishi.cc/login.php?redirect=https%3A%2F%2Fwww.meishij.net%2F"</span></span><br><span class="line">        self.index_url = <span class="string">"https://www.meishij.net&#123;&#125;?&amp;page=&#123;&#125;"</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"</span></span><br><span class="line">        &#125;</span><br><span class="line">        self.total_page = <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_cookies</span><span class="params">(self)</span>:</span></span><br><span class="line">        cookie = LWPCookieJar(filename=<span class="string">"mei_shi_jie.txt"</span>)</span><br><span class="line">        cookie_handler = HTTPCookieProcessor(cookie)</span><br><span class="line">        opener = build_opener(cookie_handler)</span><br><span class="line">        login_data = urlencode(&#123;</span><br><span class="line">            <span class="comment"># "redirect":"https://www.meishij.net/",</span></span><br><span class="line">            <span class="string">"username"</span>:<span class="string">"1797190195@qq.com"</span>,</span><br><span class="line">            <span class="string">"password"</span>:<span class="string">"qwert12345"</span></span><br><span class="line">        &#125;)</span><br><span class="line">        request = Request(self.login_url,bytes(login_data,encoding=<span class="string">"utf-8"</span>))</span><br><span class="line">        response = opener.open(request).read().decode()</span><br><span class="line"></span><br><span class="line">        cookie.save(ignore_discard=<span class="keyword">True</span>,ignore_expires=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code</span><span class="params">(self,path,page_index)</span>:</span></span><br><span class="line">        cookie = LWPCookieJar()</span><br><span class="line">        cookie.load(<span class="string">"mei_shi_jie.txt"</span>,ignore_expires=<span class="keyword">True</span> ,ignore_discard=<span class="keyword">True</span>)</span><br><span class="line">        cookie_handler = HTTPCookieProcessor(cookie)</span><br><span class="line">        opener = build_opener(cookie_handler)</span><br><span class="line">        url = self.index_url.format(path,str(page_index))</span><br><span class="line">        request = Request(url,headers=self.headers)</span><br><span class="line">        response = opener.open(request)</span><br><span class="line">        <span class="keyword">return</span> response.read().decode()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_total_page</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        root = etree.HTML(code)</span><br><span class="line">        self.total_page = int(root.xpath(<span class="string">'//span/form/text()'</span>)[<span class="number">0</span>][<span class="number">1</span>:<span class="number">-5</span>])</span><br><span class="line">    <span class="comment"># def get_menu_url(self,code):</span></span><br><span class="line">    <span class="comment">#     root = etree.HTML(code)</span></span><br><span class="line">    <span class="comment">#     hrefs = root.xpath('//ul[@class="listnav_ul"]/li/a/@href')</span></span><br><span class="line">    <span class="comment">#     print(hrefs[:-2])</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_data_from_code</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        root = etree.HTML(code)</span><br><span class="line">        cai_names = root.xpath(<span class="string">'//div[@class="c1"]/strong/text()'</span>)</span><br><span class="line">        comment_and_love = root.xpath(<span class="string">'//div[@class="c1"]/span/text()'</span>)</span><br><span class="line">        comments,loves = [],[]</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> comment_and_love:</span><br><span class="line">            comment = re.findall(<span class="string">r'(\d+) 评论'</span>,data,re.S)</span><br><span class="line">            comments.append(comment[<span class="number">0</span>])</span><br><span class="line">            love = re.findall(<span class="string">r'评论  (\d+) 人气'</span>,data,re.S)</span><br><span class="line">            loves.append(love[<span class="number">0</span>])</span><br><span class="line">        authors = root.xpath(<span class="string">'//div[@class="c1"]/em/text()'</span>)</span><br><span class="line">        <span class="keyword">return</span> cai_names,authors,comments,loves</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.get_cookies()</span><br><span class="line">        workBook = xlwt.Workbook(encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        des_list = [<span class="string">"印象中的那些妈妈的味道"</span>, <span class="string">"了解咱餐饮文化大国，看中华八大菜系"</span>, <span class="string">"不出家门，也能吃遍大江南北"</span>, <span class="string">"看着菜谱做洋餐，做国际美食达人"</span>, <span class="string">"把爱卷进面团，让它到烤箱里继续升温"</span>]</span><br><span class="line">        href_list = [<span class="string">'/chufang/diy/'</span>, <span class="string">'/china-food/caixi/'</span>, <span class="string">'/china-food/xiaochi/'</span>, <span class="string">'/chufang/diy/guowaicaipu1/'</span>,<span class="string">'/hongpei/'</span>]</span><br><span class="line">        <span class="keyword">for</span> index, dec <span class="keyword">in</span> enumerate(des_list):</span><br><span class="line">            sheet = workBook.add_sheet(dec)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">0</span>, <span class="string">"菜名"</span>)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">1</span>, <span class="string">"作者"</span>)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">2</span>, <span class="string">"评论数"</span>)</span><br><span class="line">            sheet.write(<span class="number">0</span>, <span class="number">3</span>, <span class="string">"人气数"</span>)</span><br><span class="line">            code = self.get_code(href_list[index], <span class="number">1</span>)</span><br><span class="line">            self.get_total_page(code)</span><br><span class="line">            x = <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,self.total_page+<span class="number">1</span>):</span><br><span class="line">                print(x)</span><br><span class="line">                code = self.get_code(href_list[index],i)</span><br><span class="line">                cai_names, authors, comments, loves = self.get_data_from_code(code)</span><br><span class="line">                <span class="keyword">for</span> cai_name,author,comment,love <span class="keyword">in</span> zip(cai_names,authors,comments,loves):</span><br><span class="line">                    sheet.write(x,<span class="number">0</span>,cai_name)</span><br><span class="line">                    sheet.write(x,<span class="number">1</span>,author)</span><br><span class="line">                    sheet.write(x,<span class="number">2</span>,comment)</span><br><span class="line">                    sheet.write(x,<span class="number">3</span>,love)</span><br><span class="line">                    x += <span class="number">1</span></span><br><span class="line">            workBook.save(<span class="string">"美食杰食谱2.xls"</span>)</span><br><span class="line"></span><br><span class="line">meishi = MeiShiJie()</span><br><span class="line">meishi.start_spider()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/87.jpg?imageView2/2/h/600&quot;&gt;&lt;br
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
      <category term="xlwt" scheme="https://acczmt.top/tags/xlwt/"/>
    
  </entry>
  
  <entry>
    <title>51Job</title>
    <link href="https://acczmt.top/2018/07/26/Job51/"/>
    <id>https://acczmt.top/2018/07/26/Job51/</id>
    <published>2018-07-26T12:50:00.000Z</published>
    <updated>2018-08-17T02:08:17.914Z</updated>
    
    <content type="html"><![CDATA[<div align="center"><br><img title="BBB" alt="BBBB" src="http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/55.jpg?imageView2/2/h/600"><br></div><ul><li>51job</li><li>爬取任意城市的python岗位</li><li>包含公司名称</li><li>存入execl中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> Request,urlopen</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> quote</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobSpider</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,cityList=[],workName=<span class="string">""</span>)</span>:</span></span><br><span class="line">        self.old_work_name = workName</span><br><span class="line">        self.base_url = <span class="string">"https://search.51job.com/list/&#123;&#125;,000000,0000,00,9,99,&#123;&#125;,2,&#123;&#125;.html"</span></span><br><span class="line">        self.total_page = <span class="number">1</span></span><br><span class="line">        self.cityString = <span class="string">""</span></span><br><span class="line">        self.headers = &#123;</span><br><span class="line">            <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># 将获取的字典反转</span></span><br><span class="line">        self.cityDic = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.get_city_info().items()&#125;</span><br><span class="line">        <span class="comment"># 或者使用通过 值获取对应的键 list(dic.keys())[list(dic.values()).index(2)]</span></span><br><span class="line">        <span class="comment"># 如果没有选择城市默认为全国</span></span><br><span class="line">        <span class="keyword">if</span> len(cityList) == <span class="number">0</span>:</span><br><span class="line">            self.cityString = <span class="string">'000000'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 以下代码为：如果城市名输入错误进行错误处理</span></span><br><span class="line">            <span class="keyword">for</span> cityName <span class="keyword">in</span> cityList:</span><br><span class="line">                <span class="keyword">if</span> cityName <span class="keyword">in</span> self.cityDic:</span><br><span class="line">                    <span class="keyword">if</span> cityName == cityList[<span class="number">-1</span>]:</span><br><span class="line">                        self.cityString+=self.cityDic[cityName]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        self.cityString += self.cityDic[cityName] + <span class="string">"%252C"</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    print(<span class="string">"******&#123;&#125;城市输入错误******"</span>.format(cityName))</span><br><span class="line">            <span class="keyword">if</span> len(self.cityString) == <span class="number">0</span>:</span><br><span class="line">                self.cityString = <span class="string">'000000'</span></span><br><span class="line">        <span class="comment"># 职位处理</span></span><br><span class="line">        <span class="keyword">if</span> len(workName) == <span class="number">0</span>:</span><br><span class="line">            self.workName = <span class="string">'%2520'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.workName = quote(workName,string.printable)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_city_info</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 获取城市对应的ID</span></span><br><span class="line">        url = <span class="string">"https://js.51jobcdn.com/in/js/2016/layer/area_array_c.js?20180319"</span></span><br><span class="line">        request = Request(url,headers=self.headers)</span><br><span class="line">        code = urlopen(request).read().decode(<span class="string">"gbk"</span>)</span><br><span class="line">        pattern = re.compile(<span class="string">r'.*?area=(.*?);'</span>,re.S)</span><br><span class="line">        result = pattern.findall(code)</span><br><span class="line">        <span class="keyword">return</span> json.loads(result[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_code</span><span class="params">(self,pageIndex=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># 获取网页源码</span></span><br><span class="line">        url = self.base_url.format(self.cityString,self.workName,pageIndex)</span><br><span class="line">        print(url)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            request = Request(url,headers=self.headers)</span><br><span class="line">            code = urlopen(request).read().decode(<span class="string">"gbk"</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(<span class="string">"请求失败"</span>,e)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> code</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_total_page</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        <span class="comment"># 获取所有页数</span></span><br><span class="line">        pattern = re.compile(<span class="string">r'共(\d+)页，到第'</span>,re.S)</span><br><span class="line">        total_page = pattern.findall(code)[<span class="number">0</span>]</span><br><span class="line">        self.total_page=int(total_page)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_data</span><span class="params">(self,code)</span>:</span></span><br><span class="line">        <span class="comment"># 提取数据</span></span><br><span class="line">        pattern = re.compile(<span class="string">r'&lt;p class="t1 "&gt;.*?&lt;a.*?title="(.*?)".*?&gt;.*?&lt;span class="t2"&gt;.*?&lt;a.*?title="(.*?)".*?&gt;.*?&lt;span class="t3"&gt;(.*?)&lt;/span&gt;.*?&lt;span class="t4"&gt;(.*?)&lt;/span&gt;'</span>,re.S)</span><br><span class="line">        result = pattern.findall(code)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_sheet_table</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 创建execl表</span></span><br><span class="line">        workBook = xlwt.Workbook(encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">        sheet = workBook.add_sheet(self.old_work_name+<span class="string">"职位"</span>)</span><br><span class="line">        lista = [<span class="string">"职位名"</span>,<span class="string">"公司名"</span>,<span class="string">"工作地点"</span>,<span class="string">"薪资"</span>]</span><br><span class="line">        <span class="keyword">for</span> y,i <span class="keyword">in</span> enumerate(lista):</span><br><span class="line">            sheet.write(<span class="number">0</span>,y,i)</span><br><span class="line">        <span class="keyword">return</span> sheet,workBook</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_spider</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 程序入口</span></span><br><span class="line">        code = self.get_code(<span class="number">1</span>)</span><br><span class="line">        self.get_total_page(code)</span><br><span class="line">        sheet,workBook = self.open_sheet_table()</span><br><span class="line">        x = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(<span class="number">1</span>,self.total_page+<span class="number">1</span>): <span class="comment">#self.total_page+1</span></span><br><span class="line">            time.sleep(<span class="number">1</span>)</span><br><span class="line">            code = self.get_code(index)</span><br><span class="line">            results = self.get_all_data(code)</span><br><span class="line">            <span class="keyword">if</span> len(results) == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">"对不起，没有找到符合你条件的职位！"</span>)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">                <span class="keyword">for</span> y,res <span class="keyword">in</span> enumerate(result):</span><br><span class="line">                    <span class="comment"># x 代表行，y代表列  res代表值</span></span><br><span class="line">                    sheet.write(x,y,res)</span><br><span class="line">                x += <span class="number">1</span></span><br><span class="line">            workBook.save(<span class="string">"51job招聘信息4.xls"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    cityList = []</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        city = input(<span class="string">"请输入你想去的城市,按Q退出："</span>)</span><br><span class="line">        <span class="keyword">if</span> city == <span class="string">"Q"</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        cityList.append(city)</span><br><span class="line">    work = input(<span class="string">"请输入你喜欢的工作："</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># job = JobSpider(["北京","上海"],"python")</span></span><br><span class="line">    job = JobSpider(cityList,work)</span><br><span class="line">    job.start_spider()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img title=&quot;BBB&quot; alt=&quot;BBBB&quot; src=&quot;http://pdhrh6d6j.bkt.clouddn.com/images/Bing_1280/55.jpg?imageView2/2/h/600&quot;&gt;&lt;br&gt;&lt;/
      
    
    </summary>
    
    
      <category term="爬虫" scheme="https://acczmt.top/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Python" scheme="https://acczmt.top/tags/Python/"/>
    
  </entry>
  
</feed>
